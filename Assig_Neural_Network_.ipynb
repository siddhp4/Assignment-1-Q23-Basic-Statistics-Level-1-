{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhp4/Assignment-1-Q23-Basic-Statistics-Level-1-/blob/main/Assig_Neural_Network_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsZ0YfPsTBJg"
      },
      "source": [
        "# Assignment 16. Neural Network - 01"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "h8FJSbokTBJk"
      },
      "source": [
        "PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS\n",
        "\n",
        "month\tmonth of the year: 'jan' to 'dec'\n",
        "day\tday of the week: 'mon' to 'sun'\n",
        "FFMC\tFFMC index from the FWI system: 18.7 to 96.20\n",
        "DMC\tDMC index from the FWI system: 1.1 to 291.3\n",
        "DC\tDC index from the FWI system: 7.9 to 860.6\n",
        "ISI\tISI index from the FWI system: 0.0 to 56.10\n",
        "temp\ttemperature in Celsius degrees: 2.2 to 33.30\n",
        "RH\trelative humidity in %: 15.0 to 100\n",
        "wind\twind speed in km/h: 0.40 to 9.40\n",
        "rain\toutside rain in mm/m2 : 0.0 to 6.4\n",
        "Size_Categorie \tthe burned area of the forest ( Small , Large)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re26zuH2TBJm"
      },
      "source": [
        "#### Dataset: forestfires.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NtzpVusrTBJn"
      },
      "outputs": [],
      "source": [
        "# Importig Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZV5uDA54TBJq"
      },
      "outputs": [],
      "source": [
        "# Loading dataset\n",
        "\n",
        "data = pd.read_csv('forestfires.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRQcUxhVTBJq"
      },
      "source": [
        "### EDA & Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPreoHScTBJr",
        "outputId": "192c8653-06b8-4aa6-9cfc-2cd285f4435d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(517, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "9FJNiIzvTBJu",
        "outputId": "f3ee8fef-0014-4b47-8919-4ada49d11eb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f2035d9b-7223-4974-9e6b-39c7f316afe2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f2035d9b-7223-4974-9e6b-39c7f316afe2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f2035d9b-7223-4974-9e6b-39c7f316afe2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f2035d9b-7223-4974-9e6b-39c7f316afe2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  month  day  FFMC   DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "0   mar  fri  86.2  26.2  ...         0         0         0          small\n",
              "1   oct  tue  90.6  35.4  ...         0         1         0          small\n",
              "2   oct  sat  90.6  43.7  ...         0         1         0          small\n",
              "3   mar  fri  91.7  33.3  ...         0         0         0          small\n",
              "4   mar  sun  89.3  51.3  ...         0         0         0          small\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "3sByfZ2aTBJv",
        "outputId": "dc76f788-fd09-4832-edc1-657441011472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7e99be9b-466c-48fa-bdcc-046cc7268d8f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>sep</td>\n",
              "      <td>sat</td>\n",
              "      <td>92.2</td>\n",
              "      <td>102.3</td>\n",
              "      <td>751.5</td>\n",
              "      <td>8.4</td>\n",
              "      <td>19.7</td>\n",
              "      <td>35</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>jun</td>\n",
              "      <td>mon</td>\n",
              "      <td>90.4</td>\n",
              "      <td>93.3</td>\n",
              "      <td>298.1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>20.7</td>\n",
              "      <td>25</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>sep</td>\n",
              "      <td>fri</td>\n",
              "      <td>90.3</td>\n",
              "      <td>290.0</td>\n",
              "      <td>855.3</td>\n",
              "      <td>7.4</td>\n",
              "      <td>16.2</td>\n",
              "      <td>58</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>jul</td>\n",
              "      <td>mon</td>\n",
              "      <td>94.2</td>\n",
              "      <td>62.3</td>\n",
              "      <td>442.9</td>\n",
              "      <td>11.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>36</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>sep</td>\n",
              "      <td>sat</td>\n",
              "      <td>92.5</td>\n",
              "      <td>88.0</td>\n",
              "      <td>698.6</td>\n",
              "      <td>7.1</td>\n",
              "      <td>17.8</td>\n",
              "      <td>51</td>\n",
              "      <td>7.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>sep</td>\n",
              "      <td>mon</td>\n",
              "      <td>63.5</td>\n",
              "      <td>70.8</td>\n",
              "      <td>665.3</td>\n",
              "      <td>0.8</td>\n",
              "      <td>22.6</td>\n",
              "      <td>38</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.32</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>sep</td>\n",
              "      <td>mon</td>\n",
              "      <td>91.6</td>\n",
              "      <td>108.4</td>\n",
              "      <td>764.0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>22.7</td>\n",
              "      <td>35</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.48</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>sep</td>\n",
              "      <td>fri</td>\n",
              "      <td>92.1</td>\n",
              "      <td>99.0</td>\n",
              "      <td>745.3</td>\n",
              "      <td>9.6</td>\n",
              "      <td>19.8</td>\n",
              "      <td>47</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.72</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>aug</td>\n",
              "      <td>tue</td>\n",
              "      <td>94.8</td>\n",
              "      <td>108.3</td>\n",
              "      <td>647.1</td>\n",
              "      <td>17.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>51</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>aug</td>\n",
              "      <td>tue</td>\n",
              "      <td>91.0</td>\n",
              "      <td>121.2</td>\n",
              "      <td>561.6</td>\n",
              "      <td>7.0</td>\n",
              "      <td>21.6</td>\n",
              "      <td>19</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e99be9b-466c-48fa-bdcc-046cc7268d8f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7e99be9b-466c-48fa-bdcc-046cc7268d8f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7e99be9b-466c-48fa-bdcc-046cc7268d8f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    month  day  FFMC    DMC  ...  monthnov  monthoct  monthsep  size_category\n",
              "328   sep  sat  92.2  102.3  ...         0         0         1          small\n",
              "300   jun  mon  90.4   93.3  ...         0         0         0          small\n",
              "440   sep  fri  90.3  290.0  ...         0         0         1          small\n",
              "47    jul  mon  94.2   62.3  ...         0         0         0          small\n",
              "10    sep  sat  92.5   88.0  ...         0         0         1          small\n",
              "199   sep  mon  63.5   70.8  ...         0         0         1          large\n",
              "338   sep  mon  91.6  108.4  ...         0         0         1          large\n",
              "353   sep  fri  92.1   99.0  ...         0         0         1          small\n",
              "82    aug  tue  94.8  108.3  ...         0         0         0          small\n",
              "79    aug  tue  91.0  121.2  ...         0         0         0          small\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veoiHJy8TBJw",
        "outputId": "86fc4e4a-33be-4b9d-cc93-73a8dea43583"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 517 entries, 0 to 516\n",
            "Data columns (total 31 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   month          517 non-null    object \n",
            " 1   day            517 non-null    object \n",
            " 2   FFMC           517 non-null    float64\n",
            " 3   DMC            517 non-null    float64\n",
            " 4   DC             517 non-null    float64\n",
            " 5   ISI            517 non-null    float64\n",
            " 6   temp           517 non-null    float64\n",
            " 7   RH             517 non-null    int64  \n",
            " 8   wind           517 non-null    float64\n",
            " 9   rain           517 non-null    float64\n",
            " 10  area           517 non-null    float64\n",
            " 11  dayfri         517 non-null    int64  \n",
            " 12  daymon         517 non-null    int64  \n",
            " 13  daysat         517 non-null    int64  \n",
            " 14  daysun         517 non-null    int64  \n",
            " 15  daythu         517 non-null    int64  \n",
            " 16  daytue         517 non-null    int64  \n",
            " 17  daywed         517 non-null    int64  \n",
            " 18  monthapr       517 non-null    int64  \n",
            " 19  monthaug       517 non-null    int64  \n",
            " 20  monthdec       517 non-null    int64  \n",
            " 21  monthfeb       517 non-null    int64  \n",
            " 22  monthjan       517 non-null    int64  \n",
            " 23  monthjul       517 non-null    int64  \n",
            " 24  monthjun       517 non-null    int64  \n",
            " 25  monthmar       517 non-null    int64  \n",
            " 26  monthmay       517 non-null    int64  \n",
            " 27  monthnov       517 non-null    int64  \n",
            " 28  monthoct       517 non-null    int64  \n",
            " 29  monthsep       517 non-null    int64  \n",
            " 30  size_category  517 non-null    object \n",
            "dtypes: float64(8), int64(20), object(3)\n",
            "memory usage: 125.3+ KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "7W2iRNNSTBJx",
        "outputId": "7c1d4dc6-427c-4e7a-c756-d3cf52db4603"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9e897606-860f-4729-9825-3d5408c931a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>dayfri</th>\n",
              "      <th>daymon</th>\n",
              "      <th>daysat</th>\n",
              "      <th>daysun</th>\n",
              "      <th>daythu</th>\n",
              "      <th>daytue</th>\n",
              "      <th>daywed</th>\n",
              "      <th>monthapr</th>\n",
              "      <th>monthaug</th>\n",
              "      <th>monthdec</th>\n",
              "      <th>monthfeb</th>\n",
              "      <th>monthjan</th>\n",
              "      <th>monthjul</th>\n",
              "      <th>monthjun</th>\n",
              "      <th>monthmar</th>\n",
              "      <th>monthmay</th>\n",
              "      <th>monthnov</th>\n",
              "      <th>monthoct</th>\n",
              "      <th>monthsep</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>90.644681</td>\n",
              "      <td>110.872340</td>\n",
              "      <td>547.940039</td>\n",
              "      <td>9.021663</td>\n",
              "      <td>18.889168</td>\n",
              "      <td>44.288201</td>\n",
              "      <td>4.017602</td>\n",
              "      <td>0.021663</td>\n",
              "      <td>12.847292</td>\n",
              "      <td>0.164410</td>\n",
              "      <td>0.143133</td>\n",
              "      <td>0.162476</td>\n",
              "      <td>0.183752</td>\n",
              "      <td>0.117988</td>\n",
              "      <td>0.123791</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.355899</td>\n",
              "      <td>0.017408</td>\n",
              "      <td>0.038685</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.061896</td>\n",
              "      <td>0.032882</td>\n",
              "      <td>0.104449</td>\n",
              "      <td>0.003868</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>0.029014</td>\n",
              "      <td>0.332689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5.520111</td>\n",
              "      <td>64.046482</td>\n",
              "      <td>248.066192</td>\n",
              "      <td>4.559477</td>\n",
              "      <td>5.806625</td>\n",
              "      <td>16.317469</td>\n",
              "      <td>1.791653</td>\n",
              "      <td>0.295959</td>\n",
              "      <td>63.655818</td>\n",
              "      <td>0.371006</td>\n",
              "      <td>0.350548</td>\n",
              "      <td>0.369244</td>\n",
              "      <td>0.387657</td>\n",
              "      <td>0.322907</td>\n",
              "      <td>0.329662</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.479249</td>\n",
              "      <td>0.130913</td>\n",
              "      <td>0.193029</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.241199</td>\n",
              "      <td>0.178500</td>\n",
              "      <td>0.306138</td>\n",
              "      <td>0.062137</td>\n",
              "      <td>0.043980</td>\n",
              "      <td>0.168007</td>\n",
              "      <td>0.471632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.700000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>90.200000</td>\n",
              "      <td>68.600000</td>\n",
              "      <td>437.700000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>91.600000</td>\n",
              "      <td>108.300000</td>\n",
              "      <td>664.200000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>92.900000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>713.900000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.570000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>96.200000</td>\n",
              "      <td>291.300000</td>\n",
              "      <td>860.600000</td>\n",
              "      <td>56.100000</td>\n",
              "      <td>33.300000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>1090.840000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9e897606-860f-4729-9825-3d5408c931a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9e897606-860f-4729-9825-3d5408c931a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9e897606-860f-4729-9825-3d5408c931a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             FFMC         DMC          DC  ...    monthnov    monthoct    monthsep\n",
              "count  517.000000  517.000000  517.000000  ...  517.000000  517.000000  517.000000\n",
              "mean    90.644681  110.872340  547.940039  ...    0.001934    0.029014    0.332689\n",
              "std      5.520111   64.046482  248.066192  ...    0.043980    0.168007    0.471632\n",
              "min     18.700000    1.100000    7.900000  ...    0.000000    0.000000    0.000000\n",
              "25%     90.200000   68.600000  437.700000  ...    0.000000    0.000000    0.000000\n",
              "50%     91.600000  108.300000  664.200000  ...    0.000000    0.000000    0.000000\n",
              "75%     92.900000  142.400000  713.900000  ...    0.000000    0.000000    1.000000\n",
              "max     96.200000  291.300000  860.600000  ...    1.000000    1.000000    1.000000\n",
              "\n",
              "[8 rows x 28 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpGcQOg7TBJx",
        "outputId": "82d22f51-d4a5-4d79-a4b6-f6d5f90455d2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "month            0\n",
              "day              0\n",
              "FFMC             0\n",
              "DMC              0\n",
              "DC               0\n",
              "ISI              0\n",
              "temp             0\n",
              "RH               0\n",
              "wind             0\n",
              "rain             0\n",
              "area             0\n",
              "dayfri           0\n",
              "daymon           0\n",
              "daysat           0\n",
              "daysun           0\n",
              "daythu           0\n",
              "daytue           0\n",
              "daywed           0\n",
              "monthapr         0\n",
              "monthaug         0\n",
              "monthdec         0\n",
              "monthfeb         0\n",
              "monthjan         0\n",
              "monthjul         0\n",
              "monthjun         0\n",
              "monthmar         0\n",
              "monthmay         0\n",
              "monthnov         0\n",
              "monthoct         0\n",
              "monthsep         0\n",
              "size_category    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FU-yhsF7TBJy",
        "outputId": "9077a14f-c8f6-4f72-e1dd-c9643b16f585"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-742e8640-66db-4a29-bbc4-d178aa3f4ecf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "      <td>large</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows  12 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742e8640-66db-4a29-bbc4-d178aa3f4ecf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-742e8640-66db-4a29-bbc4-d178aa3f4ecf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-742e8640-66db-4a29-bbc4-d178aa3f4ecf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    month  day  FFMC    DMC     DC  ...  RH  wind  rain   area  size_category\n",
              "0     mar  fri  86.2   26.2   94.3  ...  51   6.7   0.0   0.00          small\n",
              "1     oct  tue  90.6   35.4  669.1  ...  33   0.9   0.0   0.00          small\n",
              "2     oct  sat  90.6   43.7  686.9  ...  33   1.3   0.0   0.00          small\n",
              "3     mar  fri  91.7   33.3   77.5  ...  97   4.0   0.2   0.00          small\n",
              "4     mar  sun  89.3   51.3  102.2  ...  99   1.8   0.0   0.00          small\n",
              "..    ...  ...   ...    ...    ...  ...  ..   ...   ...    ...            ...\n",
              "512   aug  sun  81.6   56.7  665.6  ...  32   2.7   0.0   6.44          large\n",
              "513   aug  sun  81.6   56.7  665.6  ...  71   5.8   0.0  54.29          large\n",
              "514   aug  sun  81.6   56.7  665.6  ...  70   6.7   0.0  11.16          large\n",
              "515   aug  sat  94.4  146.0  614.7  ...  42   4.0   0.0   0.00          small\n",
              "516   nov  tue  79.5    3.0  106.7  ...  31   4.5   0.0   0.00          small\n",
              "\n",
              "[517 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Dropping columns which are not required\n",
        "\n",
        "data = data.drop(['dayfri', 'daymon', 'daysat', 'daysun', 'daythu','daytue', 'daywed', 'monthapr', 'monthaug', 'monthdec', \n",
        "                  'monthfeb','monthjan', 'monthjul', 'monthjun', 'monthmar', 'monthmay', 'monthnov','monthoct','monthsep'], \n",
        "                 axis = 1)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8A_WZxtTBJ0",
        "outputId": "f6074735-9b5e-4237-acd0-9637590fd031"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "small    378\n",
              "large    139\n",
              "Name: size_category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Checking how much datapoints are having small and large area\n",
        "data.size_category.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "oT2MIWunTBJ1",
        "outputId": "713461db-ffa7-4ae2-f001-2c8b18ba0f8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fdd16b23f50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEHCAYAAABBW1qbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAATo0lEQVR4nO3dfbRddX3n8ffHgNAWKlpumZiExkUzy0E6RrxFrDNdFKcKdDrBjlhcFVNlTbSDXWWtji12HnxYMtWllqpjadOihA4V8QGJDi1DqWJ1FTXQCAFkTAVKUh5SRB6qUIHv/HF+d3MI9yYnkH3Ozb3v11p7nb1/+7f3+d67Tu4n++H8dqoKSZIAnjHpAiRJ84ehIEnqGAqSpI6hIEnqGAqSpM5+ky7g6Tj00ENr5cqVky5DkvYp11xzzT9W1dRs6/bpUFi5ciWbNm2adBmStE9Jcttc6zx9JEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnq7NPfaN4bXvzWCyZdguaha973+kmXIE2ERwqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpI6hIEnqGAqSpE5voZDkwCRfS/KNJDckeWdrPz/JLUk2t2l1a0+SDyXZmuS6JEf3VZskaXZ9Doj3MHB8VT2YZH/gy0n+vK17a1V9aqf+JwKr2vQS4Nz2Kkkak96OFGrgwba4f5tqF5usAS5o210NHJJkaV/1SZKerNdrCkmWJNkM3A1cUVVfbavObqeIzklyQGtbBtw+tPm21rbzPtcl2ZRk044dO/osX5IWnV5DoaoerarVwHLgmCRHAW8Dng/8NPAc4Lf3cJ/rq2q6qqanpqb2es2StJiN5e6jqvou8AXghKq6o50iehj4GHBM67YdWDG02fLWJkkakz7vPppKckib/yHg54FvzlwnSBLgZGBL22Qj8Pp2F9KxwH1VdUdf9UmSnqzPu4+WAhuSLGEQPhdX1eeT/FWSKSDAZuDNrf9lwEnAVuB7wBt6rE2SNIveQqGqrgNeNEv78XP0L+CMvuqRJO2e32iWJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSp7dQSHJgkq8l+UaSG5K8s7U/L8lXk2xN8okkz2ztB7TlrW39yr5qkyTNrs8jhYeB46vqhcBq4IQkxwLvBc6pqp8E7gVOb/1PB+5t7ee0fpKkMeotFGrgwba4f5sKOB74VGvfAJzc5te0Zdr6lydJX/VJkp6s12sKSZYk2QzcDVwB/B3w3ap6pHXZBixr88uA2wHa+vuAH+uzPknSE/UaClX1aFWtBpYDxwDPf7r7TLIuyaYkm3bs2PG0a5QkPW4sdx9V1XeBLwAvBQ5Jsl9btRzY3ua3AysA2vpnAffMsq/1VTVdVdNTU1O91y5Ji0mfdx9NJTmkzf8Q8PPATQzC4dWt21rg0ja/sS3T1v9VVVVf9UmSnmy/3Xd5ypYCG5IsYRA+F1fV55PcCFyU5N3A3wLntf7nAX+aZCvwHeDUHmuTJM2it1CoquuAF83S/m0G1xd2bn8IOKWveiRJu+c3miVJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJHUNBktQxFCRJnd5CIcmKJF9IcmOSG5L8Rmt/R5LtSTa36aShbd6WZGuSm5O8sq/aJEmz26/HfT8C/GZVXZvkYOCaJFe0dedU1fuHOyc5EjgVeAHwXOAvk/zLqnq0xxolSUN6O1Koqjuq6to2/wBwE7BsF5usAS6qqoer6hZgK3BMX/VJkp5sLNcUkqwEXgR8tTW9Jcl1ST6a5NmtbRlw+9Bm25glRJKsS7IpyaYdO3b0WLUkLT69h0KSg4BPA2dW1f3AucARwGrgDuADe7K/qlpfVdNVNT01NbXX65WkxazXUEiyP4NAuLCqPgNQVXdV1aNV9Rjwxzx+img7sGJo8+WtTZI0Jn3efRTgPOCmqvq9ofalQ91eBWxp8xuBU5MckOR5wCrga33VJ0l6sj7vPnoZcBpwfZLNre13gNcmWQ0UcCvwJoCquiHJxcCNDO5cOsM7jyRpvHoLhar6MpBZVl22i23OBs7uqyZJ0q75jWZJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUsdQkCR1DAVJUmekUEhy5ShtkqR92y4HxEtyIPDDwKHtCWkzA9z9KLt+tKYkaR+0u1FS3wScCTwXuIbHQ+F+4H/1WJckaQJ2GQpV9UHgg0l+vao+PKaaJEkTMtLzFKrqw0l+Blg5vE1VXdBTXZKkCRgpFJL8KXAEsBmYeRpaAYaCJC0goz55bRo4sqqqz2IkSZM16vcUtgD/Yk92nGRFki8kuTHJDUl+o7U/J8kVSb7VXp/d2pPkQ0m2JrkuydF79qNIkp6uUUPhUODGJJcn2Tgz7WabR4DfrKojgWOBM5IcCZwFXFlVq4Ar2zLAicCqNq0Dzt3Dn0WS9DSNevroHXu646q6A7ijzT+Q5CYG321YAxzXum0Avgj8dmu/oJ2iujrJIUmWtv1IksZg1LuPrno6b5JkJfAi4KvAYUN/6O8EDmvzy4Dbhzbb1tqeEApJ1jE4kuDwww9/OmVJknYy6jAXDyS5v00PJXk0yf0jbnsQ8GngzKp6wjbtqGCPLl5X1fqqmq6q6ampqT3ZVJK0G6MeKRw8M58kDE71HLu77ZLszyAQLqyqz7Tmu2ZOCyVZCtzd2rcDK4Y2X97aJEljssejpNbAZ4FX7qpfC4/zgJuq6veGVm0E1rb5tcClQ+2vb3chHQvc5/UESRqvUb+89ktDi89g8L2Fh3az2cuA04Drk2xubb8DvAe4OMnpwG3Aa9q6y4CTgK3A94A3jFKbJGnvGfXuo18cmn8EuJXBKaQ5VdWXeXwAvZ29fJb+BZwxYj2SpB6Mek3B/7VL0iIw6t1Hy5NckuTuNn06yfK+i5MkjdeoF5o/xuBC8HPb9LnWJklaQEYNhamq+lhVPdKm8wG/JCBJC8yooXBPktclWdKm1wH39FmYJGn8Rg2FNzK4dfROBsNOvBr41Z5qkiRNyKi3pL4LWFtV98Jg+Gvg/QzCQpK0QIx6pPCvZwIBoKq+w2CAO0nSAjJqKDxj5mE40B0pjHqUIUnaR4z6h/0DwN8k+WRbPgU4u5+SJEmTMuo3mi9Isgk4vjX9UlXd2F9ZkqRJGPkUUAsBg0CSFrA9HjpbkrRwGQqSpI6hIEnqGAqSpI6hIEnqGAqSpE5voZDko+2BPFuG2t6RZHuSzW06aWjd25JsTXJzklf2VZckaW59HimcD5wwS/s5VbW6TZcBJDkSOBV4QdvmD5Is6bE2SdIseguFqvoS8J0Ru68BLqqqh6vqFmArcExftUmSZjeJawpvSXJdO700M8jeMuD2oT7bWpskaYzGHQrnAkcAqxk8rOcDe7qDJOuSbEqyaceOHXu7Pkla1MYaClV1V1U9WlWPAX/M46eItgMrhroub22z7WN9VU1X1fTUlI+JlqS9aayhkGTp0OKrgJk7kzYCpyY5IMnzgFXA18ZZmySpxwflJPk4cBxwaJJtwNuB45KsBgq4FXgTQFXdkORiBqOwPgKcUVWP9lWbJGl2vYVCVb12lubzdtH/bHxwjyRNlN9oliR1fM6yNE/9/bt+atIlaB46/H9c3+v+PVKQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHUMBUlSx1CQJHV6C4UkH01yd5ItQ23PSXJFkm+112e39iT5UJKtSa5LcnRfdUmS5tbnkcL5wAk7tZ0FXFlVq4Ar2zLAicCqNq0Dzu2xLknSHHoLhar6EvCdnZrXABva/Abg5KH2C2rgauCQJEv7qk2SNLtxX1M4rKruaPN3Aoe1+WXA7UP9trW2J0myLsmmJJt27NjRX6WStAhN7EJzVRVQT2G79VU1XVXTU1NTPVQmSYvXuEPhrpnTQu317ta+HVgx1G95a5MkjdG4Q2EjsLbNrwUuHWp/fbsL6VjgvqHTTJKkMdmvrx0n+ThwHHBokm3A24H3ABcnOR24DXhN634ZcBKwFfge8Ia+6pIkza23UKiq186x6uWz9C3gjL5qkSSNxm80S5I6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqWMoSJI6hoIkqdPb4zh3JcmtwAPAo8AjVTWd5DnAJ4CVwK3Aa6rq3knUJ0mL1SSPFH6uqlZX1XRbPgu4sqpWAVe2ZUnSGM2n00drgA1tfgNw8gRrkaRFaVKhUMD/TXJNknWt7bCquqPN3wkcNpnSJGnxmsg1BeDfVNX2JD8OXJHkm8Mrq6qS1GwbthBZB3D44Yf3X6kkLSITOVKoqu3t9W7gEuAY4K4kSwHa691zbLu+qqaranpqampcJUvSojD2UEjyI0kOnpkHXgFsATYCa1u3tcCl465Nkha7SZw+Ogy4JMnM+/9ZVf1Fkq8DFyc5HbgNeM0EapOkRW3soVBV3wZeOEv7PcDLx12PJOlx8+mWVEnShBkKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6hgKkqSOoSBJ6sy7UEhyQpKbk2xNctak65GkxWRehUKSJcBHgBOBI4HXJjlyslVJ0uIxr0IBOAbYWlXfrqp/Bi4C1ky4JklaNPabdAE7WQbcPrS8DXjJcIck64B1bfHBJDePqbbF4FDgHyddxHyQ96+ddAl6Ij+bM96evbGXn5hrxXwLhd2qqvXA+knXsRAl2VRV05OuQ9qZn83xmW+nj7YDK4aWl7c2SdIYzLdQ+DqwKsnzkjwTOBXYOOGaJGnRmFenj6rqkSRvAS4HlgAfraobJlzWYuJpOc1XfjbHJFU16RokSfPEfDt9JEmaIENBktQxFDSyJA+215VJtky6Hu3bZj5Pml8MBUnzXgb8ezUG/pIXqCQ/kuT/JPlGki1JfjnJrUl+N8nmJJuSHJ3k8iR/l+TNbbuDklyZ5Nok1ydxmBH1aq7PXDsivTnJBcAWYEWS/97avpzk40n+S+t7RJK/SHJNkr9O8vxJ/kz7snl1S6r2qhOAf6iqXwBI8izgvcDfV9XqJOcA5wMvAw5k8I/uD4GHgFdV1f1JDgWuTrKxvE1N/Zn1M9fWrQLWVtXVSX4a+I/AC4H9gWuBa1q/9cCbq+pbSV4C/AFw/Fh/igXCUFi4rgc+kOS9wOer6q+TwONfBrweOKiqHgAeSPJwkkOAfwL+Z5KfBR5jMB7VYcCdY/8JtFiE2T9zALdV1dVt/mXApVX1EPBQks/B4EgD+Bngk+0zDnDAuIpfaAyFBaqq/l+So4GTgHcnubKteri9PjY0P7O8H/ArwBTw4qr6QZJbGRxJSH3Z1Wfun0bY/hnAd6tqdU/1LSpeU1igkjwX+F5V/W/gfcDRI276LODu9o/z59jFaIrSXjLqZ+4rwC8mObAdHfx7gKq6H7glySnQXZR+4TgKX4g8Uli4fgp4X5LHgB8AvwZ8aoTtLgQ+l+R6YBPwzf5KlIARP3NV9fV2reE64C4Gp0Dva6t/BTg3yX9jcL3hIuAbfRe+EDnMhaR9RpKDqurBJD8MfAlYV1XXTrquhcQjBUn7kvXtEb0HAhsMhL3PIwVJUscLzZKkjqEgSeoYCpKkjqEgSeoYCloUkvxJu2tl3O97SJL/PO73lZ4q7z6SepRkJYOxp47q+X32q6pH+nwPLQ4eKWjBmWPY8C8mmU7yH9rQ4ZvbEMy3tG1enOSqNvTy5UmW7mL/P5nkL9v+r23DNs815Ph7gCPa+72vbf/WJF9Pcl2Sdw7td65hoVcnubr1vyTJs1v7F5P8fpJNwH9NckuS/du6Hx1elkbll9e0EM02bPivAVTVRtpIsUkuBq5qfzg/DKypqh1Jfhk4G3jjHPu/EHhPVV2S5EAG/7n6Z2Yf/vks4KiZwdqSvILBcNDHMBgddGMbHfT7zD0s9AXAr1fVVUneBbwdOLOte2ZVTbd9rwR+AfgscCrwmar6wVP8HWqRMhS0EM01bHgnyW8B36+qjyQ5CjgKuKL1WwLcMduOkxwMLKuqSwDaMM60YJlr+Odhr2jT37blgxiExMHMPiz0s4BDquqq1n8D8Mmh/X1iaP5PgN9iEApvAP7TnL8haQ6GghacXQwbDkCSfwecAvzsTBNwQ1W99Gm87ahDjgf43ar6o51qOnOWvqPohpauqq9k8LSy44AlVeVztLXHvKagBWdXw4Yn+QngI8ApVfX91nwzMJXkpa3P/kleMNu+20OJtiU5ufU9oA3ONtfwzw8wOAqYcTnwxjb0M0mWJflx5h4W+j7g3iT/tm1/GnAVc7sA+DPgY7v+LUmz80hBC9Fsw4a/v637VeDHgM+2U0X/UFUnJXk18KF2umY/4PeBG+bY/2nAH7Xz+z9gcNQx6/DPVXVPkq8k2QL8eVW9Ncm/Av6mvf+DwOt2Myz0WuAPW/h8m8GpoblcCLwb+PhovyrpibwlVZon9saw0C3c1lTVab0UqQXPIwVp/nhaw0In+TBwIoNrKdJT4pGCNIckH2HwsPhhH6wqz9drwTIUJEkd7z6SJHUMBUlSx1CQJHUMBUlS5/8DbsWLwKc6StIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(x = 'size_category', data = data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "vLUCw2xKTBJ2",
        "outputId": "fbb8d239-8ad8-48ab-e12f-dabae58eeb80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8b2f494-fd99-4c8c-9b73-e54b765c5cb4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>size_category</th>\n",
              "      <th>large</th>\n",
              "      <th>small</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>area</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.00</th>\n",
              "      <td>0</td>\n",
              "      <td>247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.09</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.17</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.21</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.24</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200.94</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212.88</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278.53</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>746.28</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1090.84</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>251 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8b2f494-fd99-4c8c-9b73-e54b765c5cb4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8b2f494-fd99-4c8c-9b73-e54b765c5cb4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8b2f494-fd99-4c8c-9b73-e54b765c5cb4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "size_category  large  small\n",
              "area                       \n",
              "0.00               0    247\n",
              "0.09               0      1\n",
              "0.17               0      1\n",
              "0.21               0      1\n",
              "0.24               0      1\n",
              "...              ...    ...\n",
              "200.94             1      0\n",
              "212.88             1      0\n",
              "278.53             1      0\n",
              "746.28             1      0\n",
              "1090.84            1      0\n",
              "\n",
              "[251 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Checking for which value of area is categorised into large and small by creating crosstab between area and size_category\n",
        "pd.crosstab(data.area, data.size_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "DsYAOTUNTBJ3",
        "outputId": "57a8c766-3888-496c-d0e5-68564d7c66ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJkAAAJqCAYAAACIHJGmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdfZxWdYE3/s/MwJADqDyMgnr7sGokAgK6sLegJCmbKJqu2roVtZUrVNam2a1pa7ilWaKF4NYqYYK6CKkraZulbj70oOz4kC3iXSKmtxmMEjAMz/z+6OdsEw9eeGauawbf79eL1/E651xnPtfXS4WP3/M9VVu2bNkSAAAAACigutIBAAAAAOj8lEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAGC7rrvuugwYMCAjRozI+vXrtzr+5S9/OQMGDMjYsWPbLcMdd9yRu+66a6v9F110UU444YSdvt6ECRNy5plnbvf4ggULMmDAgPz85z/f6Wv/4he/yIABA9701x133LHT1y6XP886YsSInH322fnJT35SkTx33HFHBgwYkN/97nc79b5Fixbluuuuy+rVq9spGQDw57pUOgAA0LFVV1dn/fr1eeihh3L88ce37N+4cWPuvffedO/evV1//p133pmampq8733va5PrnXrqqfn617+epUuX5oADDtjq+IIFC9K/f/+MHDlyp699+OGHZ+7cuS2vX3vttUyePDmTJ0/Ou9/97pb9+++//1vKXi7vf//7c/rppydJXn/99dx2222ZPHlybrnllgwbNqzC6UqzaNGiTJ8+PWeeeWZ69OhR6TgA8LZgJhMAsENVVVV5z3vek7vvvrvV/kcffTSrV6/OMcccU6Fkb82ECRNSXV291edJ/lgKPfroozn55JNTVVW109fu0aNHhg4d2vJr4MCBSf5YKv3p/t69exf+HO2pX79+LVmPO+64TJ8+PbW1tfnxj39c+NqbN2/Oxo0b2yAlANDRKJkAgDd1yimn5D//8z9b3Xp0991357jjjtvmLJHf/e53Of/88zNixIgMGTIkZ5xxxla3W71xu9tTTz2Vs846K0cccUTGjx+f++67r+WcD33oQ3nsscfys5/9rOX2rYsuuqjVdXb0/m3Ze++9M3LkyCxYsGCrY/fee282btyYU089tWXfnXfemQkTJuSII47IUUcdldNPP71w2XLvvffm9NNPz5AhQzJy5Mh84QtfyB/+8IeW4y+99FIGDBiQefPm5Stf+UpGjhyZo446KldccUU2b96chQsX5owzzsjQoUNz+umn51e/+lWr6w8YMCDTp0/PNddck6OPPjpDhw7Neeedl+XLl7+lvLW1tamtrW1VDi1fvjyXXnppTjjhhAwZMiRjx47NF7/4xaxYsaLVe8eOHZtLLrkkc+bMyQknnJBBgwblueeea7kNbuHChfnoRz+aI444Isccc0xuuOGGN82zfv36XH311RkzZkwGDRqUcePG5Tvf+U62bNmS5I+32F188cVJkjFjxrR8dwCA9qVkAgDe1KhRo9K9e/f8x3/8R5JkzZo1eeCBBzJhwoStzl29enVLOXTRRRdl2rRp6dOnTyZNmpSHH3641bkrVqzIxRdfnPe///2ZMWNG9tlnn/zjP/5jli5dmiS57LLLMnDgwAwePDhz587N3Llz84lPfKLk92/PqaeemqVLl+app55qtf/uu+/OwIEDc+ihhyZJHn/88Vx00UU5+uij861vfStTp07Ne9/73qxcuXLnB/H/d8stt+T888/PkCFDMmPGjFx00UV5+OGHc+6552bz5s2tzp0xY0bWrVuXqVOn5sMf/nC++93v5oorrshll12WD33oQ/nGN76R9evX57zzzttqdtDtt9+eX/7yl/nKV76SSy65JI899lg+9alPlZTxjdlGGzduzLJly3L11Vdn9erVGTduXMs5K1asSF1dXT7/+c9n5syZ+fSnP52FCxfm4x//+FbX+8lPfpI777wzF1xwQb797W9nr732ajn2uc99LkOHDs2MGTMybty4XH311fm3f/u3Heb7/Oc/n5tuuilnn312vvWtb2Xs2LG56qqr8o1vfCNJ8u53vzuTJ09OkvzLv/xLy3cHAGhf1mQCAN5Uly5dMn78+CxYsCBnnHFG7rvvvnTt2jXHHntsHnzwwVbn3nnnnXnxxRczb968DBkyJEly7LHH5uSTT851113X6va6lStXZubMmS3nDRw4MKNGjcp9992Xc845J4ccckh69OiRmpqaDB06dKtcb/b+7Rk3blymTJmSBQsW5IgjjkiSvPjii3nqqadazZR6+umns8cee7TMikn+ODPmrWpqaso111yTD3zgA/niF7/Ysn///ffP3/3d3+Xhhx9udf13vetdufzyy5Mko0ePzoMPPpjZs2fnjjvuyOGHH54k2bJlSyZNmpRnnnmm1Rht3rw53/72t1NbW5sk6d27dz7xiU/kkUceyejRo3eY87rrrst1113X8rpr16754he/mCOPPLJl3yGHHJIvfOELLa+HDRuWAw88MO9///vzq1/9qiVfkjQ3N2fWrFnZfffdt/pZ733ve/PpT3+65TO++uqruf7663PWWWelunrr/x+6ePHi/OAHP8iFF17YUmiNHj06a9asyaxZs/Kxj30svXv3bln3auDAgenXr98OPy8A0DbMZAIASjJhwoQ89thjefXVV7NgwYK8973vbSkw/tTjjz+eAw44oKX4Sf64ePiJJ56YX/7yl1m3bl3L/j333LPVeb17906fPn3yyiuvlJTprb6/e/fuec973pN77703mzZtSvLHWUw1NTU5+eSTW84bNGhQ/vCHP+TCCy/MQw89VPhJZU8++WRWr16dk046qWWm0MaNG3PEEUeke/fu+a//+q9W548aNarV64MOOih77rlnqwLnwAMPTJKtnr42duzYVn9/3nj95JNPvmnOs88+O/Pnz8/8+fMza9asnH322bn88svz7//+7y3nbNmyJXPmzMmECRMydOjQHH744Xn/+9+fJHnhhRdaXe+oo47aZsGUJH/913+91etXX311u0+TW7hwYZJsNYvupJNOyrp16/L000+/6ecDANqHmUwAQEmGDh2a/fbbLzfddFN+9rOf5bvf/e42z1u5cmX69u271f6+fftm8+bNWbVqVbp165Yk2yweamtrWxVRO1Lk/aecckq+//3v55FHHsmYMWOyYMGC/O///b9TX1/fcs7IkSNz7bXXZvbs2Zk0aVKqq6szZsyYXHLJJdlnn31KyvinGhsbk/yxxNmWP1/P6M8/X9euXbe5L8lWn/nPFxevqqpK7969s2zZsjfNuddee2Xw4MEtr48++uj89re/zVVXXZVTTjklVVVVufnmm3PFFVfkwx/+cD73uc+lV69eWbZsWT7xiU9slaVPnz7b/Vl/fuyN786yZcu2OcZvrF21vfcVuZURAChGyQQAlGzChAn5l3/5l/Tr1y9HHXXUNs/Zfffd8+yzz261f/ny5amurk7Pnj3bO2ZJRo8enb59+2bBggXp1atXXnjhhVbrPb1h/PjxGT9+fFatWpWHH344X/3qV3PhhRfmlltu2emfucceeyRJrrnmmpbbuf5UWz517rXXXmv1esuWLXnttddalWg74+CDD86DDz6YxsbG9O3bNz/4wQ8yevToVrfMvTHL6M/t6El9jY2NrcbijcXJt5fzjTFsbGzM3nvvvdX73jgOAJSf2+UAgJK9733vy3HHHZdzzz13u8XBX/7lX2bp0qV55plnWvZt3rw5//Ef/5HBgwe3zGIq1c7MbNoZNTU1GT9+fO6///7MnTs3dXV1OeGEE7Z7fs+ePTN+/PiceOKJ+b//9/++pZ955JFHpq6uLi+99FIGDx681a999933rX6crTzwwANZv379Vq+3tbZVKZ577rl07dq1pSRcu3ZtyyyqN9x11107fd0f/vCHW73u16/fdtdReqPcvOeee1rtv/fee9OtW7eWGVhv3CrYHt8dAGDbzGQCAEq2//775/rrr9/hOaeffnpuvvnmTJ48Oeeff3569eqVf/u3f8vzzz+ff/3Xf93pn/kXf/EXmTdvXn70ox+lX79+6dWrV/bbb7+3+hFaOfXUU3PzzTfne9/7Xk455ZTU1dW1Oj5t2rQ0NjZm5MiRqa+vz9KlS3P33XdvtVZSqXr06JHPfe5zufLKK7Ns2bKMGjUq73jHO/LKK6/k0UcfzQc+8IEMHz68LT5aqqurc+6552bixIlZvnx5rr766gwbNuxNF/1O/ri+0xtrN61cuTI/+clP8tBDD+Vv//ZvW0rC0aNHZ+bMmbnxxhtz2GGH5cEHH8zPf/7znc75wx/+MHV1dRk+fHj+8z//Mz/60Y9y+eWXb3PR7yQZMGBATjzxxFxzzTXZsGFDBg0alEceeSRz587Nueee23I74cEHH5zkj0/zGz9+fGpqalrdAggAtD0lEwDQprp3757Zs2fna1/7Wq644oqsXbs2AwYMyLe+9a1WT5Yr1cc//vG89NJLufTSS7NixYqcdtpp+epXv9omWQcNGpSDDz44v/nNb3LKKadsdXzIkCH57ne/mx/96EdZuXJl9tprr0yYMKHlaWhvxQc+8IH069cvM2fOzPe+970kSb9+/XL00Ue3WXmWJGeddVbWr1+fL3zhC1mzZk2OOeaYXHbZZSW9d+7cuZk7d26SpK6uLvvvv38uvfTSVmtJffKTn8wf/vCH3HDDDdmwYUNGjx6da6+9NmecccZO5fz617+e66+/PjNnzkzPnj1zwQUXtCwgvj1f+9rX8s1vfjO33nprGhsbs88+++Tzn/98/v7v/77lnMMOOyz/+I//mNtvvz1z5szJpk2bsnjx4p3KBgDsnKotW7ZsqXQIAADazoABA/KZz3xmm2tMdRR33HFHLr744vzkJz/Z7q1xAEDnYk0mAAAAAApTMgEAAABQmNvlAAAAACjMTCYAAAAAClMyAQAAAFCYkgkAAACAwrpUOkB7ev31pmzebMkpAAAAgKKqq6vSq1f37R7fpUumzZu3KJkAAAAAysDtcgAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAsNMaGhZmypRL0tCwsNJRAIAOokulAwAA0PnMm3drlix5PmvXNmf48KMqHQcA6ADMZAIAYKc1N69ttQUAUDIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQCdXkPDwkyZckkaGhZWOgoAwNtWl0oHAAAoat68W7NkyfNZu7Y5w4cfVek4AABvS2YyAQCdXnPz2lZbAADKT8kEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAACgE2hoWJgpUy5JQ8PCSkcBgG3qUukAAADAm5s379YsWfJ81q5tzvDhR1U6DgBsxUwmAADoBJqb17baAkBHo2QCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhni4HANAJdN/9Hanr1rXSMVrU1FS1bOvre1Y4TWtr1m1I00qLYwNAuSmZAAA6gbpuXdPvsjmVjtHikMZV6Zbk+cZVHSpXkvxuygfTFCUTAJSb2+UAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIV1qXQAAADoiLrv8Y7U1XatdIwWNTVVLdv6+p4VTtPamvUb0vSHtZWOAUCFKZkAAGAb6mq7Zu+pN1Q6RotDX1+Zbkmef31lh8qVJK9ecE6aomQCeLtzuxwAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMAADQCWzu0qXVFgA6GiUTAAB0Aq++c3BW994rr75zcKWjAMA2+d8gAADQCazea5+s3mufSscAgO0ykwkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFdKh0AAOh8uu++W+q6dZzfRtTUVLVs6+t7VjhNa2vWbUzTyuZKx2hzm2u6ttoCAHSc3x0CAJ1GXbcu6X/+/ErHaHHwstXpluT5Zas7VK4keeWaM9JU6RDt4PcHDEvfl5/J8n0HVToKANBBKJkAANhpq3v/r6zu/b8qHQMA6ECsyQQAAABAYUomAACAbWhoWJgpUy5JQ8PCSkcB6BTcLgcAALAN8+bdmiVLns/atc0ZPvyoSscB6PDMZAIAANiG5ua1rbYA7FhZS6YbbrghZ555Zo488siMGDEiH/nIR/LEE09sdd7999+fCRMmZNCgQRk3blzmz+9YT4kBAAAAoLWylkyPPfZYzjrrrNxyyy257bbb0r9//3z0ox/N0qVLW8556qmnct5552XcuHH593//90ycODH/9E//lB//+MfljAoAAADATijrmkw33HBDq9df+cpX8sADD+Shhx7Khz70oSTJTTfdlCOPPDLnnXdekuTggw/OU089lRtvvDHHH398OeMCAAAAUKKKrsm0bt26rF+/PrvvvnvLvieeeCKjR49udd4xxxyTZ555Jhs2bCh3RAAAAABKUNGny33ta1/L7rvvnve85z0t+5YvX54+ffq0Oq++vj4bNmzI66+/nr322qvk6/fp06PNsgIAvFX19T0rHeFtx5iX36445jU1VS3bXfHzAbS1ipVM119/fb7//e9n1qxZ6dGjfcqgxsbV2bx5S7tcGwDezvxha+csW7aq8DWM+c4x5uXXFmPe0WzatKVluyt+PoCdVV1dtcMJPRUpmaZNm5bZs2fnO9/5TgYNGtTqWN++fdPY2Nhq3/Lly9OlS5f06tWrnDEBAAAAKFHZ12T6+te/njlz5mTWrFkZPHjwVseHDRuWRx99tNW+hx9+OIMHD07Xrl3LFRMAAACAnVDWkumf//mfc+utt+bqq6/O3nvvnWXLlmXZsmVZtep/pp5+5CMfycKFCzN9+vQ8//zzueWWW/L9738/H//4x8sZFQAAAICdUNbb5ebMmZMkOeecc1rtP+200/LVr341SXLEEUdk2rRp+cY3vpFvfetb6devX6ZMmZLjjz++nFEBAAAA2AllLZkWL15c0nnHH3+8UgkAAACgEyn7mkwAAAAA7Hoq8nQ5AACAP9d9j3ekrrbjPOynpqaqZVtf37PCaVpbs35Dmv6wttIxAFpRMgEAAB1CXW3X7H3j9ErHaHHoyhXpluT5lSs6VK4kefXjn0pTlExAx+J2OQAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAANuwuUvXVlsAdkzJBAAAsA2vDj4sq/fqm1cHH1bpKACdQpdKBwAAAOiIVu/bL6v37VfpGACdhplMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAB0CA0NCzNlyiVpaFhY6SjAW9Cl0gEAAAAgSebNuzVLljyftWubM3z4UZWOA+wkM5kAAADoEJqb17baAp2LkgkAAACAwpRMAAAAABSmZAIAOr3NNV1bbQEAKD8lEwDQ6S3rNyJN3ffJsn4jKh0FAOBty9PlAIBOb/XuB2T17gdUOgYAwNuamUwAAAAAFKZkAgAAAKAwJRMAtLGGhoWZMuWSNDQsrHQUAAAoG2syAUAbmzfv1ixZ8nzWrm3O8OFHVToOAACUhZlMANDGmpvXttoCAMDbgZIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFNal0gEAAACojO57viN1XbtWOkaLmpqqlm19fc8Kp2ltzYYNaVqxttIxoENTMgEAALxN1XXtmv7zr610jBYHr16RbkmeX72iQ+VKklfO+GyaomSCHXG7HAAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAA0CFs7tql1RboXJRMAAAAdAjLRrwzTfv0ybIR76x0FOAtUA8DAADQIaw+YO+sPmDvSscA3iIzmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAACis7CXT448/nkmTJmX06NEZMGBA7rnnnlbH77jjjgwYMGCrX0uXLi13VAAAAABK1KXcP3DNmjUZMGBA/uZv/iaf+tSntnlObW1tHnjggVb7evfuXY54AAAAALwFZS+ZxowZkzFjxrzpefX19WVIAwAAAEBbKHvJVIoNGzZk7Nix2bBhQw499NBMnjw5f/mXf1npWAAAAABsR4crmQ466KBcccUVede73pXm5ubMmzcvEydOzOzZs3PUUUft1LX69OnRTikBYPtqaqpatvX1PSucho7A96D8jHn5GfPyM+blZ8xhxzpcyTRs2LAMGzas5fWRRx6Z3/3ud5k5c+ZOl0yNjauzefOWto4IADu0adOWlu2yZasqnKZ9+E32zmmL74Ex3znGvPyMefkZ8/LbVf+7DqWqrq7a4YSesj9d7q0YOnRoXnjhhUrHAAAAAGA7OkXJ9N///d8WAgcAAADowMp+u1xTU1NefPHFltcvv/xyFi1alLq6uhxwwAGZPn16hgwZkgMPPDBr1qzJ/Pnz89BDD2XGjBnljgoAAABAicpeMj3zzDOZOHFiy+upU6dm6tSpGTFiRGbPnp1Vq1blS1/6UpYtW5a6urq8853vzHe+850cffTR5Y4KAAAAQInKXjKNHDkyixcv3u7xiy++OBdffHEZEwEAAABQVId7uhwAbauhYWEWLLgzEyacluHDd+4pnZ1F9913S123jvOftJqaqpZtR3tqz5p1G9O0srnSMQAA2AXt1O/IH3744SxcuDArVqzIpEmT0r9//zz55JPZb7/90rdv3/bKCEAB8+bdmiVLns/atc27bMlU161L9v34PZWO0eIvXm1KbZIlrzZ1qFxJ8vKNJ6Wp0iEAANgllVQyrVy5MpMmTUpDQ0O6d++eNWvW5Kyzzkr//v0ze/bs9OrVK5deeml7ZwXgLWhuXttqCwAA0B6qSznpqquuyksvvZTbbrstv/jFL7Jly5aWY6NGjcrPfvazdgsIAAAAQMdXUsl0//335/zzz8+wYcNSVVXV6tg+++yTV155pV3CAQAAANA5lFQyNTc3p76+fpvH1q51+wUAAADA211JJdMhhxySBx54YJvHHnnkkQwcOLBNQwEAAADQuZS08PfHPvaxXHDBBamurs5JJ52UJHnxxRfz6KOPZu7cuZk2bVq7hgQAAACgYyupZBo/fnxef/31XHvttZkzZ06S5LOf/Wzq6upy8cUX57jjjmvXkAAAAAB0bCWVTKtWrcqZZ56Z0047LU8++WQaGxuzxx57ZPjw4enRo0d7ZwQAAACgg3vTkmnjxo0ZOXJkZsyYkeOOOy5HH310OXIBAAAA0Im86cLfXbp02e6T5QAAAAAgKfHpcmeccUZuvfXWbN68ub3zAAAAANAJlbQmU3V1dRYvXpz3vve9OfbYY9OnT59UVVW1HK+qqsq5557bbiEBAAAA6NhKKpmuu+66lr9+4+lyf0rJBAAAAPD2VlLJ9Oyzz7Z3DgAAAAA6sZLWZAJoKw0NCzNlyiVpaFhY6SgAAAC0oZJmMjU0NLzpOcOHDy8cBtj1zZt3a5YseT5r1zZn+PCjKh0HAACANlJSyfR3f/d3rRb63pZFixa1SSBg19bcvLbVFgAAgF1DSSXTzTffvNW+FStW5MEHH8xjjz2Wf/qnf2rzYAAAAAB0HiWVTCNGjNjm/nHjxuWKK67Ij3/844wZM6ZNgwEAAADQeRRe+Pvd7353fvjDH7ZFFgAAAAA6qcIl05IlS1JbW9sWWQAAAADopEq6Xe6uu+7aat+GDRvy3HPPZf78+TnttNPaPBgAAAAAnUdJJdNFF1201b7a2tr0798/H/nIRzJp0qQ2DwYAAABA51FSyfTss8+2dw4AAAAAOrGS1mR6/PHH09TUtM1jTU1Nefzxx9s0FAAAAACdS0kl08SJE/Ob3/xmm8eWLFmSiRMntmkoAAAAADqXkkqmLVu2bPfY2rVr061btzYLBAAAAEDns901mZ577rksXry45fUjjzySpUuXtjpn3bp1ueeee7L//vu3X0IAAAAAOrztlkz33Xdfpk+fniSpqqrKtGnTtnneHnvskauuuqp90gEAAADQKWy3ZPrwhz+c0047LVu2bMnxxx+f6dOn57DDDmt1Tm1tbfr27Zuqqqp2DwoAAABAx7XdkrhQ5KgAACAASURBVKlnz57p2bNnkuT+++9PfX19amtryxYMAAAAgM5juyXTn9p3331b/rqxsTHr1q3b6px99tmn7VIBAAAA0KmUVDJt2rQp1157bW6//fasWrVqm+csWrSoTYMBAAAA0HmUVDJ95zvfydy5c/MP//APmTp1aj75yU+muro63//+97Np06ZMnjy5vXMCb1H3nrul7h0l/aNeFjU1VS3b+vqeFU7T2pq1G9O0qrnSMQAAADqlkv7kedddd+VTn/pUPvjBD2bq1KkZO3ZsDj/88EyePDnnnHNOnn/++fbOCbxFde/okv914k8rHaPFgevXpjbJkpfXdqhcSfLbHxydpm1P1gQAAOBNVJdy0ssvv5yBAwempqYmXbp0abllrrq6Oh/84Adz1113tWtIAAAAADq2kkqm3XffPc3Nf7yFZO+9987ixYtbjjU1NaWpqal90gEAAADQKZR0u9wRRxyRZ599Nscee2xOOOGEzJgxIxs2bEiXLl0yc+bMDBs2rL1zAgAAANCBlVQynXPOOXn55ZeTJJ/85Cfz29/+Ntdee202bdqUI444IlOmTGnXkAAAAAB0bCWVTEOGDMmQIUOSJD179syMGTOyfv36rF+/Pj169GjXgAAAAAB0fG+6JtP69eszYsSI3H///a3219bWKpgAAAAASFJCyVRbW5suXbqktra2HHkAAAAA6IRKerrc+PHjc/fdd7d3FgAAAAA6qZLWZBowYECuu+66TJw4Mccdd1z69OmTqqqqVudMmDChXQICAAAA0PGVVDJ98YtfTJL8/ve/z2OPPbbV8aqqKiUTAAAAwNtYSSXTny/6DQAAAAB/qqSSad99923vHAAAAAB0YiWVTG94+OGHs3DhwqxYsSKTJk1K//798+STT2a//fZL37592ysjAAAAAB1cSSXTypUrM2nSpDQ0NKR79+5Zs2ZNzjrrrPTv3z+zZ89Or169cumll7Z3VgAAAAA6qOpSTrrqqqvy0ksv5bbbbssvfvGLbNmypeXYqFGj8rOf/azdAgK7ls1V3VptAQAA2DWUVDLdf//9Of/88zNs2LBUVVW1OrbPPvvklVdeaZdwwK6nsWZs1lQdlMaasZWOAgAAQBsq6Xa55ubm1NfXb/PY2rVr2zQQsGtrqh6QpuoBlY4BAABAGytpJtMhhxySBx54YJvHHnnkkQwcOLBNQwEAAADQuZQ0k+ljH/tYLrjgglRXV+ekk05Kkrz44ot59NFHM3fu3EybNq1dQwIAAADQsZVUMo0fPz6vv/56rr322syZMydJ8tnPfjZ1dXW5+OKLc9xxx7VrSAAAAAA6tpJKpiT5wAc+kNNOOy1PPPFEXnvtteyxxx4ZPnx4evTo0Z75ADqd7j13S907Sv7Xa7urqalq2dbX96xwmtbWrN2YplXNlY4BAAC0gZ36U1BdXV1GjRrVXlkAdgl17+iS/c7a9jp2lXDQ682pTbLkleYOlStJXrp9bJpWVToFAADQFkoumV5//fXcdNNNeeqpp7Js2bLU19dn6NCh+fCHP5xevXq1Z0YAAAAAOriSni739NNPZ9y4cbnppptSU1OTww8/PDU1NZk1a1bGjRuXX/7yl+2dEwAAAIAOrKSZTP/8z/+c/fffPzfccEN69+7dsr+xsTHnnHNOvvzlL2fu3LntFhIAAACAjq2kmUyLFy/O5MmTWxVMSdKnT5984hOfyKJFi9olHAAAAACdQ0kzmfr375/169dv89i6devSv3//Ng0FAAAAu6Lue74jdV27VjpGp7Bmw4Y0rVhb6RjshJJKpvPOOy/f/OY3c+ihh+bQQw9t2f/cc89l2rRp+cxnPtNuAQEAAGBXUde1a/Z74GuVjtEpvDT282mKkqkzKalk+t73vpempqaccsopOfDAA9OnT580NjbmhRdeSN++fTN//vzMnz8/SVJVVZWZM2e2a2gAAAAAOpaSSqaNGzfmoIMOykEHHdSyr2/fvunbt2+SZMOGDe2TDgAAAIBOoaSSafbs2e2dAwAAAIBOrKSnywEAAADAjpQ0kylJli5dmvvuuy+vvvpq1q1b1+pYVVVVLr/88jYPBwAAAEDnUFLJdNddd+WSSy5JkvTu3Ttd/+xxi1VVVW2fDAAAAIBOo6SSacaMGTn++OPz5S9/OT179mzvTAAAAAB0MiWtydTY2Ji//du/VTCxy2loWJgpUy5JQ8PCSkcBAACATq2kkumv/uqv8uyzz7Z3Fii7efNuzaJFv8q8ebdWOgoAAAB0aiXdLvelL30pn/zkJ1NdXZ1Ro0Ztc0bT3nvv3ebhoL01N69ttQVoC5ura1ttAQDg7aCkkqlr167p06dPrrzyyu0u8r1o0aI2DQYAndWyXken9x8W5rU9jqp0FAAAKJuSSqb/83/+T5544on8/d//fQ466KCtni4HAPyPprq/SFPdX1Q6BgAAlFVJJdNjjz2WL33pS3nf+97X3nkAAAAA6IRKWvi7b9++2XPPPds7CwAAAACdVEkl0z/8wz9k1qxZWb9+fXvnAQAAAKATKul2uaeffjovvvhixo4dm+HDh2ePPfZodbyqqiqXX355uwQEAAAAoOMrqWT66U9/mqqqqtTW1uaZZ57Z6vj2njgHAAAAwNtDSSXTAw880N45AAAAAOjESlqTCQAAAAB2pOSSadmyZZk6dWrOPvvsnHjiifn1r3+dJLnlllvyy1/+st0CAgAAANDxlVQy/frXv87JJ5+cefPmZY899sgLL7yQdevWJUleeOGF3HTTTe2ZEQAAAIAOrqSS6corr8zBBx+c+++/P9OnT8+WLVtajg0fPjxPPvlkuwUEAAAAoOMrqWRqaGjIOeeck+7du2/1JLm+fftm+fLl7RIOAAAAgM6hpJKppqYmmzZt2uaxxsbG7Lbbbm0aCgAAAIDOpaSSadiwYbntttta3Sb3xoymu+66KyNGjGifdAAAAAB0CtstmS6++OL89re/TZJ85jOfycKFC/M3f/M3mTlzZqqqqnLPPffknHPOyS9+8Yucd955ZQsMAAAAQMez3ZLpzjvvzOuvv54kGTRoUObMmZMePXrkm9/8ZrZs2ZJZs2alubk5s2fPzqGHHlq2wAAAAAB0PF1KPXHw4MG5+eabs27duqxYsSK77767tZgAAAAASLITJdMbunXrlr333rs9sgAAAADQSe2wZLr++uvTq1evN71IVVVVrrjiijYLBQAAAEDnssOS6dlnn01tbe2bXuSNJ80BAAAA8Pa0w5Jp2rRpGTJkSLmyAAAAANBJbffpcgAAAABQqrKXTI8//ngmTZqU0aNHZ8CAAbnnnnu2OqehoSFnnnlmBg8enDFjxuTb3/52uWMCAAAAsBPKXjKtWbMmAwYMyGWXXbbN4y+//HI+9rGP5bDDDsudd96ZCy+8MNdff32++93vljkpAAAAAKXa7ppMzz77bLv8wDFjxmTMmDHbPX7bbbeld+/emTJlSqqqqnLIIYfk17/+dWbOnJmJEydaZBwAAACgA+pwazI98cQTGTVqVKsy6Zhjjsmrr76al19+uYLJAAAAANieHT5drhKWL1+eESNGtNpXX1+fJFm2bFn222+/kq/Vp0+PNs3GrqempqplW1/fs8Jp6Ah8D8rPmJefMS8/Y15+xrz8jHn5GfPyM+blZ8w7lw5XMrWlxsbV2bx5S6Vj0IFt2rSlZbts2aoKp2kf/qW8c9rie2DMd44xLz9jXn7GvPyMefkZ8/Iz5uVnzMtvV/1zWmdVXV21wwk9He52ub59+6axsbHVvuXLlyf5nxlNAAAAAHQsHa5kGjZsWH7605+22vfwww9n7733zr777luhVAAAAADsSNlLpqampixatCiLFi1Kkrz88stZtGhRli5dmiQ5++yz09jYmC996Uv5zW9+k3vuuSezZs3KRz/6UU+WAwAAAOigyr4m0zPPPJOJEye2vJ46dWqmTp2aESNGZPbs2dl3331z44035sorr8ypp56a3r17Z9KkSfnIRz5S7qgAAAAAlKjsJdPIkSOzePHiHZ5z5JFHZv78+WVKBAAAAEBRHW5NJgAAAAA6n7LPZOLtrXuPutTtVlPpGC1qaqpath3tUaJrmjelafWaSscAAACAkiiZKKu63Wqy/+gnKh2jxQFd16W2Olny23UdKleSvPjIsDStrnQKAAAAKI3b5QAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAu7jNVbWttgAAAO1ByQSwi1ted2zWdDkgy+uOrXQUAABgF9al0gEAaF9NtYemqfbQSscAAAB2cWYyAQAAAFCYkgkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMvK1tTrdWWwAAAOCtUTLxtta46a+zZvPBadz015WOAgAAAJ1al0oHgEpas3lg1mweWOkYAAAA0OmZyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZkAAAAAKEzJBAAAAEBhSiYAAAAAClMyAQAAAFCYkgkAAACAwpRMAAAAABSmZAIAAACgMCUTAAAAAIUpmQAAAAAoTMkEAAAAQGFKJgAAAAAKUzIBAAAAUJiSCQAAAIDClEwAAAAAFKZkAgAAAKAwJRMAAAAAhSmZAAAAAChMyQQAAABAYUomAAAAAApTMgEAAABQmJIJAAAAgMKUTAAAAAAUpmQCAAAAoDAlEwAAAACFKZk6kIaGhZky5ZI0NCysdBQAAACAndKl0gH4H/Pm3ZolS57P2rXNGT78qErHAQAAACjZ27pk6tGjLrvtVlPpGC3Wr1/Xsq2v71nhNK01N2/K6tVrKh0DAAAA6KA6ZMl03XXXZfr06Vvt/9WvfpUuXdou8m671eTAIc+22fWK2m/P6nTrmjz/QnWHypUkLzz9rqxeXekUAAAAQEfVIUumJDnggANyyy23tNrXlgVTR/TampOz524/zorm4ysdBQAAAGCndNjWprq6OvX19ZWOUVZr1g/KmvWDKh0DAAAAYKd12JLp//2//5djjz02NTU1Oeyww/LpT38673rXuyodCwAAAIBt6JAl05AhQ3LllVfm4IMPzooVKzJr1qycffbZueuuu3LAAQeUfJ0+fXq0Y8q3n462GPnbgTEvP2Nefsa8/Ix5+Rnz8jPm5WfMy8+Yl58xL79dccx//vOf5/bbb89ZZ52Vv/qrv6p0nDbVIUumMWPGtHp95JFHZsKECZk9e3YuvfTSkq/T2Lg6mzdv2e7xXfHL2p6WLVtV+BrGfOcY8/Iz5uVnzMvPmJefMS8/Y15+xrz8jHn5GfPya4sx72huvHFmlix5PitXrsrBBx9e6Tg7pbq6aocTeqrLmOUt69q1awYPHpwXXnih0lEAAAAA3rLm5rWttruSTlEybd68Oc8+++zbbiFwAAAAgM6iQ94u99WvfjXHHXdc9tlnn5Y1mZYsWZIrr7yy0tEAAAAA2IYOWTL9/ve/z4UXXpjXXnste+65ZwYOHJjbbrstgwYNqnQ0AAAAALahQ5ZM11xzTaUjAAAAALATOsWaTAAAAAB0bEomAAAAAApTMgEAAABQmJIJAAAAgMI65MLfAAAAAG2he69uqetSW+kYLWpqqlq29fU9K5ymtTUb16fp9f+vvXuPq6LO/zj+xgQ1FC/gNY2H4nLcFBUh0VJay0urkclq1gabiXmpzNJ6gHfdtcx7iZrZjcK7lnhDM0tNzc0bWraua3jDtVYRSxEQifn90cPz64jKwTkwHHg9H48ePc73zHz5fL8zzpzzZma4ctvrEzIBAAAAAIAy686KXvI/8JrVZdjdfSVDXpKOX8koVXVJ0snWo3VZtx8ycbscAAAAAAAATCNkAgAAAAAAgGmETAAAAAAAADCNkAkAAAAAAACmETIBAAAAAADANEImAAAAAAAAmEbIBAAAAAAAANMImQAAAAAAAGAaIRMAAAAAAABMI2QCAAAAAACAaYRMAAAAAAAAMI2QCQAAAAAAAKYRMgEAAAAAAJSQ/MoVHf5flhAyAQAAAAAAlJCMbo2VFVBDGd0aW12Ky5W92AwAAAAAAKCUyrrHT1n3+FldRrHgSiYAAAAAAACYRsgEAAAAAAAA0wiZAAAAAAAAYBohEwAAAAAAAEwjZAIAAAAAAIBphEwAAAAAAAAwjZAJAAAAAAAAphEyAQAAAAAAwDRCJgAAAAAAAJhGyAQAAAAAAADTCJkAAAAAAABgGiETAAAAAAAATCNkAgAAAAAAgGmETAAAAAAAADCNkAkAAAAAAACmETIBAAAAAADANEImAAAAAAAAmEbIBAAAAAAAANMImQAAAAAAAGAaIRMAAAAAAABMI2QCAAAAAACAaYRMAAAAAAAAMI2QCQAAAAAAAKYRMgEAAAAAAMA0QiYAAAAAAACYRsgEAAAAAAAA0wiZAAAAAAAAYBohEwAAAAAAAEwjZAIAAAAAAIBphEwAAAAAAAAwjZAJAAAAAAAAphEyAQAAAAAAwDRCJgAAAAAAAJhGyAQAAAAAAADTCJkAAAAAAABgGiETAAAAAAAATCNkAgAAAAAAgGmETAAAAAAAADCNkAkAAAAAAACmETIBAAAAAADANEImAAAAAAAAmEbIBAAAAAAAANMImQAAAAAAAGAaIRMAAAAAAABMI2QCAAAAAACAaYRMAAAAAAAAMI2QCQAAAAAAAKYRMgEAAAAAAMA0QiYAAAAAAACYRsgEAAAAAAAA0wiZAAAAAAAAYBohEwAAAAAAAEwjZAIAAAAAAIBphEwAAAAAAAAwjZAJAAAAAAAAphEyAQAAAAAAwDRCJgAAAAAAAJhGyAQAAAAAAADTCJkAAAAAAABgGiETAAAAAAAATCNkAgAAAAAAgGmETAAAAAAAADCNkAkAAAAAAACmETIBAAAAAADANEImAAAAAAAAmEbIBAAAAAAAANMImQAAAAAAAGAaIRMAAAAAAABMI2QCAAAAAACAaYRMAAAAAAAAMI2QCQAAAAAAAKYRMgEAAAAAAMA0QiYAAAAAAACYRsgEAAAAAAAA0wiZAAAAAAAAYBohEwAAAAAAAEwjZAIAAAAAAIBppTJk+uKLLxQREaEWLVqoa9euWrlypdUlAQAAAAAA4BZKXch08OBBDR06VF27dtXq1av1t7/9TePGjdPmzZutLg0AAAAAAAA3UdHqAq6XkJCgkJAQDR06VJIUEBCggwcP6r333lPnzp0trg4AAAAAAAA3UupCppSUFD355JMObR07dtSoUaN09epVeXp6Ot1XhQoehS7TsIHz/ZV3zsynMxrW83JJP+WBy+a8TiWX9FMeuGzOa1d2ST/lgcvm3LeKS/opD1w25zXvdEk/5YGr5rxRDW+X9FMeuGzOfaq6pJ/ywGVzXrWaS/opD1x2PL/TxyX9lAcum/PKzLmzXDbnXtVd0k95cKs5L2x7eBiGYbi6IDNatGihCRMmqHfv3va2Xbt2qV+/ftq+fbvq1KljYXUAAAAAAAC4kVL3TCYAAAAAAAC4n1IXMvn5+en8+fMObenp6apYsaJq1qxpUVUAAAAAAAC4lVIXMgUHB2vnzp0Obdu3b1dQUFCRnscEAAAAAACAklPqQqZ+/fpp7969mjNnjo4dO6ZFixZp3bp1GjBggNWlAQAAAAAA4CZK3YO/JWnz5s168803deLECdWrV0+DBg1Snz59rC4LAAAAAAAAN1EqQyYAAAAAAAC4l1J3uxwAAAAAAADcDyETAAAAAAAATCNkAgAAAAAAgGmETCUoLi5OMTExVpdRbuTn52vcuHEKCwuTzWbT5s2bC13HZrNp/fr1JVAdAKAoOIdaq6jzHx8fr4cffrgYKwIAwD2MGzdO0dHRVpdRYipaXUB5Mnr0aOXn51tdRrnx5Zdf6tNPP1VCQoL8/f1VvXp1q0sCANwmzqHWYv4BlAYHDhxQ37599cUXX6hhw4ZWlwPgBgiZSlC1atWsLqFcOXnypGrXrq3Q0FCrS4EL5ObmysvLy+oyyg3mG6UN51BrMf8AAMAZ3C5Xgn5/qfnOnTsVHR2ttm3bKiQkRFFRUfr2228dlrfZbFqyZIlGjBih4OBgPfDAA/rggw+sKN3txMXFaerUqTpz5oxsNptsNpsMw1BCQoK6du2qoKAgPfzww/r4449lGIbDuhkZGXr++efVqlUrhYeHa+HChRaNwj1ER0dr7Nixmjlzptq1a6fQ0FDNmjVL+fn5mjNnju677z61a9dOs2bNsq+zdu1a9enTRyEhIQoLC9PAgQN1/Phx+/unT5+WzWbT2rVr1b9/f7Vq1UrvvPOOFcNzC4UdT2w2mxITE2+5X9tsNi1cuFDDhg1TcHCwxo0bV9LDKLWKYx+PiooqMMe//vqrOnbsqMTExBIbmzv5/Tk0Ojq6wPxdf3vWteWXLFmiTp06KSQkRM8//7wyMjJKtO6yoqjzj6Jx5jh+/e3812+HjIwMvfDCC2rVqpU6dOigDz74QDExMYqLiyuxcbibPXv2qG/fvgoODlZISIgiIyP13XffSZKOHz+uIUOG2I/jgwcP1qlTp+zrXtvnk5KS9OCDDyooKEgxMTE6c+aMVcNxG7m5uZoyZYo6dOigFi1aqGfPntqyZYv9/XPnzik2Nlbt27dXUFCQunfvruTkZJ0+fVp9+/aVJD300EOy2Wzl6hak23HtOHHt80pYWJhGjRql7OxsSYVviyeeeEITJkxw6DM/P1/h4eF67733SnIobiMnJ0djxoxRmzZtFBYWpilTpjh833TmO2lmZqYmTZqk8PBwtWjRQp07d9bHH39sxXBuCyGTRbKysvTkk09q6dKlWrp0qRo3bqwBAwbowoULDsvNnTtX7dq1U1JSkvr3768pU6Zo3759FlXtPkaPHq3BgwerXr162rFjh3bs2KHZs2crMTFRcXFxSk5O1ogRIzRv3jwtWbLEYd1rB+Frc/7aa69p27ZtFo3EPSQnJ8swDC1ZskSjRo3S/PnzNXDgQGVlZWnhwoUaOXKk3nnnHW3dulXSbye0IUOGaNWqVfrwww9VsWJFDRo0SLm5uQ79Tp8+XZGRkVq3bp0iIyMtGJl7cOZ44sx+HR8fr7Zt22r16tV67rnnSnoYpZqr9/G+fftq/fr1ysrKsv+MrVu36pdfftGjjz5qxRDLpIMHD2rfvn1asGCBFixYoH/961+aOXOm1WUBBTj7ufBW4uLidOzYMb3//vt6//33tW/fPh04cKAYq3ZveXl5eu6559SmTRslJSVp5cqVGjBggDw9PXXu3Dn99a9/1V133aUlS5Zo0aJF8vHxUb9+/ZSTk2Pv46efftKKFSs0e/ZsLVq0SBcuXNCwYcMsHJV7mDFjhpKSkjR+/HitWbNG999/v55//nkdOXJE2dnZioqKUmpqqmbNmqXk5GTFxsbK09NT9evX14IFCyRJK1as0I4dOxQfH2/xaEq/5ORkXb58WQsXLtS0adO0adMmJSQkSLr1tpCknj17asOGDbp69aq9v2+++Ubnzp1TRESEFcMp9aZNm6YtW7ZoxowZWrx4sS5duuTwS4LCvpMahqGBAwdq+/btmjhxojZs2KB//OMf7nVFsYESExsba/Tv3/+G7+Xn5xthYWHG6tWr7W2BgYHG66+/7rBcly5djPj4+GKts6x45513jE6dOhmGYRhZWVlGy5Ytja+//tphmXfffdfo3r27/XVgYKARFxfnsMyLL75oPP3008Ver7uKiooyevXq5dAWERFhPPLIIw5tvXr1Ml577bUb9nHp0iXDZrMZe/fuNQzDMNLS0ozAwEBj/vz5xVN0GXf98cSZ/TowMNAYO3ZsSZbpNopjH79y5YrRtm1bY+XKlfZlBg0aZIwYMcLF1Zcdvz+HRkVFFdhfZ8+ebXTr1s1h+fvuu8+4cuWKvW3evHn28wKKpqjzf/1rFM2NjuPr1q1zWOb32+HYsWNGYGCgsXv3bvv7ly5dMoKDg43Y2NiSK9yNXLhwwQgMDDS++eabAu+99dZbxpNPPunQdvXqVSMkJMRITk42DOO3fdxmsxmnTp2yL3P06FEjMDDQ2LNnT/EW78YuX75sNG/e3Fi+fLlDe9++fY1XXnnFWL58udGyZUvj7NmzN1w/JSXFCAwMNNLS0kqiXLcXFRVlPPbYYw5to0ePNqKiogrdFoZhGD///LPRvHlz4/PPP7e/HxsbazzzzDPFX7wbyszMNJo3b+7w+S4vL8948MEHjaioKKe+k+7cudMIDAw0Dh8+XKK1uxLPZLJIWlqaZs+erQMHDuj8+fMyDEPZ2dkFLrH94x//6PC6Tp06Sk9PL8lSy4SjR48qJydHQ4YMkYeHh709Ly+vwO1yrVu3dnjdpk0bvfvuuyVSp7tq1qyZw+vatWurRo0aDm1+fn46f/68JOnw4cOaM2eODh8+bP8trWEYOnPmjEJCQuzrtGzZspgrLxucOZ44s18HBQWVSL3uyNX7uJeXlyIjI7VixQr95S9/0dmzZ/XVV1/Zh4WXjQAADL9JREFUf7MI1wgICHB4tlidOnXs2wgoTZz9XHgzqamp8vDwUKtWrextVatW1R/+8IfiKtnt1ahRQ5GRkYqJiVH79u0VFhambt26qWHDhjp06JAOHjyo4OBgh3Wys7Mdbpnz8/NTo0aN7K+bNm0qHx8fpaam8kzQmzh16pSuXr3q8HlPkkJDQ/X111/L29tbgYGBql27tkUVlj3Xf4apU6eO9u/fX+i2kKTq1aurU6dOWrNmjTp37qzs7Gx99tlnBW6hw2/S0tJ09epVh2PHHXfcoVatWuncuXNOfSf9/vvv5evrW2C7uRNCJosMHjxYtWrV0vjx41WvXj15enoqKirK4VJESfL09HR47eHhwV93uQ3X/tHOmTPH4cMAXKNixYKHkpvtu9nZ2erfv7/uvfdeTZ48WX5+fvLw8FCPHj0K7P9VqlQp1rrLCmePJ4W58847i6lC91cc+/jjjz+uDz/8UKmpqfr888/VqFEjtW3bttjHUhb8/oPZNXl5eQXaOIcWD2fnH84r7Dju4eFR4JdiRT3Go6DJkyfr6aef1vbt27V161a9+eab9mfudejQQaNGjSqwDn+tGO7G7LmwZ8+eevnll3Xx4kX7oxa6dOni0hrLi/LynZRnMlngwoUL+uGHHzR48GB16NBBTZs2VeXKlblCqRg1bdpUlSpV0n//+1/5+/sX+O/3rn9+QUpKigICAkqy3DItNTVVGRkZGj58uMLCwhQQEKBLly7xxe82OXs8Yb8uOc7u440bN9a9996r5cuX65NPPlHv3r0tqtj9+Pr66uzZsw5t33//vUXVlD/Mv2s5cxy/fs5zcnIc/phAQECADMNweFh4Zmamfvjhh5IZhBtr1qyZnn32WSUmJqpjx4765JNP1Lx5cx09elT169cv8Jnx91expqen6/Tp0/bXqampunjxIufXW/D395enp2eBZ8zu3btXTZs2tc/9zb4XXQtM+NxoXmHb4poHHnhAd955pzZs2KDVq1era9eu/GLyJho1aiRPT0+lpKTY23799VcdPHhQknPfSZs3b67z58/r3//+tyVjcAVCJgtUr15dtWrV0rJly3T8+HGlpKTo5ZdfVuXKla0urczy9vbWwIEDNW3aNC1dulQnTpzQkSNHtGrVqgJ/tezLL7/U4sWLdeLECX300UfatGmT+vXrZ03hZVCDBg3k5eWlxMREpaWladeuXZo4caIqVOBwdDucPZ6wX5ecouzjTzzxhBYtWqQff/yRh9sXwX333acdO3Zo48aNOnHihObPn88DjksQ8+9azhzH27dvr8WLF+vAgQM6cuSI4uLiHK4ea9y4sR544AFNmDBBe/fu1X/+8x+NHDlS0o2vPIN08uRJzZgxQ/v379eZM2e0e/duHT58WAEBAYqOjlZubq6GDh2q/fv3Ky0tTbt379bkyZN14sQJex+VK1fWyJEjdejQIX377beKjY1VixYtuFXuFqpUqaKoqCjNnDlTmzdv1rFjxzR16lR9++23iomJUY8ePVSnTh0NHjxY//znP5WWlqYdO3Zo8+bNkqT69eurQoUK2rZtm86fP69Lly5ZPCL3Vdi2uMbT01M9evTQwoUL9fXXX6tnz54WVl26eXt76/HHH9esWbO0bds2paamauLEifZHJzjznbR9+/YKDg7WsGHDtGXLFqWlpWnPnj1KSkqycmhFwu1yFqhQoYLeeustTZo0SY8++qgaNGigYcOGafbs2VaXVqa98MIL8vPz06JFizRp0iR5e3srICBATz31VIHlvvrqK02ZMkXVqlVTbGysOnXqZFHVZU+tWrU0bdo0zZw5U8uXL1eTJk00cuRIPfvss1aX5pacPZ6wX5ecouzjXbp00d///neFhYXJ19fXgmrd02OPPaYjR45o4sSJysvLU8+ePfXUU0/ps88+s7q0coH5dy1njuOxsbEaO3asnnnmGVWvXl1Dhgwp8HyxN954Q2PHjlX//v3l4+OjmJgYXbhwweG5ZPh/VapU0bFjx5SUlKQLFy7I19dXXbt21dChQ1WpUiUtWbJEM2fO1JAhQ5SVlaW6desqLCxMPj4+9j7q1aunyMhIDR06VOnp6QoNDdWkSZMsHJV7GD58uDw8PDR+/Hj98ssvCggI0Ny5c2Wz2SRJiYmJmjp1ql588UXl5OSoUaNGeuGFFyT9do599dVXtWDBAr3++usKDQ1VYmKilcNxa4Vti2t69uypRYsWqW7dumrXrp1F1bqHV199VTk5OXrppZfk6empXr16qUePHvaAurDvpB4eHnr33Xc1ffp0jRkzRr/88ovq16+vp59+2sJRFY2Hcf0N3ig2w4cPV15eHmESgBJls9k0c+ZM9ejRw+pScJ2MjAyFh4fr7bffVseOHa0up1TjHGot5t/95OTk6E9/+pMGDRqkZ555xupyypz4+HitX79eGzdutLoUAChVuD+lBOTm5uro0aM6cOCAAgMDrS4HAGCxq1ev6ty5c5oxY4YaNWqkDh06WF1SqcU51FrMv/vYs2ePPvvsM6WlpenQoUN65ZVXdOXKFXXv3t3q0gAA5QghUwlISUlRnz59FBgYqOjoaKvLAQBYbP/+/erQoYO++eYbTZ48mWem3ALnUGsx/+4jLy9Pc+fOVUREhGJiYpSZmanFixerbt26VpcGAChHuF0OAAAAAAAApnElEwAAAAAAAEwjZAIAAAAAAIBphEwAAAAAAAAwjZAJAADgBuLj42Wz2dS2bVvl5uYWeH/SpEmy2Wx68MEHi+Xnf/rpp0pKSirQHhcXpy5duhTLzwQAADCDkAkAAOAmKlSooNzcXH311VcO7Xl5eUpOTpa3t3ex/exVq1bdMGQCAAAorQiZAAAAbsLDw0MPPfSQ1qxZ49C+c+dOZWZmqmPHjhZVBgAAUPoQMgEAANzCo48+qq1btyozM9PetmbNGnXq1ElVq1Z1WPann37S8OHD1bZtW7Vs2VK9e/fWtm3bHJa5drvbwYMH9fjjj6tVq1bq3r27Nm3aZF8mOjpau3fv1q5du2Sz2WSz2RQXF+fQz63Wl6SUlBRFR0crNDRUrVu3Vrdu3TRv3jxXTQsAAEABhEwAAAC3cP/998vb21sbN26UJGVlZenLL79URESEw3KZmZn2cCguLk6zZ8+Wr6+vBg8erO3btzss+/PPP2vkyJHq27ev5s6dqwYNGuill17SyZMnJUnjx4/XPffco6CgIC1btkzLli3Tc8895/T6mZmZGjhwoCpXrqzp06fr7bffVv/+/ZWdnV2cUwUAAMq5ilYXAAAAUJpVrFhR3bt319q1a9W7d29t2rRJnp6eCg8P15YtW+zLrVq1SqdOndKKFSvUsmVLSVJ4eLgeeeQRxcfHO9xad/HiRb3//vv25e655x7df//92rRpk5599lk1bdpUVatW1R133KHWrVsXqKmw9Y8fP66LFy9qxIgRatasmSSpffv2xTZHAAAAElcyAQAAFCoiIkK7d+/W//73P61du1YPP/ywvLy8HJbZs2eP/P397cGP9NuDw//85z/ru+++05UrV+ztNWrUcFiuVq1a8vX11Y8//uhUPYWt7+/vr2rVqmnChAlat26dzp49e1vjBgAAKApCJgAAgEK0bt1aDRs2VEJCgnbt2lXgVjnpt6uL/Pz8CrT7+fkpPz9fly5dsrf5+PgUWM7Ly8shiLqVwtb38fFRQkKCatasqTFjxig8PFy9e/fWnj17nOofAADgdhAyAQAAOCEiIkIJCQmqW7euQkNDC7zv4+Oj9PT0Au3p6emqUKGCqlWrVhJl2rVo0UJvv/22du/erY8++kienp4aNGiQLl68WKJ1AACA8oOQCQAAwAmPPfaYOnXqpEGDBsnDw6PA+/fee69OnjypQ4cO2dvy8/O1ceNGBQUFqVKlSkX6eUW5sqmwfsLCwjRgwABdvnxZZ86cMd0nAADAjfDgbwAAACfcfffdmjdv3k3fj4yM1Mcff6whQ4Zo+PDhqlmzppYuXapjx45pwYIFRf55TZo00YoVK/T555+rXr16qlmzpho2bOjUulu2bNHy5cvVpUsX3XXXXbp48aLmz5+v+vXrq0mTJkWuBQAAwBmETAAAAC7g7e2txMRETZ06Va+//rpycnJks9k0f/58h78s56wBAwbo9OnTGjNmjH7++Wf16tVLb7zxhlPr+vv7y8vLS/Hx8UpPT5ePj49CQkI0ffr0Ag8sBwAAcBUPwzAMq4sAAAAAAACAe+OZTAAAAAAAADCNkAkAAAAAAACmETIBAAAAAADANEImAAAAAAAAmEbIBAAAAAAAANMImQAAAAAAAGAaIRMAAAAAAABMI2QCAAAAAACAaYRMAAAAAAAAMO3/AIUG2tuRUAN0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting Month Vs. temp plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [20, 10]\n",
        "sns.set(style = \"darkgrid\", font_scale = 1.3)\n",
        "month_temp = sns.barplot(x = 'month', y = 'temp', data = data,\n",
        "                         order = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec'], palette = 'winter');\n",
        "month_temp.set(title = \"Month Vs Temp Barplot\", xlabel = \"Months\", ylabel = \"Temperature\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "1sPPJQZKTBJ5",
        "outputId": "2525d789-7f6e-4a09-e770-437f08e4f64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "sns.set(style = 'whitegrid', font_scale = 1.3)\n",
        "day = sns.countplot(data['day'], order = ['sun' ,'mon', 'tue', 'wed', 'thu', 'fri', 'sat'], palette = 'spring')\n",
        "day.set(title = 'Countplot for the weekdays', xlabel = 'Days', ylabel = 'Count');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "M0lxuI6LTBJ6",
        "outputId": "2c7d3c84-2d52-418e-b4ed-ce74585371af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'HeatMap of Features for the Classes')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "sns.heatmap(data.corr(), annot=True, cmap=\"inferno\")\n",
        "ax = plt.gca()\n",
        "ax.set_title(\"HeatMap of Features for the Classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_U6bP69fTBJ7",
        "outputId": "40ae293b-c909-4836-aaa8-9c2f3efc0263"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-72dc33fc-2d21-4324-875f-82aaaa482f3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72dc33fc-2d21-4324-875f-82aaaa482f3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72dc33fc-2d21-4324-875f-82aaaa482f3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72dc33fc-2d21-4324-875f-82aaaa482f3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area size_category\n",
              "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0         small\n",
              "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0         small\n",
              "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0         small\n",
              "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0         small\n",
              "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0         small"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "F3hKi910TBJ8",
        "outputId": "5c50e2ed-c2fd-459c-fd27-4bbb4e8f994a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0e063979-56f1-4a42-9890-f728bba95587\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>small</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e063979-56f1-4a42-9890-f728bba95587')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e063979-56f1-4a42-9890-f728bba95587 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e063979-56f1-4a42-9890-f728bba95587');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area size_category\n",
              "0      3    5  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0         small\n",
              "1     10    2  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0         small\n",
              "2     10    6  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0         small\n",
              "3      3    5  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0         small\n",
              "4      3    7  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0         small"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Encoding month and day features\n",
        "\n",
        "data.month.replace(('jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec'),\n",
        "                           (1,2,3,4,5,6,7,8,9,10,11,12), inplace=True)\n",
        "data.day.replace(('mon','tue','wed','thu','fri','sat','sun'),(1,2,3,4,5,6,7), inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OW7nAaKiTBJ9",
        "outputId": "57eeb442-76d5-4d5a-e888-6a4d989bb2ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2f7afd73-b9a3-488c-ba7d-d2d6a2943910\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "      <th>size_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>88.8</td>\n",
              "      <td>147.3</td>\n",
              "      <td>614.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>14.4</td>\n",
              "      <td>66</td>\n",
              "      <td>5.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>92.2</td>\n",
              "      <td>91.6</td>\n",
              "      <td>503.6</td>\n",
              "      <td>9.6</td>\n",
              "      <td>20.7</td>\n",
              "      <td>70</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>94.8</td>\n",
              "      <td>222.4</td>\n",
              "      <td>698.6</td>\n",
              "      <td>13.9</td>\n",
              "      <td>26.2</td>\n",
              "      <td>34</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.4</td>\n",
              "      <td>25</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.23</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>91.4</td>\n",
              "      <td>142.4</td>\n",
              "      <td>601.4</td>\n",
              "      <td>10.6</td>\n",
              "      <td>18.2</td>\n",
              "      <td>43</td>\n",
              "      <td>4.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f7afd73-b9a3-488c-ba7d-d2d6a2943910')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f7afd73-b9a3-488c-ba7d-d2d6a2943910 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f7afd73-b9a3-488c-ba7d-d2d6a2943910');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     month  day  FFMC    DMC     DC  ...  RH  wind  rain   area  size_category\n",
              "101      8    2  88.8  147.3  614.5  ...  66   5.4   0.0   0.00              0\n",
              "247      8    3  92.2   91.6  503.6  ...  70   2.2   0.0   0.75              0\n",
              "428      8    4  94.8  222.4  698.6  ...  34   5.8   0.0   0.00              0\n",
              "210     10    6  90.6   43.7  686.9  ...  25   3.1   0.0  24.23              1\n",
              "93       8    7  91.4  142.4  601.4  ...  43   4.9   0.0   0.00              0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Encoding target variable 'size category'\n",
        "\n",
        "data.size_category.replace(('small', 'large'), (0, 1), inplace = True)\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ECz6FJTBJ-",
        "outputId": "4a31a825-b7be-4c05-ab60-c295894eae92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "size_category    1.000000\n",
              "area             0.311322\n",
              "month            0.080316\n",
              "wind             0.059113\n",
              "rain             0.050001\n",
              "DMC              0.034715\n",
              "FFMC             0.022063\n",
              "DC               0.019428\n",
              "day              0.016796\n",
              "temp             0.006021\n",
              "ISI             -0.008726\n",
              "RH              -0.045243\n",
              "Name: size_category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "data.corr()['size_category'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "9myctF8FTBJ_"
      },
      "outputs": [],
      "source": [
        "# Standardizing data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDB6QKy8TBJ_",
        "outputId": "7901462b-d9b6-4f64-b716-32dd8cfb5335"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "scaler.fit(data.drop('size_category',axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ToUzoIokTBKA",
        "outputId": "39f0ef71-f2f7-49f1-f828-106126046f5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-238a1181-b452-489b-9c5b-3016bde0f80d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.968443</td>\n",
              "      <td>0.357721</td>\n",
              "      <td>-0.805959</td>\n",
              "      <td>-1.323326</td>\n",
              "      <td>-1.830477</td>\n",
              "      <td>-0.860946</td>\n",
              "      <td>-1.842640</td>\n",
              "      <td>0.411724</td>\n",
              "      <td>1.498614</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.202020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.110120</td>\n",
              "      <td>-1.090909</td>\n",
              "      <td>-0.008102</td>\n",
              "      <td>-1.179541</td>\n",
              "      <td>0.488891</td>\n",
              "      <td>-0.509688</td>\n",
              "      <td>-0.153278</td>\n",
              "      <td>-0.692456</td>\n",
              "      <td>-1.741756</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.202020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.110120</td>\n",
              "      <td>0.840597</td>\n",
              "      <td>-0.008102</td>\n",
              "      <td>-1.049822</td>\n",
              "      <td>0.560715</td>\n",
              "      <td>-0.509688</td>\n",
              "      <td>-0.739383</td>\n",
              "      <td>-0.692456</td>\n",
              "      <td>-1.518282</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.202020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.968443</td>\n",
              "      <td>0.357721</td>\n",
              "      <td>0.191362</td>\n",
              "      <td>-1.212361</td>\n",
              "      <td>-1.898266</td>\n",
              "      <td>-0.004756</td>\n",
              "      <td>-1.825402</td>\n",
              "      <td>3.233519</td>\n",
              "      <td>-0.009834</td>\n",
              "      <td>0.603155</td>\n",
              "      <td>-0.202020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.968443</td>\n",
              "      <td>1.323474</td>\n",
              "      <td>-0.243833</td>\n",
              "      <td>-0.931043</td>\n",
              "      <td>-1.798600</td>\n",
              "      <td>0.126966</td>\n",
              "      <td>-1.291012</td>\n",
              "      <td>3.356206</td>\n",
              "      <td>-1.238940</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.202020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>0.230531</td>\n",
              "      <td>1.323474</td>\n",
              "      <td>-1.640083</td>\n",
              "      <td>-0.846648</td>\n",
              "      <td>0.474768</td>\n",
              "      <td>-1.563460</td>\n",
              "      <td>1.536084</td>\n",
              "      <td>-0.753800</td>\n",
              "      <td>-0.736124</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.100753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>0.230531</td>\n",
              "      <td>1.323474</td>\n",
              "      <td>-1.640083</td>\n",
              "      <td>-0.846648</td>\n",
              "      <td>0.474768</td>\n",
              "      <td>-1.563460</td>\n",
              "      <td>0.519019</td>\n",
              "      <td>1.638592</td>\n",
              "      <td>0.995798</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>0.651674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>0.230531</td>\n",
              "      <td>1.323474</td>\n",
              "      <td>-1.640083</td>\n",
              "      <td>-0.846648</td>\n",
              "      <td>0.474768</td>\n",
              "      <td>-1.563460</td>\n",
              "      <td>0.398350</td>\n",
              "      <td>1.577248</td>\n",
              "      <td>1.498614</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.026532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>0.230531</td>\n",
              "      <td>0.840597</td>\n",
              "      <td>0.680957</td>\n",
              "      <td>0.549003</td>\n",
              "      <td>0.269382</td>\n",
              "      <td>0.500176</td>\n",
              "      <td>1.156839</td>\n",
              "      <td>-0.140366</td>\n",
              "      <td>-0.009834</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.202020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>1.549915</td>\n",
              "      <td>-1.090909</td>\n",
              "      <td>-2.020879</td>\n",
              "      <td>-1.685913</td>\n",
              "      <td>-1.780442</td>\n",
              "      <td>-1.739089</td>\n",
              "      <td>-1.222058</td>\n",
              "      <td>-0.815143</td>\n",
              "      <td>0.269509</td>\n",
              "      <td>-0.073268</td>\n",
              "      <td>-0.202020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows  11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-238a1181-b452-489b-9c5b-3016bde0f80d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-238a1181-b452-489b-9c5b-3016bde0f80d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-238a1181-b452-489b-9c5b-3016bde0f80d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        month       day      FFMC  ...      wind      rain      area\n",
              "0   -1.968443  0.357721 -0.805959  ...  1.498614 -0.073268 -0.202020\n",
              "1    1.110120 -1.090909 -0.008102  ... -1.741756 -0.073268 -0.202020\n",
              "2    1.110120  0.840597 -0.008102  ... -1.518282 -0.073268 -0.202020\n",
              "3   -1.968443  0.357721  0.191362  ... -0.009834  0.603155 -0.202020\n",
              "4   -1.968443  1.323474 -0.243833  ... -1.238940 -0.073268 -0.202020\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "512  0.230531  1.323474 -1.640083  ... -0.736124 -0.073268 -0.100753\n",
              "513  0.230531  1.323474 -1.640083  ...  0.995798 -0.073268  0.651674\n",
              "514  0.230531  1.323474 -1.640083  ...  1.498614 -0.073268 -0.026532\n",
              "515  0.230531  0.840597  0.680957  ... -0.009834 -0.073268 -0.202020\n",
              "516  1.549915 -1.090909 -2.020879  ...  0.269509 -0.073268 -0.202020\n",
              "\n",
              "[517 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "scaled_features=scaler.transform(data.drop('size_category',axis=1))\n",
        "data_head=pd.DataFrame(scaled_features,columns=data.columns[:-1])\n",
        "data_head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "VuzD1BabTBKB"
      },
      "outputs": [],
      "source": [
        "# Splitting data into test data and train data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data_head,data['size_category'], test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUZGP_gjTBKC",
        "outputId": "0cb700d8-e5b3-4d84-abea-a3ed77e5e726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train:  (361, 11)\n",
            "Shape of x_test:  (156, 11)\n",
            "Shape of y_train:  (361,)\n",
            "Shape of y_test:  (156,)\n"
          ]
        }
      ],
      "source": [
        "print('Shape of x_train: ', x_train.shape)\n",
        "print('Shape of x_test: ', x_test.shape)\n",
        "print('Shape of y_train: ', y_train.shape)\n",
        "print('Shape of y_test: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnIEd4HSTBKD"
      },
      "source": [
        "### Artificial Neural Network Model - Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vPceZYpmTBKD"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-3dW9uSSTBKE"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=11, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(Dense(10, kernel_initializer='uniform', activation='relu'))\n",
        "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BPbrZwgYTBKF"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCsT462LTBKF",
        "outputId": "089f47de-9f3c-4239-9b92-f1f4888449aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "37/37 [==============================] - 1s 2ms/step - loss: 0.6892 - accuracy: 0.7091\n",
            "Epoch 2/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6778 - accuracy: 0.7285\n",
            "Epoch 3/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6569 - accuracy: 0.7285\n",
            "Epoch 4/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.7285\n",
            "Epoch 5/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7313\n",
            "Epoch 6/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7396\n",
            "Epoch 7/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7535\n",
            "Epoch 8/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7645\n",
            "Epoch 9/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7784\n",
            "Epoch 10/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4437 - accuracy: 0.8006\n",
            "Epoch 11/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.4174 - accuracy: 0.8033\n",
            "Epoch 12/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3968 - accuracy: 0.8283\n",
            "Epoch 13/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8504\n",
            "Epoch 14/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8615\n",
            "Epoch 15/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8643\n",
            "Epoch 16/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8726\n",
            "Epoch 17/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2779 - accuracy: 0.8753\n",
            "Epoch 18/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2605 - accuracy: 0.8781\n",
            "Epoch 19/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.8892\n",
            "Epoch 20/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2359 - accuracy: 0.9169\n",
            "Epoch 21/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.9141\n",
            "Epoch 22/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.2004 - accuracy: 0.9169\n",
            "Epoch 23/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9197\n",
            "Epoch 24/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9224\n",
            "Epoch 25/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1643 - accuracy: 0.9280\n",
            "Epoch 26/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1526 - accuracy: 0.9307\n",
            "Epoch 27/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9584\n",
            "Epoch 28/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9391\n",
            "Epoch 29/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9557\n",
            "Epoch 30/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1178 - accuracy: 0.9501\n",
            "Epoch 31/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9668\n",
            "Epoch 32/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9723\n",
            "Epoch 33/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0987 - accuracy: 0.9751\n",
            "Epoch 34/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9806\n",
            "Epoch 35/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0902 - accuracy: 0.9751\n",
            "Epoch 36/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9889\n",
            "Epoch 37/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0801 - accuracy: 0.9806\n",
            "Epoch 38/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9806\n",
            "Epoch 39/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0738 - accuracy: 0.9861\n",
            "Epoch 40/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9861\n",
            "Epoch 41/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9889\n",
            "Epoch 42/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0643 - accuracy: 0.9834\n",
            "Epoch 43/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9917\n",
            "Epoch 44/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9917\n",
            "Epoch 45/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9889\n",
            "Epoch 46/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9917\n",
            "Epoch 47/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9861\n",
            "Epoch 48/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9917\n",
            "Epoch 49/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9917\n",
            "Epoch 50/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9889\n",
            "Epoch 51/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0460 - accuracy: 0.9917\n",
            "Epoch 52/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9917\n",
            "Epoch 53/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9889\n",
            "Epoch 54/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9945\n",
            "Epoch 55/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9917\n",
            "Epoch 56/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9861\n",
            "Epoch 57/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9889\n",
            "Epoch 58/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9917\n",
            "Epoch 59/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.9917\n",
            "Epoch 60/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9945\n",
            "Epoch 61/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9917\n",
            "Epoch 62/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9945\n",
            "Epoch 63/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9917\n",
            "Epoch 64/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9945\n",
            "Epoch 65/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9972\n",
            "Epoch 66/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9917\n",
            "Epoch 67/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9945\n",
            "Epoch 68/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9917\n",
            "Epoch 69/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9945\n",
            "Epoch 70/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9945\n",
            "Epoch 71/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 0.9945\n",
            "Epoch 72/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9945\n",
            "Epoch 73/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9917\n",
            "Epoch 74/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 0.9917\n",
            "Epoch 75/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9917\n",
            "Epoch 76/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9917\n",
            "Epoch 77/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9945\n",
            "Epoch 78/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9945\n",
            "Epoch 79/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0280 - accuracy: 0.9945\n",
            "Epoch 80/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9945\n",
            "Epoch 81/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9917\n",
            "Epoch 82/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9945\n",
            "Epoch 83/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0257 - accuracy: 0.9917\n",
            "Epoch 84/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 0.9945\n",
            "Epoch 85/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9917\n",
            "Epoch 86/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0302 - accuracy: 0.9917\n",
            "Epoch 87/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9917\n",
            "Epoch 88/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9917\n",
            "Epoch 89/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9945\n",
            "Epoch 90/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9917\n",
            "Epoch 91/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0253 - accuracy: 0.9945\n",
            "Epoch 92/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9945\n",
            "Epoch 93/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9945\n",
            "Epoch 94/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9945\n",
            "Epoch 95/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9917\n",
            "Epoch 96/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9917\n",
            "Epoch 97/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9945\n",
            "Epoch 98/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0212 - accuracy: 0.9972\n",
            "Epoch 99/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9945\n",
            "Epoch 100/100\n",
            "37/37 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9917\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdca086dbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Fit the model\n",
        "model.fit(x_train,y_train, epochs=100, batch_size=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxNSk3ceTBKG",
        "outputId": "aab949b4-273a-4963-f8f7-354c6fa6a102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9679\n",
            "accuracy: 96.79%\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMUItBgtTBKH"
      },
      "source": [
        "### Artificial Neural Network Model - Tuning of Hyperparameters batch size and epochs "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k7p2rQvOTBKH"
      },
      "outputs": [],
      "source": [
        "# Importing the necessary packages\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import adam_v2\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "c4Tu8ghUTBKI"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=11, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
        "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
        "    \n",
        "    adam=adam_v2.Adam(learning_rate=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HneVJYmuTBKJ",
        "outputId": "6612e584-cfe3-4534-dcd9-ce8161fc56dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV 1/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 1/5; 1/9] END .....batch_size=10, epochs=10;, score=0.959 total time=   1.5s\n",
            "[CV 2/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 2/5; 1/9] END .....batch_size=10, epochs=10;, score=0.944 total time=   1.3s\n",
            "[CV 3/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 3/5; 1/9] END .....batch_size=10, epochs=10;, score=0.986 total time=   1.3s\n",
            "[CV 4/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 4/5; 1/9] END .....batch_size=10, epochs=10;, score=0.986 total time=   1.3s\n",
            "[CV 5/5; 1/9] START batch_size=10, epochs=10....................................\n",
            "[CV 5/5; 1/9] END .....batch_size=10, epochs=10;, score=0.944 total time=   1.3s\n",
            "[CV 1/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 1/5; 2/9] END .....batch_size=10, epochs=50;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 2/5; 2/9] END .....batch_size=10, epochs=50;, score=0.958 total time=   3.3s\n",
            "[CV 3/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 3/5; 2/9] END .....batch_size=10, epochs=50;, score=0.944 total time=   2.6s\n",
            "[CV 4/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 4/5; 2/9] END .....batch_size=10, epochs=50;, score=0.986 total time=   2.5s\n",
            "[CV 5/5; 2/9] START batch_size=10, epochs=50....................................\n",
            "[CV 5/5; 2/9] END .....batch_size=10, epochs=50;, score=0.972 total time=   2.6s\n",
            "[CV 1/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 1/5; 3/9] END ....batch_size=10, epochs=100;, score=1.000 total time=   4.4s\n",
            "[CV 2/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 2/5; 3/9] END ....batch_size=10, epochs=100;, score=0.931 total time=   6.1s\n",
            "[CV 3/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 3/5; 3/9] END ....batch_size=10, epochs=100;, score=0.944 total time=   4.4s\n",
            "[CV 4/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 4/5; 3/9] END ....batch_size=10, epochs=100;, score=0.986 total time=   4.5s\n",
            "[CV 5/5; 3/9] START batch_size=10, epochs=100...................................\n",
            "[CV 5/5; 3/9] END ....batch_size=10, epochs=100;, score=0.972 total time=   5.8s\n",
            "[CV 1/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 1/5; 4/9] END .....batch_size=20, epochs=10;, score=0.877 total time=   0.9s\n",
            "[CV 2/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 2/5; 4/9] END .....batch_size=20, epochs=10;, score=0.944 total time=   0.9s\n",
            "[CV 3/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 3/5; 4/9] END .....batch_size=20, epochs=10;, score=0.847 total time=   1.0s\n",
            "[CV 4/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 4/5; 4/9] END .....batch_size=20, epochs=10;, score=0.944 total time=   0.9s\n",
            "[CV 5/5; 4/9] START batch_size=20, epochs=10....................................\n",
            "[CV 5/5; 4/9] END .....batch_size=20, epochs=10;, score=0.889 total time=   0.9s\n",
            "[CV 1/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 1/5; 5/9] END .....batch_size=20, epochs=50;, score=0.986 total time=   1.7s\n",
            "[CV 2/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 2/5; 5/9] END .....batch_size=20, epochs=50;, score=0.944 total time=   2.0s\n",
            "[CV 3/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 3/5; 5/9] END .....batch_size=20, epochs=50;, score=0.944 total time=   2.3s\n",
            "[CV 4/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 4/5; 5/9] END .....batch_size=20, epochs=50;, score=1.000 total time=   1.7s\n",
            "[CV 5/5; 5/9] START batch_size=20, epochs=50....................................\n",
            "[CV 5/5; 5/9] END .....batch_size=20, epochs=50;, score=0.958 total time=   1.7s\n",
            "[CV 1/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 1/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   3.2s\n",
            "[CV 2/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 2/5; 6/9] END ....batch_size=20, epochs=100;, score=0.972 total time=   3.3s\n",
            "[CV 3/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 3/5; 6/9] END ....batch_size=20, epochs=100;, score=0.931 total time=   2.7s\n",
            "[CV 4/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 4/5; 6/9] END ....batch_size=20, epochs=100;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 6/9] START batch_size=20, epochs=100...................................\n",
            "[CV 5/5; 6/9] END ....batch_size=20, epochs=100;, score=0.958 total time=   2.7s\n",
            "[CV 1/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "[CV 1/5; 7/9] END .....batch_size=40, epochs=10;, score=0.726 total time=   0.8s\n",
            "[CV 2/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "[CV 2/5; 7/9] END .....batch_size=40, epochs=10;, score=0.736 total time=   0.8s\n",
            "[CV 3/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdc970d65f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 3/5; 7/9] END .....batch_size=40, epochs=10;, score=0.681 total time=   0.8s\n",
            "[CV 4/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fdca0130e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[CV 4/5; 7/9] END .....batch_size=40, epochs=10;, score=0.750 total time=   0.8s\n",
            "[CV 5/5; 7/9] START batch_size=40, epochs=10....................................\n",
            "[CV 5/5; 7/9] END .....batch_size=40, epochs=10;, score=0.819 total time=   1.2s\n",
            "[CV 1/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 1/5; 8/9] END .....batch_size=40, epochs=50;, score=0.973 total time=   1.3s\n",
            "[CV 2/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 2/5; 8/9] END .....batch_size=40, epochs=50;, score=0.972 total time=   1.3s\n",
            "[CV 3/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 3/5; 8/9] END .....batch_size=40, epochs=50;, score=0.972 total time=   1.3s\n",
            "[CV 4/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 4/5; 8/9] END .....batch_size=40, epochs=50;, score=0.986 total time=   1.3s\n",
            "[CV 5/5; 8/9] START batch_size=40, epochs=50....................................\n",
            "[CV 5/5; 8/9] END .....batch_size=40, epochs=50;, score=0.917 total time=   1.3s\n",
            "[CV 1/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 1/5; 9/9] END ....batch_size=40, epochs=100;, score=0.945 total time=   2.0s\n",
            "[CV 2/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 2/5; 9/9] END ....batch_size=40, epochs=100;, score=0.889 total time=   1.8s\n",
            "[CV 3/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 3/5; 9/9] END ....batch_size=40, epochs=100;, score=0.931 total time=   2.0s\n",
            "[CV 4/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 4/5; 9/9] END ....batch_size=40, epochs=100;, score=1.000 total time=   2.0s\n",
            "[CV 5/5; 9/9] START batch_size=40, epochs=100...................................\n",
            "[CV 5/5; 9/9] END ....batch_size=40, epochs=100;, score=0.972 total time=   2.3s\n"
          ]
        }
      ],
      "source": [
        "# Create the model\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "# Define the grid search parameters\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdk3tFDDTBKK",
        "outputId": "8ae75cdd-e182-4b97-a90a-6039055cc343"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best : 0.9722222208976745, using {'batch_size': 20, 'epochs': 100}\n",
            "0.9640030264854431,0.0188075077546884 with: {'batch_size': 10, 'epochs': 10}\n",
            "0.966742753982544,0.014194584661031812 with: {'batch_size': 10, 'epochs': 50}\n",
            "0.9666666626930237,0.02576004694866349 with: {'batch_size': 10, 'epochs': 100}\n",
            "0.9003424525260926,0.03847413159439316 with: {'batch_size': 20, 'epochs': 10}\n",
            "0.9667047023773193,0.022599675262683125 with: {'batch_size': 20, 'epochs': 50}\n",
            "0.9722222208976745,0.026352307551859317 with: {'batch_size': 20, 'epochs': 100}\n",
            "0.7424276947975159,0.045002097220154025 with: {'batch_size': 40, 'epochs': 10}\n",
            "0.9639649868011475,0.02424274610889378 with: {'batch_size': 40, 'epochs': 50}\n",
            "0.947374427318573,0.037669612694489533 with: {'batch_size': 40, 'epochs': 100}\n"
          ]
        }
      ],
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXIuLXwiTBKL"
      },
      "source": [
        "## Artificial Neural Network Model - Tuning of All Hyperparameters "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKlDIvwnTBKL",
        "outputId": "6b2048c5-f789-4fca-8553-eafb0a500286"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
            "  from ipykernel import kernelapp as app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "[CV 5/5; 115/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   2.5s\n",
            "[CV 1/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   2.5s\n",
            "[CV 2/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   2.5s\n",
            "[CV 3/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   2.5s\n",
            "[CV 5/5; 116/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 116/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   2.5s\n",
            "[CV 2/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   3.7s\n",
            "[CV 4/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   2.5s\n",
            "[CV 5/5; 117/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 117/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   2.5s\n",
            "[CV 1/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.945 total time=   3.3s\n",
            "[CV 2/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.917 total time=   2.5s\n",
            "[CV 3/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 4/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.5s\n",
            "[CV 5/5; 118/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 118/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   2.5s\n",
            "[CV 1/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.973 total time=   2.5s\n",
            "[CV 2/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   2.5s\n",
            "[CV 3/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   2.5s\n",
            "[CV 4/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 119/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 119/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   2.9s\n",
            "[CV 1/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   3.3s\n",
            "[CV 2/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.958 total time=   2.5s\n",
            "[CV 3/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   2.5s\n",
            "[CV 4/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   2.5s\n",
            "[CV 5/5; 120/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 120/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   2.5s\n",
            "[CV 1/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.959 total time=   2.5s\n",
            "[CV 2/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.903 total time=   3.3s\n",
            "[CV 3/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 121/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 121/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.972 total time=   3.3s\n",
            "[CV 1/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.945 total time=   3.3s\n",
            "[CV 2/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.944 total time=   3.7s\n",
            "[CV 3/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 122/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 122/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.932 total time=   3.3s\n",
            "[CV 2/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.903 total time=   3.3s\n",
            "[CV 3/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.986 total time=   2.5s\n",
            "[CV 5/5; 123/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 123/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 1/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.945 total time=   2.5s\n",
            "[CV 2/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.917 total time=   2.5s\n",
            "[CV 3/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.931 total time=   3.3s\n",
            "[CV 4/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.986 total time=   3.0s\n",
            "[CV 5/5; 124/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 124/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   2.5s\n",
            "[CV 1/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.959 total time=   2.6s\n",
            "[CV 2/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.861 total time=   3.3s\n",
            "[CV 3/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.903 total time=   2.5s\n",
            "[CV 4/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 125/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 125/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.917 total time=   3.3s\n",
            "[CV 1/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.973 total time=   2.5s\n",
            "[CV 2/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.917 total time=   2.5s\n",
            "[CV 3/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.861 total time=   2.5s\n",
            "[CV 4/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=1.000 total time=   2.5s\n",
            "[CV 5/5; 126/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 126/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 1/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.904 total time=   2.9s\n",
            "[CV 2/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.972 total time=   3.3s\n",
            "[CV 3/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   2.5s\n",
            "[CV 4/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   2.5s\n",
            "[CV 5/5; 127/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 127/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 1/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 2/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   2.5s\n",
            "[CV 3/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   2.5s\n",
            "[CV 5/5; 128/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 128/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.959 total time=   3.3s\n",
            "[CV 2/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   2.9s\n",
            "[CV 3/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   2.5s\n",
            "[CV 4/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   2.5s\n",
            "[CV 5/5; 129/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 129/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 1/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 2/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.889 total time=   2.5s\n",
            "[CV 3/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.931 total time=   3.3s\n",
            "[CV 4/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 130/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 130/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.889 total time=   2.5s\n",
            "[CV 1/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 2/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.889 total time=   2.5s\n",
            "[CV 3/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.972 total time=   3.3s\n",
            "[CV 4/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.986 total time=   3.7s\n",
            "[CV 5/5; 131/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 131/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.904 total time=   3.3s\n",
            "[CV 2/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   3.3s\n",
            "[CV 3/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   2.7s\n",
            "[CV 4/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 5/5; 132/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 132/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.986 total time=   2.6s\n",
            "[CV 1/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.918 total time=   3.3s\n",
            "[CV 2/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.958 total time=   3.3s\n",
            "[CV 3/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   3.3s\n",
            "[CV 4/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.861 total time=   2.7s\n",
            "[CV 5/5; 133/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 133/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   3.3s\n",
            "[CV 1/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.959 total time=   3.1s\n",
            "[CV 2/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.875 total time=   3.3s\n",
            "[CV 3/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   3.3s\n",
            "[CV 4/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 134/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 134/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.959 total time=   2.7s\n",
            "[CV 2/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.931 total time=   3.3s\n",
            "[CV 3/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.875 total time=   2.6s\n",
            "[CV 4/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.944 total time=   2.6s\n",
            "[CV 5/5; 135/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 135/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   3.7s\n",
            "[CV 4/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 136/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 136/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   2.5s\n",
            "[CV 1/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 137/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 137/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   2.7s\n",
            "[CV 3/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.0s\n",
            "[CV 5/5; 138/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 138/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   3.5s\n",
            "[CV 1/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   3.1s\n",
            "[CV 2/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   3.5s\n",
            "[CV 5/5; 139/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 139/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   6.0s\n",
            "[CV 1/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   3.5s\n",
            "[CV 3/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 140/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 140/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   3.2s\n",
            "[CV 1/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   3.5s\n",
            "[CV 2/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   4.0s\n",
            "[CV 3/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   3.5s\n",
            "[CV 4/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 141/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 141/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.2s\n",
            "[CV 3/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.5s\n",
            "[CV 5/5; 142/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 142/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.2s\n",
            "[CV 3/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   3.7s\n",
            "[CV 4/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 143/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 143/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   3.2s\n",
            "[CV 1/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   3.2s\n",
            "[CV 2/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.1s\n",
            "[CV 3/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   3.1s\n",
            "[CV 4/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.2s\n",
            "[CV 5/5; 144/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 144/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   3.5s\n",
            "[CV 1/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.726 total time=   3.5s\n",
            "[CV 2/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.681 total time=   3.5s\n",
            "[CV 4/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   3.5s\n",
            "[CV 5/5; 145/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 145/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.681 total time=   2.8s\n",
            "[CV 4/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 146/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 146/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.726 total time=   2.7s\n",
            "[CV 2/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   2.7s\n",
            "[CV 3/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.681 total time=   2.7s\n",
            "[CV 4/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   2.7s\n",
            "[CV 5/5; 147/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 147/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.726 total time=   2.7s\n",
            "[CV 2/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   3.0s\n",
            "[CV 3/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 148/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 148/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.681 total time=   2.7s\n",
            "[CV 4/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 149/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 149/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.736 total time=   3.2s\n",
            "[CV 5/5; 150/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 150/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 151/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 151/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.764 total time=   2.8s\n",
            "[CV 1/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.736 total time=   2.7s\n",
            "[CV 5/5; 152/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 152/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.764 total time=   2.7s\n",
            "[CV 1/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.726 total time=   3.9s\n",
            "[CV 2/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.736 total time=   2.9s\n",
            "[CV 3/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.681 total time=   2.7s\n",
            "[CV 4/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.736 total time=   2.7s\n",
            "[CV 5/5; 153/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 153/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 154/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 154/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.681 total time=   3.2s\n",
            "[CV 4/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 155/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 155/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 156/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 156/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.736 total time=   3.7s\n",
            "[CV 5/5; 157/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 157/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.736 total time=   2.5s\n",
            "[CV 5/5; 158/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 158/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.736 total time=   2.8s\n",
            "[CV 5/5; 159/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 159/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.764 total time=   2.8s\n",
            "[CV 1/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.736 total time=   2.9s\n",
            "[CV 3/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.681 total time=   2.9s\n",
            "[CV 4/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 160/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 160/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.764 total time=   2.8s\n",
            "[CV 1/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.726 total time=   2.8s\n",
            "[CV 2/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.736 total time=   2.8s\n",
            "[CV 3/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 161/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 161/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.764 total time=   2.8s\n",
            "[CV 1/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.681 total time=   3.9s\n",
            "[CV 4/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 162/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 162/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.764 total time=   2.8s\n",
            "[CV 1/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.890 total time=   4.4s\n",
            "[CV 2/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.903 total time=   4.3s\n",
            "[CV 3/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.847 total time=   5.9s\n",
            "[CV 4/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.931 total time=   4.3s\n",
            "[CV 5/5; 163/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 163/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.847 total time=   5.9s\n",
            "[CV 1/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.863 total time=   4.3s\n",
            "[CV 2/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.903 total time=   5.9s\n",
            "[CV 3/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.861 total time=   4.3s\n",
            "[CV 4/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 5/5; 164/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 164/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.847 total time=   6.3s\n",
            "[CV 1/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.877 total time=   5.9s\n",
            "[CV 2/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 3/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.861 total time=   4.4s\n",
            "[CV 4/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 5/5; 165/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 165/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.847 total time=   4.3s\n",
            "[CV 1/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.890 total time=   4.2s\n",
            "[CV 2/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.903 total time=   5.9s\n",
            "[CV 3/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.847 total time=   5.9s\n",
            "[CV 4/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 5/5; 166/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 166/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.847 total time=   4.3s\n",
            "[CV 1/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.890 total time=   4.2s\n",
            "[CV 2/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.931 total time=   6.3s\n",
            "[CV 3/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.847 total time=   4.3s\n",
            "[CV 4/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.958 total time=   5.8s\n",
            "[CV 5/5; 167/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 167/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.847 total time=   5.9s\n",
            "[CV 1/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.877 total time=   4.3s\n",
            "[CV 2/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.931 total time=   5.8s\n",
            "[CV 3/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.861 total time=   4.3s\n",
            "[CV 4/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.958 total time=   5.8s\n",
            "[CV 5/5; 168/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 168/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.847 total time=   5.8s\n",
            "[CV 1/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.849 total time=   4.3s\n",
            "[CV 2/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.903 total time=   4.3s\n",
            "[CV 3/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.806 total time=   5.8s\n",
            "[CV 4/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.931 total time=   6.2s\n",
            "[CV 5/5; 169/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 169/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.833 total time=   4.3s\n",
            "[CV 1/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.904 total time=   5.8s\n",
            "[CV 2/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.875 total time=   4.3s\n",
            "[CV 3/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.847 total time=   4.3s\n",
            "[CV 4/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.958 total time=   4.3s\n",
            "[CV 5/5; 170/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 170/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.861 total time=   5.8s\n",
            "[CV 1/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.836 total time=   4.3s\n",
            "[CV 2/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.917 total time=   4.3s\n",
            "[CV 3/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.819 total time=   4.3s\n",
            "[CV 4/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.958 total time=   4.3s\n",
            "[CV 5/5; 171/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 171/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.847 total time=   4.3s\n",
            "[CV 1/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.973 total time=   4.6s\n",
            "[CV 2/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   5.8s\n",
            "[CV 3/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   4.2s\n",
            "[CV 4/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 172/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 172/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.944 total time=   4.2s\n",
            "[CV 1/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.973 total time=   5.8s\n",
            "[CV 2/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   4.2s\n",
            "[CV 3/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   4.3s\n",
            "[CV 4/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   4.2s\n",
            "[CV 5/5; 173/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 173/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   4.2s\n",
            "[CV 1/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.932 total time=   5.9s\n",
            "[CV 2/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   6.5s\n",
            "[CV 3/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.958 total time=   4.6s\n",
            "[CV 4/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   4.3s\n",
            "[CV 5/5; 174/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 174/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.932 total time=   4.4s\n",
            "[CV 2/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   4.4s\n",
            "[CV 3/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.931 total time=   4.4s\n",
            "[CV 4/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 175/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 175/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.945 total time=   5.8s\n",
            "[CV 2/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.903 total time=   5.8s\n",
            "[CV 3/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   4.3s\n",
            "[CV 4/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   6.3s\n",
            "[CV 5/5; 176/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 176/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.944 total time=   4.3s\n",
            "[CV 1/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.959 total time=   5.8s\n",
            "[CV 2/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.875 total time=   4.3s\n",
            "[CV 3/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   5.8s\n",
            "[CV 4/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 177/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 177/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   4.3s\n",
            "[CV 1/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.959 total time=   4.3s\n",
            "[CV 2/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.889 total time=   4.3s\n",
            "[CV 3/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.931 total time=   4.3s\n",
            "[CV 4/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   4.3s\n",
            "[CV 5/5; 178/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 178/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.931 total time=   5.9s\n",
            "[CV 1/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.945 total time=   4.3s\n",
            "[CV 2/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   6.4s\n",
            "[CV 3/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.917 total time=   6.0s\n",
            "[CV 4/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=1.000 total time=   4.8s\n",
            "[CV 5/5; 179/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 179/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   6.0s\n",
            "[CV 1/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.945 total time=   5.0s\n",
            "[CV 2/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.917 total time=   4.6s\n",
            "[CV 3/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.931 total time=   4.7s\n",
            "[CV 4/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 5/5; 180/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 180/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 1/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   5.9s\n",
            "[CV 3/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   6.5s\n",
            "[CV 5/5; 181/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 181/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   4.6s\n",
            "[CV 3/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.931 total time=   6.0s\n",
            "[CV 4/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   5.9s\n",
            "[CV 5/5; 182/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 182/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   4.6s\n",
            "[CV 2/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 3/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 4/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 5/5; 183/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 183/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   5.1s\n",
            "[CV 1/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.986 total time=   4.6s\n",
            "[CV 2/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   4.6s\n",
            "[CV 3/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.986 total time=   4.5s\n",
            "[CV 5/5; 184/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 184/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   4.7s\n",
            "[CV 3/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.944 total time=   5.9s\n",
            "[CV 5/5; 185/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 185/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.931 total time=   4.7s\n",
            "[CV 1/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 3/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.944 total time=   6.5s\n",
            "[CV 4/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.875 total time=   4.6s\n",
            "[CV 5/5; 186/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 186/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.918 total time=   4.5s\n",
            "[CV 2/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.875 total time=   4.6s\n",
            "[CV 3/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.903 total time=   4.7s\n",
            "[CV 4/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.903 total time=   5.9s\n",
            "[CV 5/5; 187/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 187/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.972 total time=   4.5s\n",
            "[CV 1/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.945 total time=   4.6s\n",
            "[CV 2/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   4.7s\n",
            "[CV 3/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.875 total time=   5.9s\n",
            "[CV 4/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 5/5; 188/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 188/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.944 total time=   4.6s\n",
            "[CV 1/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.945 total time=   5.1s\n",
            "[CV 2/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   4.7s\n",
            "[CV 3/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   5.9s\n",
            "[CV 4/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.986 total time=   4.5s\n",
            "[CV 5/5; 189/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 189/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.863 total time=   5.9s\n",
            "[CV 2/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.889 total time=   5.9s\n",
            "[CV 3/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.861 total time=   5.9s\n",
            "[CV 4/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 5/5; 190/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 190/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.847 total time=   4.5s\n",
            "[CV 1/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.863 total time=   5.9s\n",
            "[CV 2/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.917 total time=   4.5s\n",
            "[CV 3/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.847 total time=   6.4s\n",
            "[CV 4/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.917 total time=   5.9s\n",
            "[CV 5/5; 191/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 191/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.861 total time=   4.5s\n",
            "[CV 1/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.877 total time=   4.6s\n",
            "[CV 2/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 3/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.861 total time=   5.9s\n",
            "[CV 4/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 5/5; 192/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 192/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.847 total time=   5.9s\n",
            "[CV 1/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.849 total time=   5.9s\n",
            "[CV 2/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.889 total time=   4.5s\n",
            "[CV 3/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.806 total time=   4.4s\n",
            "[CV 4/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.944 total time=   4.6s\n",
            "[CV 5/5; 193/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 193/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.847 total time=   6.4s\n",
            "[CV 1/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.877 total time=   4.5s\n",
            "[CV 2/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.903 total time=   4.6s\n",
            "[CV 3/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.847 total time=   5.9s\n",
            "[CV 4/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.944 total time=   4.2s\n",
            "[CV 5/5; 194/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 194/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.833 total time=   5.8s\n",
            "[CV 1/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.849 total time=   5.8s\n",
            "[CV 2/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.889 total time=   4.3s\n",
            "[CV 3/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.819 total time=   5.8s\n",
            "[CV 4/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.958 total time=   4.3s\n",
            "[CV 5/5; 195/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 195/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.847 total time=   4.3s\n",
            "[CV 1/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.836 total time=   5.8s\n",
            "[CV 2/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.889 total time=   5.8s\n",
            "[CV 3/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.819 total time=   6.3s\n",
            "[CV 4/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.931 total time=   5.8s\n",
            "[CV 5/5; 196/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 196/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.847 total time=   5.8s\n",
            "[CV 1/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.836 total time=   4.3s\n",
            "[CV 2/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.889 total time=   5.8s\n",
            "[CV 3/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.847 total time=   5.8s\n",
            "[CV 4/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.958 total time=   4.3s\n",
            "[CV 5/5; 197/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 197/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.861 total time=   5.8s\n",
            "[CV 1/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.849 total time=   5.8s\n",
            "[CV 2/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.917 total time=   5.8s\n",
            "[CV 3/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.792 total time=   4.3s\n",
            "[CV 4/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.958 total time=   4.4s\n",
            "[CV 5/5; 198/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 198/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.847 total time=   4.7s\n",
            "[CV 1/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.973 total time=   4.2s\n",
            "[CV 2/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   4.2s\n",
            "[CV 3/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.944 total time=   5.8s\n",
            "[CV 4/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   4.2s\n",
            "[CV 5/5; 199/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 199/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   5.8s\n",
            "[CV 1/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.973 total time=   4.2s\n",
            "[CV 2/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   4.2s\n",
            "[CV 3/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   5.8s\n",
            "[CV 4/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   5.8s\n",
            "[CV 5/5; 200/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 200/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   5.8s\n",
            "[CV 1/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.973 total time=   5.8s\n",
            "[CV 2/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   4.3s\n",
            "[CV 3/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.958 total time=   4.7s\n",
            "[CV 4/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 5/5; 201/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 201/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 1/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.918 total time=   4.7s\n",
            "[CV 2/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.931 total time=   4.5s\n",
            "[CV 3/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.972 total time=   5.9s\n",
            "[CV 4/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.986 total time=   4.5s\n",
            "[CV 5/5; 202/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 202/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   4.5s\n",
            "[CV 1/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.959 total time=   4.4s\n",
            "[CV 2/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.917 total time=   5.9s\n",
            "[CV 3/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   4.6s\n",
            "[CV 4/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 5/5; 203/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 203/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   6.4s\n",
            "[CV 1/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.917 total time=   4.6s\n",
            "[CV 3/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 204/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 204/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.972 total time=   4.6s\n",
            "[CV 1/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.918 total time=   5.9s\n",
            "[CV 2/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 3/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.903 total time=   4.6s\n",
            "[CV 4/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 205/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 205/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.931 total time=   4.6s\n",
            "[CV 1/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.931 total time=   4.6s\n",
            "[CV 3/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.931 total time=   5.2s\n",
            "[CV 4/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 5/5; 206/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 206/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   4.5s\n",
            "[CV 1/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.932 total time=   4.7s\n",
            "[CV 2/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   4.6s\n",
            "[CV 3/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.889 total time=   5.9s\n",
            "[CV 4/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 5/5; 207/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 207/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.958 total time=   4.6s\n",
            "[CV 1/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   4.6s\n",
            "[CV 2/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   4.5s\n",
            "[CV 3/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   4.5s\n",
            "[CV 4/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   4.5s\n",
            "[CV 5/5; 208/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 208/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   4.6s\n",
            "[CV 1/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   5.3s\n",
            "[CV 2/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   4.7s\n",
            "[CV 3/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   4.5s\n",
            "[CV 4/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   4.6s\n",
            "[CV 5/5; 209/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 209/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   5.9s\n",
            "[CV 1/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.973 total time=   5.9s\n",
            "[CV 2/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 3/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   6.0s\n",
            "[CV 5/5; 210/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 210/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   4.5s\n",
            "[CV 1/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   4.8s\n",
            "[CV 2/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.931 total time=   5.9s\n",
            "[CV 3/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.833 total time=   6.4s\n",
            "[CV 4/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   4.5s\n",
            "[CV 5/5; 211/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 211/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.944 total time=   4.6s\n",
            "[CV 1/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.973 total time=   4.5s\n",
            "[CV 2/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.972 total time=   4.6s\n",
            "[CV 4/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.972 total time=   4.6s\n",
            "[CV 5/5; 212/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 212/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.931 total time=   4.6s\n",
            "[CV 1/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   4.7s\n",
            "[CV 3/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 213/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 213/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   4.7s\n",
            "[CV 1/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.918 total time=   5.2s\n",
            "[CV 2/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.875 total time=   4.6s\n",
            "[CV 3/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.903 total time=   5.9s\n",
            "[CV 4/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.958 total time=   4.6s\n",
            "[CV 5/5; 214/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 214/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.903 total time=   5.9s\n",
            "[CV 1/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.932 total time=   5.9s\n",
            "[CV 2/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.917 total time=   5.9s\n",
            "[CV 3/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.917 total time=   4.6s\n",
            "[CV 4/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.986 total time=   5.9s\n",
            "[CV 5/5; 215/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 215/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.903 total time=   5.9s\n",
            "[CV 1/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.945 total time=   5.9s\n",
            "[CV 2/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   4.6s\n",
            "[CV 3/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 4/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.972 total time=   6.4s\n",
            "[CV 5/5; 216/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 216/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.931 total time=   4.6s\n",
            "[CV 1/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   4.5s\n",
            "[CV 2/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   5.9s\n",
            "[CV 3/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   4.5s\n",
            "[CV 4/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   4.5s\n",
            "[CV 5/5; 217/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 217/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   5.9s\n",
            "[CV 1/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   5.9s\n",
            "[CV 2/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   4.4s\n",
            "[CV 3/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   4.5s\n",
            "[CV 4/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   5.9s\n",
            "[CV 5/5; 218/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 218/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   4.4s\n",
            "[CV 1/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   5.0s\n",
            "[CV 2/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   4.6s\n",
            "[CV 3/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   4.5s\n",
            "[CV 4/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   4.4s\n",
            "[CV 5/5; 219/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 219/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   4.3s\n",
            "[CV 2/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   5.9s\n",
            "[CV 3/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   4.2s\n",
            "[CV 5/5; 220/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 220/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   4.2s\n",
            "[CV 1/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   5.8s\n",
            "[CV 2/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   4.3s\n",
            "[CV 4/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   4.7s\n",
            "[CV 5/5; 221/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 221/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   4.2s\n",
            "[CV 2/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   5.9s\n",
            "[CV 4/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   5.9s\n",
            "[CV 5/5; 222/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 222/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   4.2s\n",
            "[CV 2/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   4.3s\n",
            "[CV 3/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   4.3s\n",
            "[CV 4/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   4.3s\n",
            "[CV 5/5; 223/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 223/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   6.3s\n",
            "[CV 2/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   5.8s\n",
            "[CV 5/5; 224/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 224/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   5.8s\n",
            "[CV 2/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   4.2s\n",
            "[CV 4/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   4.3s\n",
            "[CV 5/5; 225/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 225/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.726 total time=   4.2s\n",
            "[CV 2/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   4.2s\n",
            "[CV 3/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.681 total time=   5.9s\n",
            "[CV 4/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   4.6s\n",
            "[CV 5/5; 226/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 226/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.764 total time=   5.9s\n",
            "[CV 1/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.726 total time=   4.2s\n",
            "[CV 2/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.681 total time=   4.2s\n",
            "[CV 4/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   4.2s\n",
            "[CV 5/5; 227/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 227/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.764 total time=   4.2s\n",
            "[CV 1/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.726 total time=   5.8s\n",
            "[CV 2/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   4.2s\n",
            "[CV 3/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   4.2s\n",
            "[CV 5/5; 228/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 228/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.726 total time=   4.6s\n",
            "[CV 2/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.681 total time=   4.2s\n",
            "[CV 4/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   4.2s\n",
            "[CV 5/5; 229/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 229/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.726 total time=   4.2s\n",
            "[CV 2/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   4.3s\n",
            "[CV 3/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   5.8s\n",
            "[CV 5/5; 230/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 230/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.726 total time=   4.2s\n",
            "[CV 2/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.736 total time=   4.2s\n",
            "[CV 3/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.681 total time=   4.3s\n",
            "[CV 4/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.736 total time=   6.3s\n",
            "[CV 5/5; 231/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 231/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.726 total time=   4.3s\n",
            "[CV 2/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   4.4s\n",
            "[CV 3/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   5.8s\n",
            "[CV 5/5; 232/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 232/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.764 total time=   4.4s\n",
            "[CV 1/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.726 total time=   4.3s\n",
            "[CV 2/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.681 total time=   4.3s\n",
            "[CV 4/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.736 total time=   4.3s\n",
            "[CV 5/5; 233/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 233/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.726 total time=   5.9s\n",
            "[CV 2/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.736 total time=   4.7s\n",
            "[CV 3/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.736 total time=   4.3s\n",
            "[CV 5/5; 234/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 234/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.764 total time=   4.4s\n",
            "[CV 1/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.726 total time=   5.8s\n",
            "[CV 2/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.736 total time=   5.9s\n",
            "[CV 3/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.681 total time=   5.9s\n",
            "[CV 4/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.736 total time=   4.2s\n",
            "[CV 5/5; 235/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 235/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.764 total time=   5.8s\n",
            "[CV 1/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.726 total time=   5.8s\n",
            "[CV 2/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.736 total time=   4.2s\n",
            "[CV 3/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.681 total time=   5.9s\n",
            "[CV 4/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.736 total time=   6.3s\n",
            "[CV 5/5; 236/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 236/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.764 total time=   5.9s\n",
            "[CV 1/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.726 total time=   4.3s\n",
            "[CV 2/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.736 total time=   4.3s\n",
            "[CV 3/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.681 total time=   4.3s\n",
            "[CV 4/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.736 total time=   5.9s\n",
            "[CV 5/5; 237/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 237/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.726 total time=   4.3s\n",
            "[CV 2/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.736 total time=   4.3s\n",
            "[CV 3/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.736 total time=   5.9s\n",
            "[CV 5/5; 238/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 238/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.764 total time=   5.9s\n",
            "[CV 1/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.726 total time=   5.8s\n",
            "[CV 2/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.736 total time=   4.8s\n",
            "[CV 3/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.681 total time=   5.9s\n",
            "[CV 4/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.736 total time=   4.2s\n",
            "[CV 5/5; 239/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 239/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.726 total time=   4.3s\n",
            "[CV 2/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.681 total time=   4.3s\n",
            "[CV 4/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.736 total time=   4.3s\n",
            "[CV 5/5; 240/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 240/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.726 total time=   5.8s\n",
            "[CV 2/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.736 total time=   6.3s\n",
            "[CV 5/5; 241/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 241/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.726 total time=   5.9s\n",
            "[CV 2/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.736 total time=   4.3s\n",
            "[CV 3/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.681 total time=   4.4s\n",
            "[CV 4/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.736 total time=   4.3s\n",
            "[CV 5/5; 242/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 242/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.726 total time=   4.3s\n",
            "[CV 2/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.736 total time=   5.8s\n",
            "[CV 3/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.681 total time=   5.8s\n",
            "[CV 4/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.736 total time=   5.8s\n",
            "[CV 5/5; 243/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 243/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.764 total time=   4.3s\n",
            "[CV 1/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   1.1s\n",
            "[CV 2/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.9s\n",
            "[CV 3/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 244/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 244/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.264 total time=   1.4s\n",
            "[CV 3/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   1.1s\n",
            "[CV 4/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 245/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 245/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   1.1s\n",
            "[CV 2/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.6s\n",
            "[CV 5/5; 246/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 246/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.274 total time=   1.2s\n",
            "[CV 2/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   1.1s\n",
            "[CV 4/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.278 total time=   1.4s\n",
            "[CV 5/5; 247/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 247/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.1s\n",
            "[CV 3/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.319 total time=   1.1s\n",
            "[CV 4/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 248/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 248/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   1.8s\n",
            "[CV 1/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.1s\n",
            "[CV 5/5; 249/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 249/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   1.1s\n",
            "[CV 1/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.1s\n",
            "[CV 3/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.319 total time=   1.4s\n",
            "[CV 4/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.1s\n",
            "[CV 5/5; 250/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 250/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.6s\n",
            "[CV 3/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 251/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 251/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   1.1s\n",
            "[CV 4/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.1s\n",
            "[CV 5/5; 252/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 252/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.849 total time=   1.1s\n",
            "[CV 2/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.875 total time=   1.2s\n",
            "[CV 3/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.778 total time=   1.4s\n",
            "[CV 4/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   1.6s\n",
            "[CV 5/5; 253/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 253/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.861 total time=   1.4s\n",
            "[CV 3/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.778 total time=   1.2s\n",
            "[CV 4/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.889 total time=   1.2s\n",
            "[CV 5/5; 254/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 254/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.836 total time=   1.2s\n",
            "[CV 2/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.875 total time=   1.4s\n",
            "[CV 3/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 4/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 5/5; 255/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 255/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.822 total time=   1.6s\n",
            "[CV 2/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 3/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.792 total time=   1.4s\n",
            "[CV 4/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 256/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 256/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.822 total time=   1.1s\n",
            "[CV 2/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.847 total time=   1.2s\n",
            "[CV 3/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.806 total time=   1.2s\n",
            "[CV 4/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.861 total time=   1.2s\n",
            "[CV 5/5; 257/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 257/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.849 total time=   1.2s\n",
            "[CV 2/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.847 total time=   1.4s\n",
            "[CV 3/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.778 total time=   1.9s\n",
            "[CV 4/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.875 total time=   1.4s\n",
            "[CV 5/5; 258/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 258/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.836 total time=   1.2s\n",
            "[CV 2/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.861 total time=   1.2s\n",
            "[CV 3/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 4/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.889 total time=   1.2s\n",
            "[CV 5/5; 259/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 259/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.822 total time=   1.2s\n",
            "[CV 2/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.764 total time=   1.2s\n",
            "[CV 3/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.778 total time=   1.2s\n",
            "[CV 4/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.875 total time=   1.8s\n",
            "[CV 5/5; 260/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 260/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.833 total time=   1.2s\n",
            "[CV 1/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.808 total time=   1.4s\n",
            "[CV 2/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.847 total time=   1.2s\n",
            "[CV 3/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.778 total time=   1.2s\n",
            "[CV 4/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.903 total time=   1.4s\n",
            "[CV 5/5; 261/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 261/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.833 total time=   1.2s\n",
            "[CV 1/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   1.1s\n",
            "[CV 2/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.889 total time=   1.1s\n",
            "[CV 4/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   1.1s\n",
            "[CV 5/5; 262/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 262/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.847 total time=   1.2s\n",
            "[CV 1/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.973 total time=   1.6s\n",
            "[CV 2/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.889 total time=   1.2s\n",
            "[CV 3/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.931 total time=   1.4s\n",
            "[CV 4/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   1.4s\n",
            "[CV 5/5; 263/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 263/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.904 total time=   1.4s\n",
            "[CV 2/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   1.2s\n",
            "[CV 3/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.917 total time=   1.2s\n",
            "[CV 4/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   1.4s\n",
            "[CV 5/5; 264/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 264/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.917 total time=   1.2s\n",
            "[CV 1/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.918 total time=   1.4s\n",
            "[CV 2/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.889 total time=   1.4s\n",
            "[CV 3/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.861 total time=   1.9s\n",
            "[CV 4/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.903 total time=   1.2s\n",
            "[CV 5/5; 265/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 265/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.903 total time=   1.4s\n",
            "[CV 1/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.822 total time=   1.2s\n",
            "[CV 2/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.889 total time=   1.2s\n",
            "[CV 3/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.875 total time=   1.2s\n",
            "[CV 4/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.972 total time=   1.4s\n",
            "[CV 5/5; 266/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 266/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.903 total time=   1.4s\n",
            "[CV 1/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.932 total time=   1.2s\n",
            "[CV 2/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.875 total time=   1.4s\n",
            "[CV 3/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.792 total time=   1.1s\n",
            "[CV 4/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.931 total time=   1.1s\n",
            "[CV 5/5; 267/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 267/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.903 total time=   1.6s\n",
            "[CV 1/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   1.2s\n",
            "[CV 3/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.819 total time=   1.4s\n",
            "[CV 4/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.819 total time=   1.4s\n",
            "[CV 5/5; 268/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 268/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.778 total time=   1.4s\n",
            "[CV 1/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.932 total time=   1.2s\n",
            "[CV 2/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.861 total time=   1.4s\n",
            "[CV 3/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.792 total time=   1.2s\n",
            "[CV 4/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.861 total time=   1.4s\n",
            "[CV 5/5; 269/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 269/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.877 total time=   1.4s\n",
            "[CV 2/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.819 total time=   1.7s\n",
            "[CV 3/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.833 total time=   1.2s\n",
            "[CV 4/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 270/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 270/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 271/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 271/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.9s\n",
            "[CV 5/5; 272/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 272/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 273/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 273/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   1.5s\n",
            "[CV 4/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 274/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 274/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   1.6s\n",
            "[CV 2/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 275/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 275/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.5s\n",
            "[CV 5/5; 276/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 276/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.319 total time=   1.6s\n",
            "[CV 4/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 277/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 277/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.236 total time=   1.2s\n",
            "[CV 1/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.319 total time=   1.4s\n",
            "[CV 4/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 278/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 278/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 279/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 279/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   1.9s\n",
            "[CV 1/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.836 total time=   1.2s\n",
            "[CV 2/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.861 total time=   1.2s\n",
            "[CV 3/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.806 total time=   1.2s\n",
            "[CV 4/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 280/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 280/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.822 total time=   1.2s\n",
            "[CV 2/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.861 total time=   1.4s\n",
            "[CV 3/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.806 total time=   1.2s\n",
            "[CV 4/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.861 total time=   1.2s\n",
            "[CV 5/5; 281/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 281/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.849 total time=   1.2s\n",
            "[CV 2/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.875 total time=   1.7s\n",
            "[CV 3/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.792 total time=   1.2s\n",
            "[CV 4/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.903 total time=   1.5s\n",
            "[CV 5/5; 282/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 282/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.792 total time=   1.4s\n",
            "[CV 4/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 283/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 283/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 1/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.847 total time=   1.4s\n",
            "[CV 3/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.806 total time=   1.6s\n",
            "[CV 4/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.847 total time=   1.4s\n",
            "[CV 5/5; 284/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 284/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 3/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.792 total time=   1.2s\n",
            "[CV 4/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.889 total time=   1.2s\n",
            "[CV 5/5; 285/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 285/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.819 total time=   1.2s\n",
            "[CV 1/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.778 total time=   1.4s\n",
            "[CV 4/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.778 total time=   1.4s\n",
            "[CV 5/5; 286/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 286/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.819 total time=   1.9s\n",
            "[CV 1/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.778 total time=   1.2s\n",
            "[CV 4/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.875 total time=   1.2s\n",
            "[CV 5/5; 287/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 287/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.806 total time=   1.2s\n",
            "[CV 1/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.849 total time=   1.4s\n",
            "[CV 2/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.875 total time=   1.2s\n",
            "[CV 3/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.778 total time=   1.4s\n",
            "[CV 4/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.903 total time=   1.2s\n",
            "[CV 5/5; 288/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 288/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.833 total time=   1.1s\n",
            "[CV 1/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.945 total time=   1.1s\n",
            "[CV 2/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.903 total time=   1.9s\n",
            "[CV 3/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.847 total time=   1.4s\n",
            "[CV 4/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.972 total time=   1.4s\n",
            "[CV 5/5; 289/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 289/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.917 total time=   1.4s\n",
            "[CV 1/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.918 total time=   1.4s\n",
            "[CV 2/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.917 total time=   1.4s\n",
            "[CV 3/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 4/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.792 total time=   1.2s\n",
            "[CV 5/5; 290/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 290/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   1.2s\n",
            "[CV 3/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.875 total time=   1.2s\n",
            "[CV 4/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   1.6s\n",
            "[CV 5/5; 291/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 291/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   1.4s\n",
            "[CV 1/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.836 total time=   1.2s\n",
            "[CV 2/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.889 total time=   1.4s\n",
            "[CV 3/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.792 total time=   1.4s\n",
            "[CV 4/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.833 total time=   1.4s\n",
            "[CV 5/5; 292/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 292/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.847 total time=   1.2s\n",
            "[CV 1/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.904 total time=   1.2s\n",
            "[CV 2/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.917 total time=   1.4s\n",
            "[CV 3/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.847 total time=   1.2s\n",
            "[CV 4/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.847 total time=   1.4s\n",
            "[CV 5/5; 293/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 293/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.917 total time=   1.4s\n",
            "[CV 1/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.890 total time=   1.9s\n",
            "[CV 2/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.792 total time=   1.5s\n",
            "[CV 3/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.792 total time=   1.2s\n",
            "[CV 4/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.931 total time=   1.4s\n",
            "[CV 5/5; 294/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 294/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.875 total time=   1.2s\n",
            "[CV 1/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.863 total time=   1.4s\n",
            "[CV 2/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.861 total time=   1.2s\n",
            "[CV 3/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.792 total time=   1.2s\n",
            "[CV 4/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.847 total time=   1.3s\n",
            "[CV 5/5; 295/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 295/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.819 total time=   1.5s\n",
            "[CV 1/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.781 total time=   1.5s\n",
            "[CV 2/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.736 total time=   1.3s\n",
            "[CV 3/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.847 total time=   1.9s\n",
            "[CV 4/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.903 total time=   1.3s\n",
            "[CV 5/5; 296/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 296/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.833 total time=   1.5s\n",
            "[CV 1/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.877 total time=   1.5s\n",
            "[CV 2/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   1.5s\n",
            "[CV 3/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.806 total time=   1.5s\n",
            "[CV 4/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   1.5s\n",
            "[CV 5/5; 297/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 297/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.875 total time=   1.3s\n",
            "[CV 1/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   1.5s\n",
            "[CV 2/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.264 total time=   1.3s\n",
            "[CV 3/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   1.3s\n",
            "[CV 4/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.5s\n",
            "[CV 5/5; 298/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 298/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   2.1s\n",
            "[CV 1/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.5s\n",
            "[CV 5/5; 299/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 299/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   1.5s\n",
            "[CV 1/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   1.5s\n",
            "[CV 2/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.5s\n",
            "[CV 3/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   1.6s\n",
            "[CV 4/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 300/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 300/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   1.5s\n",
            "[CV 1/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   1.5s\n",
            "[CV 2/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   2.0s\n",
            "[CV 3/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 301/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 301/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.236 total time=   1.1s\n",
            "[CV 1/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 302/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 302/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.6s\n",
            "[CV 5/5; 303/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 303/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.264 total time=   1.2s\n",
            "[CV 3/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.319 total time=   1.5s\n",
            "[CV 4/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 304/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 304/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   1.6s\n",
            "[CV 1/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   1.6s\n",
            "[CV 2/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.5s\n",
            "[CV 3/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   1.5s\n",
            "[CV 4/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 305/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 305/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   1.5s\n",
            "[CV 1/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   2.1s\n",
            "[CV 2/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.6s\n",
            "[CV 3/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   1.3s\n",
            "[CV 4/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.3s\n",
            "[CV 5/5; 306/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 306/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   1.6s\n",
            "[CV 1/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.822 total time=   1.6s\n",
            "[CV 2/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.792 total time=   1.3s\n",
            "[CV 3/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.778 total time=   1.5s\n",
            "[CV 4/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.861 total time=   1.5s\n",
            "[CV 5/5; 307/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 307/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.819 total time=   1.3s\n",
            "[CV 1/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.726 total time=   1.5s\n",
            "[CV 2/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.5s\n",
            "[CV 3/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.7s\n",
            "[CV 4/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 308/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 308/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.833 total time=   1.2s\n",
            "[CV 1/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.822 total time=   1.2s\n",
            "[CV 2/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.792 total time=   1.4s\n",
            "[CV 3/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.875 total time=   1.2s\n",
            "[CV 5/5; 309/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 309/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.681 total time=   1.1s\n",
            "[CV 4/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   1.1s\n",
            "[CV 5/5; 310/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 310/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.833 total time=   1.6s\n",
            "[CV 1/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.836 total time=   1.2s\n",
            "[CV 2/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.819 total time=   1.1s\n",
            "[CV 3/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.806 total time=   1.1s\n",
            "[CV 4/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.875 total time=   1.2s\n",
            "[CV 5/5; 311/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 311/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 3/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.764 total time=   1.1s\n",
            "[CV 4/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.833 total time=   1.4s\n",
            "[CV 5/5; 312/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 312/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.819 total time=   1.9s\n",
            "[CV 3/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 313/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 313/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.822 total time=   1.2s\n",
            "[CV 2/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.847 total time=   1.2s\n",
            "[CV 3/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.792 total time=   1.4s\n",
            "[CV 4/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.889 total time=   1.1s\n",
            "[CV 5/5; 314/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 314/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.806 total time=   1.1s\n",
            "[CV 1/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.847 total time=   1.4s\n",
            "[CV 3/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.792 total time=   1.8s\n",
            "[CV 4/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 5/5; 315/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 315/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.959 total time=   1.4s\n",
            "[CV 2/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.917 total time=   1.4s\n",
            "[CV 3/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.903 total time=   1.2s\n",
            "[CV 4/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   1.2s\n",
            "[CV 5/5; 316/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 316/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.903 total time=   1.1s\n",
            "[CV 1/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.945 total time=   1.4s\n",
            "[CV 2/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.917 total time=   1.1s\n",
            "[CV 3/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.833 total time=   1.4s\n",
            "[CV 4/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   1.4s\n",
            "[CV 5/5; 317/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 317/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.903 total time=   1.9s\n",
            "[CV 1/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.959 total time=   1.2s\n",
            "[CV 2/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.903 total time=   1.2s\n",
            "[CV 3/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.903 total time=   1.1s\n",
            "[CV 4/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.917 total time=   1.2s\n",
            "[CV 5/5; 318/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 318/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.875 total time=   1.2s\n",
            "[CV 1/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.767 total time=   1.4s\n",
            "[CV 2/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.903 total time=   1.4s\n",
            "[CV 3/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.792 total time=   1.4s\n",
            "[CV 4/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   1.4s\n",
            "[CV 5/5; 319/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 319/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.708 total time=   1.2s\n",
            "[CV 1/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.918 total time=   1.1s\n",
            "[CV 2/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.875 total time=   1.6s\n",
            "[CV 3/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.861 total time=   1.2s\n",
            "[CV 4/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.986 total time=   1.2s\n",
            "[CV 5/5; 320/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 320/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.917 total time=   1.1s\n",
            "[CV 1/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.904 total time=   1.2s\n",
            "[CV 2/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.875 total time=   1.4s\n",
            "[CV 3/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.944 total time=   1.2s\n",
            "[CV 4/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.903 total time=   1.2s\n",
            "[CV 5/5; 321/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 321/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.861 total time=   1.1s\n",
            "[CV 1/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.904 total time=   1.1s\n",
            "[CV 2/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.847 total time=   1.2s\n",
            "[CV 4/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.903 total time=   1.9s\n",
            "[CV 5/5; 322/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 322/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.792 total time=   1.2s\n",
            "[CV 1/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   1.2s\n",
            "[CV 3/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.903 total time=   1.2s\n",
            "[CV 4/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.931 total time=   1.1s\n",
            "[CV 5/5; 323/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 323/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.792 total time=   1.4s\n",
            "[CV 1/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   1.4s\n",
            "[CV 3/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.833 total time=   1.1s\n",
            "[CV 4/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.903 total time=   1.4s\n",
            "[CV 5/5; 324/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 324/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   3.0s\n",
            "[CV 2/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 325/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 325/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 326/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 326/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.1s\n",
            "[CV 5/5; 327/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 327/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 328/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 328/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 329/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 329/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   3.8s\n",
            "[CV 2/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 330/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 330/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 331/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 331/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.1s\n",
            "[CV 3/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   2.7s\n",
            "[CV 5/5; 332/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 332/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   2.7s\n",
            "[CV 3/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 333/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 333/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.3s\n",
            "[CV 2/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.944 total time=   3.4s\n",
            "[CV 3/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   3.4s\n",
            "[CV 4/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.8s\n",
            "[CV 5/5; 334/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 334/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   2.6s\n",
            "[CV 1/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   3.3s\n",
            "[CV 2/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   3.4s\n",
            "[CV 3/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   3.4s\n",
            "[CV 4/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 335/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 335/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 1/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.959 total time=   3.4s\n",
            "[CV 2/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   2.6s\n",
            "[CV 3/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   2.6s\n",
            "[CV 4/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 336/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 336/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.944 total time=   2.6s\n",
            "[CV 1/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.959 total time=   3.8s\n",
            "[CV 2/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.986 total time=   2.6s\n",
            "[CV 4/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 337/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 337/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.945 total time=   2.6s\n",
            "[CV 2/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.944 total time=   3.4s\n",
            "[CV 3/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.931 total time=   2.6s\n",
            "[CV 4/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 338/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 338/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   3.3s\n",
            "[CV 1/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.945 total time=   3.3s\n",
            "[CV 2/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   3.3s\n",
            "[CV 3/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.931 total time=   3.3s\n",
            "[CV 4/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   3.8s\n",
            "[CV 5/5; 339/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 339/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 1/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.917 total time=   2.7s\n",
            "[CV 3/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 340/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 340/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   2.7s\n",
            "[CV 1/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.945 total time=   2.6s\n",
            "[CV 2/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   3.4s\n",
            "[CV 4/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.986 total time=   3.4s\n",
            "[CV 5/5; 341/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 341/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.945 total time=   3.8s\n",
            "[CV 2/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.958 total time=   2.7s\n",
            "[CV 3/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 342/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 342/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.877 total time=   3.3s\n",
            "[CV 2/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   2.5s\n",
            "[CV 3/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.972 total time=   3.3s\n",
            "[CV 4/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 343/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 343/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 1/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.973 total time=   2.6s\n",
            "[CV 2/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.917 total time=   3.1s\n",
            "[CV 3/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 344/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 344/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   3.4s\n",
            "[CV 1/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.973 total time=   3.4s\n",
            "[CV 2/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 345/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 345/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.931 total time=   2.6s\n",
            "[CV 1/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.945 total time=   3.3s\n",
            "[CV 2/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   2.6s\n",
            "[CV 3/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.750 total time=   2.6s\n",
            "[CV 4/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.972 total time=   3.8s\n",
            "[CV 5/5; 346/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 346/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.875 total time=   2.7s\n",
            "[CV 1/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.959 total time=   2.6s\n",
            "[CV 2/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.903 total time=   2.6s\n",
            "[CV 3/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.917 total time=   2.6s\n",
            "[CV 4/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   2.7s\n",
            "[CV 5/5; 347/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 347/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.944 total time=   3.4s\n",
            "[CV 1/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.945 total time=   2.6s\n",
            "[CV 2/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.875 total time=   3.3s\n",
            "[CV 3/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   3.4s\n",
            "[CV 4/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 348/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 348/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.944 total time=   2.7s\n",
            "[CV 1/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.863 total time=   3.8s\n",
            "[CV 2/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.847 total time=   2.7s\n",
            "[CV 3/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   2.7s\n",
            "[CV 4/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.958 total time=   2.6s\n",
            "[CV 5/5; 349/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 349/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   3.3s\n",
            "[CV 1/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.877 total time=   3.3s\n",
            "[CV 2/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.875 total time=   3.3s\n",
            "[CV 3/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   2.7s\n",
            "[CV 4/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 5/5; 350/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 350/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.917 total time=   2.6s\n",
            "[CV 1/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.904 total time=   3.3s\n",
            "[CV 2/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.833 total time=   2.6s\n",
            "[CV 3/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.903 total time=   2.6s\n",
            "[CV 4/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.958 total time=   3.8s\n",
            "[CV 5/5; 351/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 351/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   2.7s\n",
            "[CV 1/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 352/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 352/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   2.7s\n",
            "[CV 4/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 353/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 353/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   3.2s\n",
            "[CV 2/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 354/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 354/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   2.7s\n",
            "[CV 1/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.750 total time=   2.6s\n",
            "[CV 3/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 355/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 355/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   2.7s\n",
            "[CV 2/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   3.8s\n",
            "[CV 3/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   2.7s\n",
            "[CV 5/5; 356/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 356/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   2.7s\n",
            "[CV 5/5; 357/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 357/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   2.7s\n",
            "[CV 2/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 358/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 358/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   3.1s\n",
            "[CV 1/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 359/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 359/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 360/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 360/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   3.4s\n",
            "[CV 2/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.972 total time=   2.6s\n",
            "[CV 3/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.917 total time=   3.8s\n",
            "[CV 4/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 361/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 361/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 2/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 362/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 362/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.931 total time=   3.4s\n",
            "[CV 1/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   3.3s\n",
            "[CV 2/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   3.4s\n",
            "[CV 3/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 4/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 363/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 363/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.958 total time=   3.8s\n",
            "[CV 1/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 364/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 364/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 1/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.944 total time=   3.4s\n",
            "[CV 4/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 365/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 365/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.945 total time=   3.8s\n",
            "[CV 2/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   2.7s\n",
            "[CV 3/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 366/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 366/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 1/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.945 total time=   3.4s\n",
            "[CV 2/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 4/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 367/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 367/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.932 total time=   2.6s\n",
            "[CV 2/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.986 total time=   3.8s\n",
            "[CV 5/5; 368/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 368/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.972 total time=   2.7s\n",
            "[CV 1/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.959 total time=   3.3s\n",
            "[CV 2/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   3.4s\n",
            "[CV 3/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 4/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=1.000 total time=   2.7s\n",
            "[CV 5/5; 369/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 369/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   2.6s\n",
            "[CV 1/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.959 total time=   3.3s\n",
            "[CV 2/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.917 total time=   3.3s\n",
            "[CV 3/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   3.4s\n",
            "[CV 4/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 370/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 370/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   2.6s\n",
            "[CV 1/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   3.8s\n",
            "[CV 3/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.931 total time=   3.4s\n",
            "[CV 4/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 371/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 371/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 1/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   3.4s\n",
            "[CV 2/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 372/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 372/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   2.6s\n",
            "[CV 1/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   3.3s\n",
            "[CV 2/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.875 total time=   3.3s\n",
            "[CV 3/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.875 total time=   3.1s\n",
            "[CV 4/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.972 total time=   2.6s\n",
            "[CV 5/5; 373/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 373/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.847 total time=   2.6s\n",
            "[CV 1/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.932 total time=   3.4s\n",
            "[CV 2/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 3/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.972 total time=   2.6s\n",
            "[CV 5/5; 374/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 374/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.931 total time=   2.6s\n",
            "[CV 1/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.945 total time=   3.3s\n",
            "[CV 2/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.889 total time=   2.7s\n",
            "[CV 3/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.917 total time=   3.3s\n",
            "[CV 4/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   3.4s\n",
            "[CV 5/5; 375/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 375/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 1/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.932 total time=   3.1s\n",
            "[CV 2/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   2.7s\n",
            "[CV 3/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.917 total time=   3.3s\n",
            "[CV 4/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.931 total time=   3.4s\n",
            "[CV 5/5; 376/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 376/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.903 total time=   2.7s\n",
            "[CV 1/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.918 total time=   2.6s\n",
            "[CV 2/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   2.6s\n",
            "[CV 3/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.819 total time=   3.4s\n",
            "[CV 4/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.917 total time=   2.6s\n",
            "[CV 5/5; 377/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 377/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.903 total time=   3.3s\n",
            "[CV 1/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.959 total time=   2.6s\n",
            "[CV 2/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.847 total time=   3.4s\n",
            "[CV 3/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.847 total time=   3.3s\n",
            "[CV 4/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   3.9s\n",
            "[CV 5/5; 378/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 378/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.944 total time=   3.4s\n",
            "[CV 1/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 379/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 379/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 380/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 380/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   3.1s\n",
            "[CV 2/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 3/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   2.7s\n",
            "[CV 4/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 381/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 381/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   2.7s\n",
            "[CV 1/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 382/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 382/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   3.1s\n",
            "[CV 5/5; 383/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 383/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 384/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 384/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 385/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 385/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   3.8s\n",
            "[CV 2/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   2.7s\n",
            "[CV 3/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 386/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 386/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   2.7s\n",
            "[CV 2/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 387/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 387/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.973 total time=   3.4s\n",
            "[CV 2/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.972 total time=   3.3s\n",
            "[CV 3/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 4/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   3.9s\n",
            "[CV 5/5; 388/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 388/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.972 total time=   2.6s\n",
            "[CV 1/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.973 total time=   2.6s\n",
            "[CV 2/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   2.6s\n",
            "[CV 3/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   2.6s\n",
            "[CV 4/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 389/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 389/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   2.6s\n",
            "[CV 2/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   2.6s\n",
            "[CV 3/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.958 total time=   3.4s\n",
            "[CV 4/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 390/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 390/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   3.3s\n",
            "[CV 1/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.973 total time=   3.8s\n",
            "[CV 2/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   3.4s\n",
            "[CV 3/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 391/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 391/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   3.4s\n",
            "[CV 1/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.3s\n",
            "[CV 2/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.917 total time=   3.3s\n",
            "[CV 3/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 392/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 392/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   3.4s\n",
            "[CV 1/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.986 total time=   2.6s\n",
            "[CV 2/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   2.7s\n",
            "[CV 3/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 4/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.986 total time=   3.8s\n",
            "[CV 5/5; 393/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 393/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   3.4s\n",
            "[CV 1/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.932 total time=   3.4s\n",
            "[CV 2/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 4/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.986 total time=   3.4s\n",
            "[CV 5/5; 394/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 394/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   3.4s\n",
            "[CV 1/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.959 total time=   3.3s\n",
            "[CV 2/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=1.000 total time=   3.4s\n",
            "[CV 5/5; 395/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 395/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 1/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.959 total time=   3.9s\n",
            "[CV 2/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   3.4s\n",
            "[CV 3/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.958 total time=   2.7s\n",
            "[CV 4/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=1.000 total time=   2.7s\n",
            "[CV 5/5; 396/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 396/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.917 total time=   3.4s\n",
            "[CV 1/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.904 total time=   2.6s\n",
            "[CV 2/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   3.3s\n",
            "[CV 4/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   3.4s\n",
            "[CV 5/5; 397/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 397/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.833 total time=   2.6s\n",
            "[CV 1/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.973 total time=   2.7s\n",
            "[CV 2/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   3.4s\n",
            "[CV 3/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   3.4s\n",
            "[CV 4/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   3.1s\n",
            "[CV 5/5; 398/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 398/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   2.7s\n",
            "[CV 1/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   3.4s\n",
            "[CV 2/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   3.4s\n",
            "[CV 3/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=1.000 total time=   3.4s\n",
            "[CV 5/5; 399/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 399/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.917 total time=   2.7s\n",
            "[CV 1/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.959 total time=   3.4s\n",
            "[CV 2/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.931 total time=   3.3s\n",
            "[CV 3/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   3.4s\n",
            "[CV 4/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.958 total time=   3.3s\n",
            "[CV 5/5; 400/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 400/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   3.4s\n",
            "[CV 1/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.959 total time=   3.3s\n",
            "[CV 2/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.889 total time=   3.1s\n",
            "[CV 3/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.903 total time=   3.4s\n",
            "[CV 4/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 5/5; 401/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 401/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.889 total time=   2.6s\n",
            "[CV 1/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.932 total time=   3.4s\n",
            "[CV 2/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   3.4s\n",
            "[CV 4/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=1.000 total time=   3.4s\n",
            "[CV 5/5; 402/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 402/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 1/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.932 total time=   2.7s\n",
            "[CV 2/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.819 total time=   2.6s\n",
            "[CV 3/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.819 total time=   3.3s\n",
            "[CV 4/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.819 total time=   3.1s\n",
            "[CV 5/5; 403/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 403/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.917 total time=   2.7s\n",
            "[CV 1/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.932 total time=   2.6s\n",
            "[CV 2/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.861 total time=   2.6s\n",
            "[CV 3/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.875 total time=   2.7s\n",
            "[CV 4/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 404/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 404/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 1/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.904 total time=   3.4s\n",
            "[CV 2/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   2.6s\n",
            "[CV 3/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.861 total time=   3.3s\n",
            "[CV 4/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   2.6s\n",
            "[CV 5/5; 405/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 405/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=50, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   2.6s\n",
            "[CV 1/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.836 total time=   5.9s\n",
            "[CV 2/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.833 total time=   4.9s\n",
            "[CV 3/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.778 total time=   5.9s\n",
            "[CV 4/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.903 total time=   4.3s\n",
            "[CV 5/5; 406/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 406/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.806 total time=   4.3s\n",
            "[CV 1/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.849 total time=   5.9s\n",
            "[CV 2/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.875 total time=   4.4s\n",
            "[CV 3/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.806 total time=   4.3s\n",
            "[CV 4/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.875 total time=   4.4s\n",
            "[CV 5/5; 407/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 407/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.833 total time=   5.9s\n",
            "[CV 1/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.836 total time=   4.4s\n",
            "[CV 2/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.875 total time=   4.4s\n",
            "[CV 3/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.806 total time=   5.9s\n",
            "[CV 4/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.903 total time=   5.9s\n",
            "[CV 5/5; 408/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 408/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.847 total time=   5.0s\n",
            "[CV 1/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.836 total time=   4.4s\n",
            "[CV 2/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.875 total time=   5.9s\n",
            "[CV 3/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.806 total time=   5.9s\n",
            "[CV 4/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.903 total time=   6.0s\n",
            "[CV 5/5; 409/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 409/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.833 total time=   6.0s\n",
            "[CV 1/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.849 total time=   6.0s\n",
            "[CV 2/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.875 total time=   5.9s\n",
            "[CV 3/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.806 total time=   4.4s\n",
            "[CV 4/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.931 total time=   5.9s\n",
            "[CV 5/5; 410/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 410/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.833 total time=   4.6s\n",
            "[CV 1/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.836 total time=   5.9s\n",
            "[CV 2/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.875 total time=   6.4s\n",
            "[CV 3/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.806 total time=   6.0s\n",
            "[CV 4/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.917 total time=   4.5s\n",
            "[CV 5/5; 411/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 411/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.847 total time=   4.5s\n",
            "[CV 1/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.849 total time=   4.6s\n",
            "[CV 2/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.875 total time=   4.6s\n",
            "[CV 3/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.806 total time=   6.0s\n",
            "[CV 4/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.889 total time=   5.9s\n",
            "[CV 5/5; 412/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 412/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.847 total time=   4.5s\n",
            "[CV 1/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.822 total time=   5.9s\n",
            "[CV 2/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.861 total time=   4.5s\n",
            "[CV 3/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.792 total time=   5.9s\n",
            "[CV 4/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.931 total time=   4.4s\n",
            "[CV 5/5; 413/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 413/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.847 total time=   4.9s\n",
            "[CV 1/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.849 total time=   4.5s\n",
            "[CV 2/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.875 total time=   5.9s\n",
            "[CV 3/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.792 total time=   4.5s\n",
            "[CV 4/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 5/5; 414/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 414/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.833 total time=   5.9s\n",
            "[CV 1/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   6.0s\n",
            "[CV 3/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   4.4s\n",
            "[CV 4/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 415/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 415/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.932 total time=   4.3s\n",
            "[CV 2/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   6.4s\n",
            "[CV 3/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   4.4s\n",
            "[CV 4/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 416/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 416/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   4.4s\n",
            "[CV 1/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   4.5s\n",
            "[CV 4/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   4.4s\n",
            "[CV 5/5; 417/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 417/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   4.4s\n",
            "[CV 1/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.973 total time=   4.4s\n",
            "[CV 2/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 3/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 4/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 418/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 418/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   5.0s\n",
            "[CV 1/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.932 total time=   5.9s\n",
            "[CV 2/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.931 total time=   5.9s\n",
            "[CV 3/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   4.4s\n",
            "[CV 4/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 419/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 419/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.973 total time=   5.9s\n",
            "[CV 2/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   4.4s\n",
            "[CV 3/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 4/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   4.5s\n",
            "[CV 5/5; 420/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 420/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 1/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.945 total time=   4.5s\n",
            "[CV 2/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   6.4s\n",
            "[CV 3/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.931 total time=   4.6s\n",
            "[CV 4/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   4.5s\n",
            "[CV 5/5; 421/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 421/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 1/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 4/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.986 total time=   4.4s\n",
            "[CV 5/5; 422/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 422/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   4.4s\n",
            "[CV 1/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.973 total time=   5.9s\n",
            "[CV 2/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 3/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 4/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 423/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 423/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   5.0s\n",
            "[CV 1/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.918 total time=   4.4s\n",
            "[CV 2/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   4.4s\n",
            "[CV 3/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 424/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 424/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   5.9s\n",
            "[CV 1/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.973 total time=   5.9s\n",
            "[CV 2/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   4.3s\n",
            "[CV 3/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 4/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   5.9s\n",
            "[CV 5/5; 425/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 425/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.903 total time=   4.3s\n",
            "[CV 1/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   4.8s\n",
            "[CV 3/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 4/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 426/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 426/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.931 total time=   4.4s\n",
            "[CV 3/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.931 total time=   4.4s\n",
            "[CV 4/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 427/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 427/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.903 total time=   4.3s\n",
            "[CV 1/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.959 total time=   4.4s\n",
            "[CV 2/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 3/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.903 total time=   4.5s\n",
            "[CV 4/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.986 total time=   5.9s\n",
            "[CV 5/5; 428/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 428/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.931 total time=   4.9s\n",
            "[CV 1/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.945 total time=   5.9s\n",
            "[CV 2/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   4.4s\n",
            "[CV 4/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 429/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 429/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 1/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.945 total time=   5.9s\n",
            "[CV 2/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   5.9s\n",
            "[CV 3/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.861 total time=   4.4s\n",
            "[CV 4/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.917 total time=   5.9s\n",
            "[CV 5/5; 430/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 430/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 1/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.904 total time=   4.4s\n",
            "[CV 2/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   4.4s\n",
            "[CV 3/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.875 total time=   4.9s\n",
            "[CV 4/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.972 total time=   4.5s\n",
            "[CV 5/5; 431/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 431/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.903 total time=   5.9s\n",
            "[CV 1/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.918 total time=   5.9s\n",
            "[CV 2/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 3/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 4/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 5/5; 432/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 432/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 1/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   5.9s\n",
            "[CV 2/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.889 total time=   5.9s\n",
            "[CV 3/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.806 total time=   4.3s\n",
            "[CV 4/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.875 total time=   5.9s\n",
            "[CV 5/5; 433/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 433/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.847 total time=   4.8s\n",
            "[CV 1/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.849 total time=   4.4s\n",
            "[CV 2/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.861 total time=   5.9s\n",
            "[CV 3/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.806 total time=   4.3s\n",
            "[CV 4/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.931 total time=   5.9s\n",
            "[CV 5/5; 434/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 434/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.847 total time=   5.9s\n",
            "[CV 1/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.849 total time=   5.9s\n",
            "[CV 2/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.875 total time=   5.9s\n",
            "[CV 3/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.806 total time=   4.4s\n",
            "[CV 4/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.889 total time=   5.9s\n",
            "[CV 5/5; 435/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 435/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.847 total time=   4.4s\n",
            "[CV 1/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.822 total time=   4.4s\n",
            "[CV 2/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   5.9s\n",
            "[CV 3/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.778 total time=   6.4s\n",
            "[CV 4/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.875 total time=   4.4s\n",
            "[CV 5/5; 436/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 436/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.833 total time=   4.3s\n",
            "[CV 1/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.849 total time=   4.4s\n",
            "[CV 2/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.875 total time=   5.9s\n",
            "[CV 3/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.778 total time=   4.3s\n",
            "[CV 4/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.931 total time=   5.9s\n",
            "[CV 5/5; 437/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 437/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.847 total time=   5.9s\n",
            "[CV 1/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.849 total time=   5.9s\n",
            "[CV 2/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.875 total time=   4.4s\n",
            "[CV 3/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.806 total time=   4.4s\n",
            "[CV 4/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.917 total time=   4.4s\n",
            "[CV 5/5; 438/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 438/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.847 total time=   4.8s\n",
            "[CV 1/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.808 total time=   4.5s\n",
            "[CV 2/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.861 total time=   4.5s\n",
            "[CV 3/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   4.4s\n",
            "[CV 4/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.889 total time=   4.4s\n",
            "[CV 5/5; 439/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 439/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.819 total time=   4.4s\n",
            "[CV 1/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.836 total time=   4.5s\n",
            "[CV 2/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.861 total time=   5.9s\n",
            "[CV 3/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.819 total time=   4.5s\n",
            "[CV 4/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.903 total time=   5.9s\n",
            "[CV 5/5; 440/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 440/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.833 total time=   4.4s\n",
            "[CV 1/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.836 total time=   4.4s\n",
            "[CV 2/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.875 total time=   4.4s\n",
            "[CV 3/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.819 total time=   6.4s\n",
            "[CV 4/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.931 total time=   5.9s\n",
            "[CV 5/5; 441/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 441/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.847 total time=   4.4s\n",
            "[CV 1/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.973 total time=   4.3s\n",
            "[CV 2/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.972 total time=   4.3s\n",
            "[CV 4/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   4.3s\n",
            "[CV 5/5; 442/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 442/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   4.3s\n",
            "[CV 1/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   4.4s\n",
            "[CV 4/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 443/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 443/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   4.3s\n",
            "[CV 1/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   4.8s\n",
            "[CV 2/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   4.4s\n",
            "[CV 3/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 4/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 444/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 444/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 1/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.973 total time=   4.3s\n",
            "[CV 2/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   4.3s\n",
            "[CV 3/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 4/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   4.3s\n",
            "[CV 5/5; 445/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 445/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.973 total time=   5.9s\n",
            "[CV 2/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.944 total time=   4.5s\n",
            "[CV 3/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   4.4s\n",
            "[CV 4/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   6.4s\n",
            "[CV 5/5; 446/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 446/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   4.4s\n",
            "[CV 1/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.959 total time=   4.4s\n",
            "[CV 2/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 3/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.972 total time=   4.4s\n",
            "[CV 4/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 447/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 447/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.959 total time=   4.5s\n",
            "[CV 2/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   4.4s\n",
            "[CV 4/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 448/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 448/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.973 total time=   4.9s\n",
            "[CV 2/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   4.4s\n",
            "[CV 3/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   4.4s\n",
            "[CV 4/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 449/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 449/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.945 total time=   5.9s\n",
            "[CV 2/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   4.4s\n",
            "[CV 3/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 4/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 450/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 450/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 1/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   5.9s\n",
            "[CV 3/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   4.3s\n",
            "[CV 4/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.931 total time=   4.8s\n",
            "[CV 5/5; 451/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 451/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   4.3s\n",
            "[CV 1/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.959 total time=   4.3s\n",
            "[CV 2/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   4.4s\n",
            "[CV 3/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   4.4s\n",
            "[CV 4/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=1.000 total time=   4.3s\n",
            "[CV 5/5; 452/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 452/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   4.3s\n",
            "[CV 1/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.903 total time=   4.4s\n",
            "[CV 3/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 453/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 453/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.932 total time=   6.4s\n",
            "[CV 2/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.944 total time=   4.4s\n",
            "[CV 3/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   5.9s\n",
            "[CV 4/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.944 total time=   4.4s\n",
            "[CV 5/5; 454/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 454/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.944 total time=   4.4s\n",
            "[CV 1/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.917 total time=   5.9s\n",
            "[CV 3/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 455/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 455/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.931 total time=   4.4s\n",
            "[CV 1/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.918 total time=   5.9s\n",
            "[CV 2/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.917 total time=   4.4s\n",
            "[CV 3/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 4/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.986 total time=   4.3s\n",
            "[CV 5/5; 456/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 456/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.931 total time=   4.9s\n",
            "[CV 1/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.781 total time=   5.9s\n",
            "[CV 2/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.875 total time=   4.5s\n",
            "[CV 3/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.917 total time=   5.9s\n",
            "[CV 4/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.972 total time=   4.5s\n",
            "[CV 5/5; 457/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 457/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.819 total time=   5.9s\n",
            "[CV 1/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.931 total time=   4.4s\n",
            "[CV 3/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.917 total time=   5.9s\n",
            "[CV 4/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.944 total time=   5.9s\n",
            "[CV 5/5; 458/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 458/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.944 total time=   4.4s\n",
            "[CV 1/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.945 total time=   5.9s\n",
            "[CV 2/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   4.9s\n",
            "[CV 3/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.819 total time=   4.5s\n",
            "[CV 4/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.986 total time=   4.4s\n",
            "[CV 5/5; 459/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 459/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   4.5s\n",
            "[CV 1/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   5.9s\n",
            "[CV 2/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.833 total time=   4.4s\n",
            "[CV 3/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.778 total time=   4.4s\n",
            "[CV 4/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.889 total time=   4.3s\n",
            "[CV 5/5; 460/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 460/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.833 total time=   5.9s\n",
            "[CV 1/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.849 total time=   5.9s\n",
            "[CV 2/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.889 total time=   4.4s\n",
            "[CV 3/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.778 total time=   5.9s\n",
            "[CV 4/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.903 total time=   4.3s\n",
            "[CV 5/5; 461/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 461/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.833 total time=   4.3s\n",
            "[CV 1/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.795 total time=   4.9s\n",
            "[CV 2/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.861 total time=   4.4s\n",
            "[CV 3/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.806 total time=   4.4s\n",
            "[CV 4/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.917 total time=   5.9s\n",
            "[CV 5/5; 462/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 462/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.819 total time=   5.9s\n",
            "[CV 1/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.836 total time=   4.3s\n",
            "[CV 2/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.833 total time=   5.9s\n",
            "[CV 3/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   4.3s\n",
            "[CV 4/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.861 total time=   5.9s\n",
            "[CV 5/5; 463/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 463/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.833 total time=   4.3s\n",
            "[CV 1/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.767 total time=   5.9s\n",
            "[CV 2/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   6.0s\n",
            "[CV 3/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.792 total time=   5.2s\n",
            "[CV 4/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.819 total time=   6.0s\n",
            "[CV 5/5; 464/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 464/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.833 total time=   4.6s\n",
            "[CV 1/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.836 total time=   4.6s\n",
            "[CV 2/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.861 total time=   4.6s\n",
            "[CV 3/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.806 total time=   5.9s\n",
            "[CV 4/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.861 total time=   4.6s\n",
            "[CV 5/5; 465/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 465/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.819 total time=   4.4s\n",
            "[CV 1/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.836 total time=   4.4s\n",
            "[CV 2/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   5.9s\n",
            "[CV 3/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.750 total time=   4.4s\n",
            "[CV 4/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.833 total time=   5.9s\n",
            "[CV 5/5; 466/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 466/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.819 total time=   4.4s\n",
            "[CV 1/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.849 total time=   4.9s\n",
            "[CV 2/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.875 total time=   4.4s\n",
            "[CV 3/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.806 total time=   4.4s\n",
            "[CV 4/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.889 total time=   4.4s\n",
            "[CV 5/5; 467/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 467/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.833 total time=   4.5s\n",
            "[CV 1/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.822 total time=   5.9s\n",
            "[CV 2/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.819 total time=   5.9s\n",
            "[CV 3/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.806 total time=   5.9s\n",
            "[CV 4/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.889 total time=   5.9s\n",
            "[CV 5/5; 468/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 468/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.833 total time=   5.9s\n",
            "[CV 1/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   4.3s\n",
            "[CV 2/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   4.4s\n",
            "[CV 3/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.958 total time=   5.0s\n",
            "[CV 4/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   4.5s\n",
            "[CV 5/5; 469/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 469/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.986 total time=   4.5s\n",
            "[CV 1/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.973 total time=   4.5s\n",
            "[CV 2/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   6.0s\n",
            "[CV 3/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   4.7s\n",
            "[CV 4/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   6.0s\n",
            "[CV 5/5; 470/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 470/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   6.0s\n",
            "[CV 1/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.959 total time=   6.0s\n",
            "[CV 2/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   4.8s\n",
            "[CV 3/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   4.7s\n",
            "[CV 4/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   4.7s\n",
            "[CV 5/5; 471/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 471/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   6.0s\n",
            "[CV 1/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.973 total time=   5.2s\n",
            "[CV 2/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.903 total time=   4.6s\n",
            "[CV 3/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   6.0s\n",
            "[CV 4/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 472/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 472/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   5.9s\n",
            "[CV 2/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   4.4s\n",
            "[CV 3/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.986 total time=   4.4s\n",
            "[CV 4/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 473/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 473/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   4.4s\n",
            "[CV 1/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.931 total time=   4.4s\n",
            "[CV 3/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 4/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   4.4s\n",
            "[CV 5/5; 474/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 474/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.972 total time=   4.9s\n",
            "[CV 1/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.986 total time=   4.4s\n",
            "[CV 2/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.972 total time=   5.9s\n",
            "[CV 3/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   4.5s\n",
            "[CV 5/5; 475/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 475/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.932 total time=   4.4s\n",
            "[CV 2/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.931 total time=   4.5s\n",
            "[CV 3/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 4/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=1.000 total time=   4.5s\n",
            "[CV 5/5; 476/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 476/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   4.5s\n",
            "[CV 1/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.918 total time=   4.4s\n",
            "[CV 2/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.903 total time=   6.4s\n",
            "[CV 3/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   4.5s\n",
            "[CV 4/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=1.000 total time=   4.5s\n",
            "[CV 5/5; 477/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 477/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.972 total time=   4.6s\n",
            "[CV 1/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   5.9s\n",
            "[CV 2/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.972 total time=   5.9s\n",
            "[CV 3/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 4/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.972 total time=   4.4s\n",
            "[CV 5/5; 478/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 478/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   4.4s\n",
            "[CV 1/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.973 total time=   4.4s\n",
            "[CV 2/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.931 total time=   4.3s\n",
            "[CV 3/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   4.3s\n",
            "[CV 4/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   4.3s\n",
            "[CV 5/5; 479/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 479/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.959 total time=   6.4s\n",
            "[CV 2/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   5.9s\n",
            "[CV 3/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   4.4s\n",
            "[CV 4/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=1.000 total time=   5.9s\n",
            "[CV 5/5; 480/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 480/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   5.9s\n",
            "[CV 1/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.904 total time=   5.9s\n",
            "[CV 2/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   5.9s\n",
            "[CV 3/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.944 total time=   5.9s\n",
            "[CV 4/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.917 total time=   4.4s\n",
            "[CV 5/5; 481/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 481/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.945 total time=   4.4s\n",
            "[CV 2/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.972 total time=   4.4s\n",
            "[CV 3/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.986 total time=   6.4s\n",
            "[CV 4/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 5/5; 482/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 482/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   5.9s\n",
            "[CV 1/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.986 total time=   4.4s\n",
            "[CV 2/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 3/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   4.4s\n",
            "[CV 4/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.958 total time=   5.9s\n",
            "[CV 5/5; 483/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 483/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.972 total time=   5.9s\n",
            "[CV 1/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.918 total time=   5.9s\n",
            "[CV 2/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.931 total time=   5.9s\n",
            "[CV 3/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.931 total time=   4.5s\n",
            "[CV 4/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.931 total time=   5.9s\n",
            "[CV 5/5; 484/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 484/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   4.4s\n",
            "[CV 1/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.959 total time=   5.9s\n",
            "[CV 2/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.931 total time=   5.0s\n",
            "[CV 3/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   5.9s\n",
            "[CV 4/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.903 total time=   4.4s\n",
            "[CV 5/5; 485/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 485/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.917 total time=   5.9s\n",
            "[CV 1/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.932 total time=   4.5s\n",
            "[CV 2/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   4.4s\n",
            "[CV 3/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.917 total time=   4.4s\n",
            "[CV 4/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.958 total time=   4.5s\n",
            "[CV 5/5; 486/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 486/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.1, epochs=100, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.875 total time=   5.9s\n",
            "[CV 1/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.7s\n",
            "[CV 5/5; 487/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 487/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 488/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 488/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   1.5s\n",
            "[CV 4/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 489/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 489/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   1.1s\n",
            "[CV 2/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.5s\n",
            "[CV 3/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   1.7s\n",
            "[CV 4/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 490/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 490/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   1.1s\n",
            "[CV 1/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 491/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 491/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.236 total time=   1.4s\n",
            "[CV 1/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.5s\n",
            "[CV 5/5; 492/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 492/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   2.0s\n",
            "[CV 2/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.3s\n",
            "[CV 3/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.3s\n",
            "[CV 5/5; 493/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 493/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   1.5s\n",
            "[CV 1/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 494/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 494/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   1.1s\n",
            "[CV 4/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 495/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 495/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   1.7s\n",
            "[CV 1/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 496/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 496/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.764 total time=   1.1s\n",
            "[CV 1/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 497/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 497/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.806 total time=   1.4s\n",
            "[CV 1/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   1.6s\n",
            "[CV 3/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   1.5s\n",
            "[CV 5/5; 498/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 498/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.792 total time=   1.2s\n",
            "[CV 5/5; 499/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 499/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.806 total time=   1.2s\n",
            "[CV 1/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 500/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 500/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.819 total time=   1.2s\n",
            "[CV 1/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.726 total time=   1.7s\n",
            "[CV 2/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.847 total time=   1.2s\n",
            "[CV 3/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 501/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 501/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.806 total time=   1.2s\n",
            "[CV 1/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.740 total time=   1.4s\n",
            "[CV 2/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 3/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.750 total time=   1.5s\n",
            "[CV 4/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.792 total time=   1.4s\n",
            "[CV 5/5; 502/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 502/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.833 total time=   1.4s\n",
            "[CV 3/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.681 total time=   1.7s\n",
            "[CV 4/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 503/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 503/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.819 total time=   1.2s\n",
            "[CV 1/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.792 total time=   1.2s\n",
            "[CV 3/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.792 total time=   1.2s\n",
            "[CV 5/5; 504/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 504/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.806 total time=   1.4s\n",
            "[CV 1/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.808 total time=   1.2s\n",
            "[CV 2/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.861 total time=   1.5s\n",
            "[CV 4/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 505/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 505/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.847 total time=   1.1s\n",
            "[CV 1/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.903 total time=   2.0s\n",
            "[CV 3/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   1.4s\n",
            "[CV 4/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.931 total time=   1.4s\n",
            "[CV 5/5; 506/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 506/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.806 total time=   1.2s\n",
            "[CV 1/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.959 total time=   1.4s\n",
            "[CV 2/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.917 total time=   1.4s\n",
            "[CV 3/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.875 total time=   1.4s\n",
            "[CV 4/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.944 total time=   1.2s\n",
            "[CV 5/5; 507/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 507/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.819 total time=   1.2s\n",
            "[CV 1/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.736 total time=   1.6s\n",
            "[CV 5/5; 508/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 508/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.792 total time=   1.2s\n",
            "[CV 1/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.918 total time=   1.4s\n",
            "[CV 2/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.806 total time=   1.4s\n",
            "[CV 3/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.833 total time=   1.4s\n",
            "[CV 4/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.847 total time=   1.2s\n",
            "[CV 5/5; 509/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 509/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.959 total time=   1.4s\n",
            "[CV 2/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.806 total time=   1.4s\n",
            "[CV 4/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.931 total time=   1.2s\n",
            "[CV 5/5; 510/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 510/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.806 total time=   1.4s\n",
            "[CV 1/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.863 total time=   1.4s\n",
            "[CV 2/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.861 total time=   1.4s\n",
            "[CV 3/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.778 total time=   2.0s\n",
            "[CV 4/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.875 total time=   1.4s\n",
            "[CV 5/5; 511/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 511/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.877 total time=   1.4s\n",
            "[CV 2/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.778 total time=   1.2s\n",
            "[CV 3/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.833 total time=   1.4s\n",
            "[CV 4/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 512/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 512/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.806 total time=   1.4s\n",
            "[CV 1/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.877 total time=   1.2s\n",
            "[CV 2/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.875 total time=   1.2s\n",
            "[CV 3/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.806 total time=   1.2s\n",
            "[CV 4/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.875 total time=   1.2s\n",
            "[CV 5/5; 513/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 513/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.847 total time=   1.2s\n",
            "[CV 1/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   1.7s\n",
            "[CV 2/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.5s\n",
            "[CV 3/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 514/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 514/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   1.1s\n",
            "[CV 1/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 515/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 515/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.7s\n",
            "[CV 5/5; 516/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 516/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.274 total time=   1.2s\n",
            "[CV 2/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 517/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 517/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 518/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 518/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   1.1s\n",
            "[CV 2/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   2.0s\n",
            "[CV 4/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 519/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 519/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.274 total time=   1.4s\n",
            "[CV 2/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 520/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 520/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 521/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 521/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.236 total time=   1.2s\n",
            "[CV 1/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   2.0s\n",
            "[CV 2/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 522/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 522/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.778 total time=   1.5s\n",
            "[CV 3/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   1.5s\n",
            "[CV 5/5; 523/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 523/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.833 total time=   1.4s\n",
            "[CV 3/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.7s\n",
            "[CV 5/5; 524/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 524/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.750 total time=   1.4s\n",
            "[CV 4/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.847 total time=   1.2s\n",
            "[CV 5/5; 525/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 525/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.792 total time=   1.2s\n",
            "[CV 1/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.819 total time=   1.4s\n",
            "[CV 3/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.833 total time=   1.4s\n",
            "[CV 5/5; 526/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 526/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.819 total time=   1.2s\n",
            "[CV 1/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 3/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.681 total time=   1.7s\n",
            "[CV 4/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 527/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 527/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.833 total time=   1.2s\n",
            "[CV 1/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.808 total time=   1.4s\n",
            "[CV 2/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.819 total time=   1.2s\n",
            "[CV 3/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.792 total time=   1.4s\n",
            "[CV 5/5; 528/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 528/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.778 total time=   1.4s\n",
            "[CV 1/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 529/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 529/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.806 total time=   1.1s\n",
            "[CV 1/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.808 total time=   1.9s\n",
            "[CV 2/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.764 total time=   1.2s\n",
            "[CV 3/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.750 total time=   1.4s\n",
            "[CV 4/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.833 total time=   1.2s\n",
            "[CV 5/5; 530/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 530/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.795 total time=   1.4s\n",
            "[CV 2/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.819 total time=   1.1s\n",
            "[CV 3/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.778 total time=   1.4s\n",
            "[CV 4/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 5/5; 531/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 531/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.904 total time=   1.2s\n",
            "[CV 2/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.889 total time=   1.4s\n",
            "[CV 3/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.833 total time=   1.4s\n",
            "[CV 4/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.819 total time=   1.7s\n",
            "[CV 5/5; 532/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 532/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.847 total time=   1.2s\n",
            "[CV 1/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.945 total time=   1.2s\n",
            "[CV 2/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.889 total time=   1.2s\n",
            "[CV 3/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.792 total time=   1.2s\n",
            "[CV 4/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.903 total time=   1.2s\n",
            "[CV 5/5; 533/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 533/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.889 total time=   1.1s\n",
            "[CV 1/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.918 total time=   1.2s\n",
            "[CV 2/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.917 total time=   1.2s\n",
            "[CV 3/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.847 total time=   1.2s\n",
            "[CV 4/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.972 total time=   1.2s\n",
            "[CV 5/5; 534/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 534/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 1/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.792 total time=   2.0s\n",
            "[CV 4/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 535/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 535/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.889 total time=   1.2s\n",
            "[CV 1/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.889 total time=   1.4s\n",
            "[CV 3/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.819 total time=   1.2s\n",
            "[CV 4/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.903 total time=   1.2s\n",
            "[CV 5/5; 536/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 536/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.833 total time=   1.5s\n",
            "[CV 1/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.877 total time=   1.2s\n",
            "[CV 2/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.889 total time=   1.4s\n",
            "[CV 3/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.889 total time=   1.2s\n",
            "[CV 4/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.903 total time=   1.4s\n",
            "[CV 5/5; 537/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 537/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 1/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.753 total time=   1.7s\n",
            "[CV 2/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.792 total time=   1.4s\n",
            "[CV 4/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.792 total time=   1.2s\n",
            "[CV 5/5; 538/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 538/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.806 total time=   1.2s\n",
            "[CV 1/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.877 total time=   1.2s\n",
            "[CV 2/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.875 total time=   1.2s\n",
            "[CV 3/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.833 total time=   1.4s\n",
            "[CV 4/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   1.2s\n",
            "[CV 5/5; 539/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 539/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.847 total time=   1.2s\n",
            "[CV 1/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.861 total time=   1.4s\n",
            "[CV 3/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.819 total time=   1.2s\n",
            "[CV 4/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.847 total time=   2.0s\n",
            "[CV 5/5; 540/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 540/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=normal, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.806 total time=   1.4s\n",
            "[CV 1/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.319 total time=   1.4s\n",
            "[CV 4/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 541/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 541/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 542/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 542/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   2.0s\n",
            "[CV 4/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   1.5s\n",
            "[CV 5/5; 543/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 543/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.264 total time=   1.2s\n",
            "[CV 3/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 544/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 544/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 545/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 545/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   1.7s\n",
            "[CV 2/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 546/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 546/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.264 total time=   1.4s\n",
            "[CV 5/5; 547/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 547/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   2.0s\n",
            "[CV 5/5; 548/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 548/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   1.5s\n",
            "[CV 2/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 549/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 549/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 550/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 550/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.681 total time=   2.0s\n",
            "[CV 4/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 551/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 551/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 552/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 552/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.726 total time=   1.4s\n",
            "[CV 2/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 553/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 553/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.726 total time=   1.7s\n",
            "[CV 2/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 554/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 554/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.806 total time=   1.2s\n",
            "[CV 1/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.778 total time=   1.2s\n",
            "[CV 4/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 5/5; 555/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 555/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.806 total time=   1.4s\n",
            "[CV 1/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.681 total time=   1.4s\n",
            "[CV 4/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.736 total time=   1.7s\n",
            "[CV 5/5; 556/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 556/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.764 total time=   1.2s\n",
            "[CV 1/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.767 total time=   1.2s\n",
            "[CV 2/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.833 total time=   1.2s\n",
            "[CV 5/5; 557/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 557/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.806 total time=   1.2s\n",
            "[CV 1/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.726 total time=   1.2s\n",
            "[CV 2/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.736 total time=   1.4s\n",
            "[CV 3/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.764 total time=   1.2s\n",
            "[CV 4/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 5/5; 558/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 558/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.764 total time=   1.4s\n",
            "[CV 1/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.808 total time=   1.2s\n",
            "[CV 2/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.903 total time=   1.2s\n",
            "[CV 3/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.806 total time=   2.0s\n",
            "[CV 4/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.903 total time=   1.4s\n",
            "[CV 5/5; 559/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 559/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.889 total time=   1.4s\n",
            "[CV 1/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.917 total time=   1.1s\n",
            "[CV 3/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 4/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.875 total time=   1.2s\n",
            "[CV 5/5; 560/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 560/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.861 total time=   1.4s\n",
            "[CV 1/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.849 total time=   1.2s\n",
            "[CV 2/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.875 total time=   1.4s\n",
            "[CV 3/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.903 total time=   1.2s\n",
            "[CV 4/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   1.2s\n",
            "[CV 5/5; 561/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 561/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.903 total time=   1.4s\n",
            "[CV 1/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.849 total time=   2.0s\n",
            "[CV 2/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 3/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.778 total time=   1.2s\n",
            "[CV 4/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.847 total time=   1.2s\n",
            "[CV 5/5; 562/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 562/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.833 total time=   1.2s\n",
            "[CV 1/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.849 total time=   1.4s\n",
            "[CV 2/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.875 total time=   1.2s\n",
            "[CV 3/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.847 total time=   1.1s\n",
            "[CV 4/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.861 total time=   1.4s\n",
            "[CV 5/5; 563/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 563/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.819 total time=   1.4s\n",
            "[CV 1/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.890 total time=   1.2s\n",
            "[CV 2/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.736 total time=   1.2s\n",
            "[CV 3/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.861 total time=   1.2s\n",
            "[CV 4/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.917 total time=   1.9s\n",
            "[CV 5/5; 564/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 564/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.833 total time=   1.4s\n",
            "[CV 1/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.849 total time=   1.2s\n",
            "[CV 2/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.861 total time=   1.2s\n",
            "[CV 3/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.681 total time=   1.2s\n",
            "[CV 4/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.778 total time=   1.4s\n",
            "[CV 5/5; 565/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 565/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.847 total time=   1.4s\n",
            "[CV 1/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.836 total time=   1.4s\n",
            "[CV 2/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.875 total time=   1.2s\n",
            "[CV 3/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.778 total time=   1.2s\n",
            "[CV 4/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.889 total time=   1.4s\n",
            "[CV 5/5; 566/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 566/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.778 total time=   1.2s\n",
            "[CV 1/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.890 total time=   1.4s\n",
            "[CV 2/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.861 total time=   1.2s\n",
            "[CV 3/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.778 total time=   1.7s\n",
            "[CV 4/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   1.4s\n",
            "[CV 5/5; 567/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 567/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=10, init=zero, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.861 total time=   1.2s\n",
            "[CV 1/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 568/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 568/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 569/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 569/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   3.9s\n",
            "[CV 2/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 570/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 570/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 571/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 571/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   3.1s\n",
            "[CV 5/5; 572/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 572/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   3.4s\n",
            "[CV 2/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 573/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 573/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   3.4s\n",
            "[CV 4/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 574/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 574/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   2.7s\n",
            "[CV 2/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   3.9s\n",
            "[CV 4/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 575/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 575/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   2.7s\n",
            "[CV 1/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.4s\n",
            "[CV 5/5; 576/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 576/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.959 total time=   3.4s\n",
            "[CV 2/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.917 total time=   3.3s\n",
            "[CV 4/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 577/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 577/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.972 total time=   3.3s\n",
            "[CV 1/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.959 total time=   3.9s\n",
            "[CV 2/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   3.4s\n",
            "[CV 3/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.972 total time=   2.6s\n",
            "[CV 4/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 578/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 578/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 4/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 579/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 579/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.917 total time=   2.6s\n",
            "[CV 1/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.932 total time=   2.6s\n",
            "[CV 2/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.958 total time=   3.4s\n",
            "[CV 3/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.931 total time=   2.6s\n",
            "[CV 4/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.986 total time=   3.9s\n",
            "[CV 5/5; 580/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 580/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   3.4s\n",
            "[CV 1/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.986 total time=   3.4s\n",
            "[CV 2/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   3.4s\n",
            "[CV 3/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 581/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 581/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.972 total time=   2.6s\n",
            "[CV 1/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.945 total time=   2.6s\n",
            "[CV 2/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   3.4s\n",
            "[CV 4/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 582/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 582/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   2.7s\n",
            "[CV 1/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.932 total time=   3.4s\n",
            "[CV 2/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.917 total time=   3.1s\n",
            "[CV 3/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.958 total time=   3.4s\n",
            "[CV 4/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 583/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 583/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   3.4s\n",
            "[CV 1/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.945 total time=   2.6s\n",
            "[CV 2/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.917 total time=   2.7s\n",
            "[CV 3/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 4/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 584/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 584/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 1/5; 585/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 585/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.945 total time=   3.3s\n",
            "[CV 2/5; 585/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 585/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.917 total time=   2.6s\n",
            "[CV 3/5; 585/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 585/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.972 total time=   3.3s\n",
            "[CV 4/5; 585/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 585/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.986 total time=   3.4s\n",
            "[CV 5/5; 585/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 585/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.944 total time=   2.6s\n",
            "[CV 1/5; 586/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 586/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.986 total time=   3.9s\n",
            "[CV 2/5; 586/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 586/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.972 total time=   2.6s\n",
            "[CV 3/5; 586/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 586/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 586/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 586/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 5/5; 586/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 586/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.917 total time=   3.3s\n",
            "[CV 1/5; 587/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 587/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   2.6s\n",
            "[CV 2/5; 587/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 587/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.889 total time=   3.3s\n",
            "[CV 3/5; 587/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 587/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.931 total time=   2.6s\n",
            "[CV 4/5; 587/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 587/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 587/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 587/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 1/5; 588/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 588/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 588/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 588/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 588/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 588/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   3.3s\n",
            "[CV 4/5; 588/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 588/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.972 total time=   2.6s\n",
            "[CV 5/5; 588/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 5/5; 588/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.972 total time=   3.2s\n",
            "[CV 1/5; 589/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 1/5; 589/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 589/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 2/5; 589/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.847 total time=   2.6s\n",
            "[CV 3/5; 589/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 3/5; 589/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.903 total time=   3.4s\n",
            "[CV 4/5; 589/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 4/5; 589/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 589/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2\n",
            "[CV 5/5; 589/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=2;, score=0.861 total time=   3.3s\n",
            "[CV 1/5; 590/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 1/5; 590/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.932 total time=   2.6s\n",
            "[CV 2/5; 590/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 2/5; 590/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 590/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 3/5; 590/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.931 total time=   3.3s\n",
            "[CV 4/5; 590/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 4/5; 590/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.903 total time=   2.6s\n",
            "[CV 5/5; 590/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4\n",
            "[CV 5/5; 590/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=4;, score=0.903 total time=   2.6s\n",
            "[CV 1/5; 591/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 1/5; 591/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.918 total time=   3.4s\n",
            "[CV 2/5; 591/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 2/5; 591/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.903 total time=   3.3s\n",
            "[CV 3/5; 591/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 3/5; 591/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.944 total time=   3.9s\n",
            "[CV 4/5; 591/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 4/5; 591/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.986 total time=   3.4s\n",
            "[CV 5/5; 591/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8\n",
            "[CV 5/5; 591/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=8, neuron2=8;, score=0.917 total time=   2.6s\n",
            "[CV 1/5; 592/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 1/5; 592/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.877 total time=   3.3s\n",
            "[CV 2/5; 592/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 2/5; 592/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.903 total time=   2.6s\n",
            "[CV 3/5; 592/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 3/5; 592/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 4/5; 592/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 4/5; 592/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.889 total time=   2.6s\n",
            "[CV 5/5; 592/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2\n",
            "[CV 5/5; 592/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=2;, score=0.847 total time=   3.4s\n",
            "[CV 1/5; 593/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 1/5; 593/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.973 total time=   2.6s\n",
            "[CV 2/5; 593/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 2/5; 593/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.903 total time=   3.4s\n",
            "[CV 3/5; 593/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 3/5; 593/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.792 total time=   2.6s\n",
            "[CV 4/5; 593/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 4/5; 593/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.931 total time=   3.3s\n",
            "[CV 5/5; 593/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4\n",
            "[CV 5/5; 593/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=4;, score=0.806 total time=   3.4s\n",
            "[CV 1/5; 594/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 1/5; 594/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.932 total time=   3.9s\n",
            "[CV 2/5; 594/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 2/5; 594/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.889 total time=   3.3s\n",
            "[CV 3/5; 594/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 3/5; 594/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.875 total time=   2.7s\n",
            "[CV 4/5; 594/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 4/5; 594/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.903 total time=   3.3s\n",
            "[CV 5/5; 594/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8\n",
            "[CV 5/5; 594/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=uniform, learning_rate=0.1, neuron1=16, neuron2=8;, score=0.861 total time=   2.6s\n",
            "[CV 1/5; 595/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 1/5; 595/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 595/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 2/5; 595/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 595/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 3/5; 595/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 595/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 4/5; 595/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 595/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2\n",
            "[CV 5/5; 595/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 596/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 1/5; 596/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 596/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 2/5; 596/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 596/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 3/5; 596/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 596/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 4/5; 596/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 596/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4\n",
            "[CV 5/5; 596/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=4;, score=0.764 total time=   3.1s\n",
            "[CV 1/5; 597/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 1/5; 597/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 597/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 2/5; 597/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 597/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 3/5; 597/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 597/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 4/5; 597/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 597/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8\n",
            "[CV 5/5; 597/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=4, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 598/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 1/5; 598/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 598/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 2/5; 598/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 598/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 3/5; 598/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 598/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 4/5; 598/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.736 total time=   2.6s\n",
            "[CV 5/5; 598/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2\n",
            "[CV 5/5; 598/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=2;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 599/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 1/5; 599/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 599/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 2/5; 599/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 599/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 3/5; 599/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.681 total time=   3.8s\n",
            "[CV 4/5; 599/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 4/5; 599/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 599/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4\n",
            "[CV 5/5; 599/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=4;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 600/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 1/5; 600/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.726 total time=   2.6s\n",
            "[CV 2/5; 600/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 2/5; 600/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 600/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 3/5; 600/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 600/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 4/5; 600/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 600/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8\n",
            "[CV 5/5; 600/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=8, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 601/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 1/5; 601/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 601/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 2/5; 601/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 3/5; 601/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 3/5; 601/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.681 total time=   2.6s\n",
            "[CV 4/5; 601/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 4/5; 601/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 601/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2\n",
            "[CV 5/5; 601/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=2;, score=0.764 total time=   2.6s\n",
            "[CV 1/5; 602/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 1/5; 602/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 602/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 2/5; 602/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.1s\n",
            "[CV 3/5; 602/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 3/5; 602/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.681 total time=   2.7s\n",
            "[CV 4/5; 602/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 4/5; 602/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 602/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4\n",
            "[CV 5/5; 602/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=4;, score=0.764 total time=   3.4s\n",
            "[CV 1/5; 603/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 1/5; 603/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.726 total time=   3.3s\n",
            "[CV 2/5; 603/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 2/5; 603/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   2.6s\n",
            "[CV 3/5; 603/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 3/5; 603/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.681 total time=   3.3s\n",
            "[CV 4/5; 603/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 4/5; 603/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.736 total time=   3.3s\n",
            "[CV 5/5; 603/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8\n",
            "[CV 5/5; 603/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.001, neuron1=16, neuron2=8;, score=0.764 total time=   3.3s\n",
            "[CV 1/5; 604/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 1/5; 604/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.932 total time=   2.6s\n",
            "[CV 2/5; 604/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 2/5; 604/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 604/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 3/5; 604/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 4/5; 604/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 4/5; 604/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 604/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2\n",
            "[CV 5/5; 604/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=2;, score=0.889 total time=   3.3s\n",
            "[CV 1/5; 605/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 1/5; 605/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.973 total time=   3.1s\n",
            "[CV 2/5; 605/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 2/5; 605/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 3/5; 605/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 3/5; 605/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 605/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 4/5; 605/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 605/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4\n",
            "[CV 5/5; 605/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 1/5; 606/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 1/5; 606/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.945 total time=   2.6s\n",
            "[CV 2/5; 606/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 2/5; 606/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   3.4s\n",
            "[CV 3/5; 606/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 3/5; 606/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.944 total time=   2.6s\n",
            "[CV 4/5; 606/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 4/5; 606/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 606/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8\n",
            "[CV 5/5; 606/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=4, neuron2=8;, score=0.972 total time=   2.6s\n",
            "[CV 1/5; 607/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 1/5; 607/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.986 total time=   3.3s\n",
            "[CV 2/5; 607/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 2/5; 607/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 607/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 3/5; 607/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.944 total time=   3.3s\n",
            "[CV 4/5; 607/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 4/5; 607/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 607/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2\n",
            "[CV 5/5; 607/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=2;, score=0.917 total time=   3.1s\n",
            "[CV 1/5; 608/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 1/5; 608/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.959 total time=   2.6s\n",
            "[CV 2/5; 608/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 2/5; 608/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 608/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 3/5; 608/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 608/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 4/5; 608/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 608/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4\n",
            "[CV 5/5; 608/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=4;, score=0.958 total time=   2.6s\n",
            "[CV 1/5; 609/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 1/5; 609/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   2.6s\n",
            "[CV 2/5; 609/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 2/5; 609/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 609/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 3/5; 609/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 4/5; 609/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 4/5; 609/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=1.000 total time=   2.6s\n",
            "[CV 5/5; 609/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8\n",
            "[CV 5/5; 609/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=8, neuron2=8;, score=0.958 total time=   3.3s\n",
            "[CV 1/5; 610/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 1/5; 610/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.973 total time=   3.3s\n",
            "[CV 2/5; 610/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 2/5; 610/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.931 total time=   3.3s\n",
            "[CV 3/5; 610/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 3/5; 610/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 4/5; 610/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 4/5; 610/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=1.000 total time=   3.1s\n",
            "[CV 5/5; 610/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2\n",
            "[CV 5/5; 610/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=2;, score=0.931 total time=   2.6s\n",
            "[CV 1/5; 611/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 1/5; 611/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.932 total time=   3.3s\n",
            "[CV 2/5; 611/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 2/5; 611/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 611/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 3/5; 611/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.972 total time=   3.3s\n",
            "[CV 4/5; 611/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 4/5; 611/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=1.000 total time=   3.3s\n",
            "[CV 5/5; 611/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4\n",
            "[CV 5/5; 611/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=4;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 612/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 1/5; 612/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.945 total time=   3.3s\n",
            "[CV 2/5; 612/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 2/5; 612/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.931 total time=   2.6s\n",
            "[CV 3/5; 612/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 3/5; 612/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.958 total time=   2.6s\n",
            "[CV 4/5; 612/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 4/5; 612/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 612/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8\n",
            "[CV 5/5; 612/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.01, neuron1=16, neuron2=8;, score=0.931 total time=   3.3s\n",
            "[CV 1/5; 613/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 1/5; 613/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.877 total time=   2.5s\n",
            "[CV 2/5; 613/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 2/5; 613/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.944 total time=   2.6s\n",
            "[CV 3/5; 613/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 3/5; 613/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.750 total time=   3.1s\n",
            "[CV 4/5; 613/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 4/5; 613/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.958 total time=   3.3s\n",
            "[CV 5/5; 613/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2\n",
            "[CV 5/5; 613/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=2;, score=0.861 total time=   3.4s\n",
            "[CV 1/5; 614/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 1/5; 614/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.849 total time=   3.3s\n",
            "[CV 2/5; 614/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 2/5; 614/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.944 total time=   3.3s\n",
            "[CV 3/5; 614/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 3/5; 614/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.958 total time=   3.3s\n",
            "[CV 4/5; 614/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 4/5; 614/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   3.3s\n",
            "[CV 5/5; 614/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4\n",
            "[CV 5/5; 614/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=4;, score=0.986 total time=   2.5s\n",
            "[CV 1/5; 615/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 1/5; 615/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.890 total time=   2.6s\n",
            "[CV 2/5; 615/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 2/5; 615/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.931 total time=   2.6s\n",
            "[CV 3/5; 615/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 3/5; 615/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.958 total time=   2.5s\n",
            "[CV 4/5; 615/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n",
            "[CV 4/5; 615/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8;, score=0.986 total time=   2.6s\n",
            "[CV 5/5; 615/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.2, epochs=50, init=normal, learning_rate=0.1, neuron1=4, neuron2=8\n"
          ]
        }
      ],
      "source": [
        "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 11,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam=adam_v2.Adam(learning_rate = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
        "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(x_train, y_train)\n",
        "\n",
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amqn37lxTBKN"
      },
      "source": [
        "#### Best : 0.9916666626930237, using {'activation_function': 'tanh', 'batch_size': 20, 'dropout_rate': 0.1, 'epochs': 50, 'init': 'normal', 'learning_rate': 0.01, 'neuron1': 4, 'neuron2': 2}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81YVkBOkTBKO"
      },
      "source": [
        "### Building final model with above best parameters obtained from tuning hyper paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7CmV0VPTBKP"
      },
      "outputs": [],
      "source": [
        "# create model\n",
        "final_model = Sequential()\n",
        "final_model.add(Dense(4,input_dim = 11,kernel_initializer = 'normal',activation = 'tanh'))\n",
        "final_model.add(Dropout(0.1))\n",
        "final_model.add(Dense(2,input_dim = 4,kernel_initializer = 'normal',activation = 'tanh'))\n",
        "final_model.add(Dropout(0.1))\n",
        "final_model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "adam=adam_v2.Adam(learning_rate = 0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-7qjuvjTBKQ"
      },
      "outputs": [],
      "source": [
        "# Compile Model\n",
        "final_model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "P4dZ2XovTBKQ",
        "outputId": "749f64c6-4939-4140-c613-f4b37a070217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "19/19 [==============================] - 1s 2ms/step - loss: 0.6608 - accuracy: 0.7313\n",
            "Epoch 2/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.5760 - accuracy: 0.7479\n",
            "Epoch 3/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.7701\n",
            "Epoch 4/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.8033\n",
            "Epoch 5/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8310\n",
            "Epoch 6/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8476\n",
            "Epoch 7/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.3325 - accuracy: 0.8837\n",
            "Epoch 8/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2599 - accuracy: 0.9030\n",
            "Epoch 9/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.9335\n",
            "Epoch 10/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9418\n",
            "Epoch 11/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.2835 - accuracy: 0.8864\n",
            "Epoch 12/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.9280\n",
            "Epoch 13/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.9668\n",
            "Epoch 14/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9640\n",
            "Epoch 15/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9778\n",
            "Epoch 16/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9917\n",
            "Epoch 17/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0889 - accuracy: 0.9778\n",
            "Epoch 18/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9861\n",
            "Epoch 19/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9778\n",
            "Epoch 20/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0693 - accuracy: 0.9806\n",
            "Epoch 21/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9834\n",
            "Epoch 22/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9695\n",
            "Epoch 23/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9834\n",
            "Epoch 24/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9778\n",
            "Epoch 25/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0632 - accuracy: 0.9751\n",
            "Epoch 26/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0540 - accuracy: 0.9834\n",
            "Epoch 27/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9723\n",
            "Epoch 28/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9861\n",
            "Epoch 29/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9806\n",
            "Epoch 30/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9834\n",
            "Epoch 31/50\n",
            "19/19 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9751\n",
            "Epoch 32/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9723\n",
            "Epoch 33/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9751\n",
            "Epoch 34/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9612\n",
            "Epoch 35/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.1038 - accuracy: 0.9778\n",
            "Epoch 36/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9751\n",
            "Epoch 37/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9834\n",
            "Epoch 38/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0539 - accuracy: 0.9778\n",
            "Epoch 39/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9723\n",
            "Epoch 40/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9861\n",
            "Epoch 41/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0470 - accuracy: 0.9834\n",
            "Epoch 42/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.9861\n",
            "Epoch 43/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9861\n",
            "Epoch 44/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9861\n",
            "Epoch 45/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9889\n",
            "Epoch 46/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9723\n",
            "Epoch 47/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0494 - accuracy: 0.9778\n",
            "Epoch 48/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9778\n",
            "Epoch 49/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9751\n",
            "Epoch 50/50\n",
            "19/19 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9861\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x25e495cee80>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the model\n",
        "final_model.fit(x_train,y_train, epochs=50, batch_size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pF5BWWmTBKR",
        "outputId": "c427afe3-42b3-4490-b9ba-3c617428bfec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9808\n",
            "accuracy: 98.08%\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model\n",
        "scores = final_model.evaluate(x_test, y_test)\n",
        "print(\"%s: %.2f%%\" % (final_model.metrics_names[1], scores[1]*100))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Assig Neural Network .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "amqn37lxTBKN"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}